{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ff5a093",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ff5a093",
        "outputId": "db9b7791-39ae-43a3-d928-d243a8d63be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.18)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.7)\n",
            "Requirement already satisfied: cryptography>=3.3.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (40.0.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (3.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m109.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.4-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.25.1-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.7/206.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=6cf1a9a41b06e87fcce92ddb2028a7d5fb2b24f8b3d2e94e56e0631fba367cd8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.25.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.4\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install transformers\n",
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1a3524a9",
      "metadata": {
        "id": "1a3524a9"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import mpl, plt\n",
        "import math, time\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from operator import itemgetter\n",
        "from tqdm import tqdm\n",
        "from math import sqrt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "24afc749",
      "metadata": {
        "id": "24afc749"
      },
      "outputs": [],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e128245b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "e128245b",
        "outputId": "9e06736e-ba88-44f4-c553-afdd166512f9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvisriv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230612_082021-yjp2cupu</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/visriv/stock_prediction/runs/yjp2cupu' target=\"_blank\">clear-bird-5</a></strong> to <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">https://wandb.ai/visriv/stock_prediction</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/visriv/stock_prediction/runs/yjp2cupu' target=\"_blank\">https://wandb.ai/visriv/stock_prediction/runs/yjp2cupu</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/visriv/stock_prediction/runs/yjp2cupu?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f5ba0973a90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"stock_prediction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76ea47cc",
      "metadata": {
        "id": "76ea47cc"
      },
      "source": [
        "### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9a8dec6d",
      "metadata": {
        "id": "9a8dec6d"
      },
      "outputs": [],
      "source": [
        "no_of_days_to_lookforward = 1\n",
        "no_of_days_to_lookback = 5\n",
        "up_threshold = 0.015\n",
        "down_threshold = -0.015\n",
        "max_text_per_iter = 20\n",
        "batch_size = 8\n",
        "MAX_LEN = 10\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af59387d",
      "metadata": {
        "id": "af59387d"
      },
      "source": [
        "### Get stocks data for last N days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ebb836a",
      "metadata": {
        "id": "6ebb836a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "64983989",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64983989",
        "outputId": "0e0b1552-23b0-4ca6-d8e1-c7edabe1ddaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "stock_symbols = [ 'XOM']\n",
        "no_of_days = 4*365\n",
        "\n",
        "EXPORT_DATA_FOLDER = './data/'\n",
        "!mkdir data\n",
        "# Set the start and end dates for the data \n",
        "# here matching it with dates of news text available\n",
        "start = datetime.strptime('2019/01/04', '%Y/%m/%d')\n",
        "end = datetime.strptime('2023/01/04', '%Y/%m/%d')\n",
        "\n",
        "\n",
        "# start = datetime.datetime.now() - datetime.timedelta(days=no_of_days)\n",
        "# end = datetime.datetime.now()\n",
        "\n",
        "for symbol in stock_symbols:\n",
        "    # Download the historical price and volume data using yfinance\n",
        "    data_raw = yf.download(symbol, start=start, end=end)\n",
        "\n",
        "    # Normalize features by percent of changes between today and yesterday\n",
        "    pct_change_open = data_raw['Open'].pct_change().fillna(0)\n",
        "    pct_change_high = data_raw['High'].pct_change().fillna(0)\n",
        "    pct_change_high_over_open = (data_raw['High']-data_raw['Open'])/data_raw['Open']\n",
        "    pct_change_low = data_raw['Low'].pct_change().fillna(0)\n",
        "    pct_change_low_over_open = (data_raw['Low']-data_raw['Open'])/data_raw['Open']\n",
        "    pct_change_close = data_raw['Close'].pct_change().fillna(0)\n",
        "    pct_change_close_over_open = (data_raw['Close']-data_raw['Open'])/data_raw['Open']\n",
        "    pct_change_adjclose = data_raw['Adj Close'].pct_change().fillna(0)\n",
        "    pct_change_adjclose_over_open = (data_raw['Adj Close']-data_raw['Open'])/data_raw['Open']\n",
        "    pct_change_volume = data_raw['Volume'].pct_change().fillna(0)\n",
        "\n",
        "    # Prepare labels: 2 means the close price of tomorow is higher than today's close price; 1 is down; 0 means the movement is between up_threshold and down_threshold\n",
        "    label = np.where(pct_change_close > up_threshold, 2, np.where(pct_change_close < down_threshold, 1, 0))[1:]\n",
        "    label = np.append(label, 0)\n",
        "\n",
        "    # Construct a data_norm data frame\n",
        "    data_norm = pd.DataFrame({'Open_norm':pct_change_open,\n",
        "                              'High_norm':pct_change_high,\n",
        "                              'Low_norm': pct_change_low,\n",
        "                              'Close_norm':pct_change_close,\n",
        "                              'Volume_norm':pct_change_volume,\n",
        "                              'High-Open_norm':pct_change_high_over_open,\n",
        "                              'Low-Open_norm':pct_change_low_over_open,\n",
        "                              'Close-Open_norm':pct_change_close_over_open,\n",
        "                              'Label_2up1down':label})\n",
        "\n",
        "    # Normalize by min-max normalization after the pct normalization\n",
        "    data_norm['Open_norm'] = data_norm['Open_norm'].apply(lambda x: (x - data_norm['Open_norm'].min()) / (data_norm['Open_norm'].max() - data_norm['Open_norm'].min()))\n",
        "    data_norm['High_norm'] = data_norm['High_norm'].apply(lambda x: (x - data_norm['High_norm'].min()) / (data_norm['High_norm'].max() - data_norm['High_norm'].min()))\n",
        "    data_norm['Low_norm'] = data_norm['Low_norm'].apply(lambda x: (x - data_norm['Low_norm'].min()) / (data_norm['Low_norm'].max() - data_norm['Low_norm'].min()))\n",
        "    data_norm['Close_norm'] = data_norm['Close_norm'].apply(lambda x: (x - data_norm['Close_norm'].min()) / (data_norm['Close_norm'].max() - data_norm['Close_norm'].min()))\n",
        "    data_norm['Volume_norm'] = data_norm['Volume_norm'].apply(lambda x: (x - data_norm['Volume_norm'].min()) / (data_norm['Volume_norm'].max() - data_norm['Volume_norm'].min()))\n",
        "    data_norm['High-Open_norm'] = data_norm['High-Open_norm'].apply(lambda x: (x - data_norm['High-Open_norm'].min()) / (data_norm['High-Open_norm'].max() - data_norm['High-Open_norm'].min()))\n",
        "    data_norm['Low-Open_norm'] = data_norm['Low-Open_norm'].apply(lambda x: (x - data_norm['Low-Open_norm'].min()) / (data_norm['Low-Open_norm'].max() - data_norm['Low-Open_norm'].min()))\n",
        "    data_norm['Close-Open_norm'] = data_norm['Close-Open_norm'].apply(lambda x: (x - data_norm['Close-Open_norm'].min()) / (data_norm['Close-Open_norm'].max() - data_norm['Close-Open_norm'].min()))\n",
        "\n",
        "    # Remove the first and the last row, becuase of NAN values\n",
        "    data_raw = data_raw.iloc[1:-1]\n",
        "    data_norm = data_norm.iloc[1:-1]\n",
        "\n",
        "    data_raw.to_csv(EXPORT_DATA_FOLDER+symbol+'_raw_data.csv', index=True)\n",
        "    data_norm.to_csv(EXPORT_DATA_FOLDER+symbol+'_norm_data.csv', index=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044f2161",
      "metadata": {
        "id": "044f2161"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9ac476c4",
      "metadata": {
        "id": "9ac476c4"
      },
      "source": [
        "## TODO "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01cc7891",
      "metadata": {
        "id": "01cc7891"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "(2023-06-05)\n",
        "cuda support check\n",
        "//read textual data into correct shape\n",
        "hyperparam tuning: number of neurons: tune to right number of neurons in FC in model\n",
        "//max_text_per_iter -> code in dataloader to maintain the size \n",
        "\n",
        "(2023-06-07)\n",
        "cuda check\n",
        "roberta encoder fix\n",
        "multi label - how to create target label?\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1b8731",
      "metadata": {
        "id": "0f1b8731"
      },
      "source": [
        "## Prep textual data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a8a06ae3",
      "metadata": {
        "id": "a8a06ae3"
      },
      "outputs": [],
      "source": [
        "text_data_df = pd.read_csv('./data/XOM_20200401_20230401_medium.csv', sep= ',', header= 0)\n",
        "text_data_df = text_data_df[['Date', 'News']]\n",
        "\n",
        "\n",
        "text_data_df = text_data_df.groupby('Date')['News'].apply('$$$###'.join)\n",
        "\n",
        "text_data_df.index = pd.to_datetime(text_data_df.index, dayfirst=True)\n",
        "# text_data_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3155ea81",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3155ea81",
        "outputId": "287c3a45-dd03-4bee-dcdc-e40dab736321"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Open_norm  High_norm  Low_norm  Close_norm  Volume_norm  \\\n",
              "Date                                                                  \n",
              "2020-04-01   0.424588   0.325630  0.445426    0.444210     0.187485   \n",
              "2020-04-02   0.778879   0.795313  0.736065    0.797702     0.445139   \n",
              "2020-04-03   0.853804   0.435964  0.626517    0.372487     0.160943   \n",
              "2020-04-06   0.427455   0.266519  0.635065    0.619722     0.182685   \n",
              "2020-04-07   0.876632   0.689534  0.761913    0.567103     0.283049   \n",
              "...               ...        ...       ...         ...          ...   \n",
              "2022-12-23   0.542767   0.435239  0.669969    0.596883     0.188873   \n",
              "2022-12-27   0.662985   0.484486  0.633508    0.546500     0.238297   \n",
              "2022-12-28   0.600374   0.392759  0.523834    0.424789     0.195329   \n",
              "2022-12-29   0.508146   0.400534  0.562507    0.521098     0.222456   \n",
              "2022-12-30   0.599916   0.444452  0.582740    0.531163     0.263573   \n",
              "\n",
              "            High-Open_norm  Low-Open_norm  Close-Open_norm  Label_2up1down  \\\n",
              "Date                                                                         \n",
              "2020-04-01        0.493448       0.887338         0.568367               2   \n",
              "2020-04-02        0.821628       0.826839         0.730773               1   \n",
              "2020-04-03        0.174091       0.435487         0.093004               2   \n",
              "2020-04-06        0.235477       0.869836         0.546103               2   \n",
              "2020-04-07        0.096776       0.676091         0.194020               2   \n",
              "...                    ...            ...              ...             ...   \n",
              "2022-12-23        0.165444       0.996267         0.555196               0   \n",
              "2022-12-27        0.108558       0.967843         0.504141               1   \n",
              "2022-12-28        0.008094       0.853954         0.357091               0   \n",
              "2022-12-29        0.158359       1.000000         0.522474               0   \n",
              "2022-12-30        0.172017       1.000000         0.551144               1   \n",
              "\n",
              "                                                         News  \n",
              "Date                                                           \n",
              "2020-04-01  Global Polymers Market, By Type (Thermoplastic...  \n",
              "2020-04-02  European Morning Briefing: U.S. Jobs Report Ey...  \n",
              "2020-04-03  Nordic Morning Briefing: Services PMI Data in ...  \n",
              "2020-04-06   圖表 Texas Takes Two Punches -- Oil Shock and O...  \n",
              "2020-04-07  Exxon Cuts Capital Spending by 30% in Response...  \n",
              "...                                                       ...  \n",
              "2022-12-23  Energy Transfer's Gulf Run gas pipeline gets U...  \n",
              "2022-12-27  Butadiene Market, By Application (Polybutadien...  \n",
              "2022-12-28  Exxon sues EU in move to block new windfall ta...  \n",
              "2022-12-29  Global Car Care Products Market 2023-2027 Publ...  \n",
              "2022-12-30  Global Polypropylene Nonwoven Fabric Market 20...  \n",
              "\n",
              "[694 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74a2617f-1d41-421d-bedc-4e63d37846c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open_norm</th>\n",
              "      <th>High_norm</th>\n",
              "      <th>Low_norm</th>\n",
              "      <th>Close_norm</th>\n",
              "      <th>Volume_norm</th>\n",
              "      <th>High-Open_norm</th>\n",
              "      <th>Low-Open_norm</th>\n",
              "      <th>Close-Open_norm</th>\n",
              "      <th>Label_2up1down</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-04-01</th>\n",
              "      <td>0.424588</td>\n",
              "      <td>0.325630</td>\n",
              "      <td>0.445426</td>\n",
              "      <td>0.444210</td>\n",
              "      <td>0.187485</td>\n",
              "      <td>0.493448</td>\n",
              "      <td>0.887338</td>\n",
              "      <td>0.568367</td>\n",
              "      <td>2</td>\n",
              "      <td>Global Polymers Market, By Type (Thermoplastic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-02</th>\n",
              "      <td>0.778879</td>\n",
              "      <td>0.795313</td>\n",
              "      <td>0.736065</td>\n",
              "      <td>0.797702</td>\n",
              "      <td>0.445139</td>\n",
              "      <td>0.821628</td>\n",
              "      <td>0.826839</td>\n",
              "      <td>0.730773</td>\n",
              "      <td>1</td>\n",
              "      <td>European Morning Briefing: U.S. Jobs Report Ey...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-03</th>\n",
              "      <td>0.853804</td>\n",
              "      <td>0.435964</td>\n",
              "      <td>0.626517</td>\n",
              "      <td>0.372487</td>\n",
              "      <td>0.160943</td>\n",
              "      <td>0.174091</td>\n",
              "      <td>0.435487</td>\n",
              "      <td>0.093004</td>\n",
              "      <td>2</td>\n",
              "      <td>Nordic Morning Briefing: Services PMI Data in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-06</th>\n",
              "      <td>0.427455</td>\n",
              "      <td>0.266519</td>\n",
              "      <td>0.635065</td>\n",
              "      <td>0.619722</td>\n",
              "      <td>0.182685</td>\n",
              "      <td>0.235477</td>\n",
              "      <td>0.869836</td>\n",
              "      <td>0.546103</td>\n",
              "      <td>2</td>\n",
              "      <td>圖表 Texas Takes Two Punches -- Oil Shock and O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-07</th>\n",
              "      <td>0.876632</td>\n",
              "      <td>0.689534</td>\n",
              "      <td>0.761913</td>\n",
              "      <td>0.567103</td>\n",
              "      <td>0.283049</td>\n",
              "      <td>0.096776</td>\n",
              "      <td>0.676091</td>\n",
              "      <td>0.194020</td>\n",
              "      <td>2</td>\n",
              "      <td>Exxon Cuts Capital Spending by 30% in Response...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-23</th>\n",
              "      <td>0.542767</td>\n",
              "      <td>0.435239</td>\n",
              "      <td>0.669969</td>\n",
              "      <td>0.596883</td>\n",
              "      <td>0.188873</td>\n",
              "      <td>0.165444</td>\n",
              "      <td>0.996267</td>\n",
              "      <td>0.555196</td>\n",
              "      <td>0</td>\n",
              "      <td>Energy Transfer's Gulf Run gas pipeline gets U...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-27</th>\n",
              "      <td>0.662985</td>\n",
              "      <td>0.484486</td>\n",
              "      <td>0.633508</td>\n",
              "      <td>0.546500</td>\n",
              "      <td>0.238297</td>\n",
              "      <td>0.108558</td>\n",
              "      <td>0.967843</td>\n",
              "      <td>0.504141</td>\n",
              "      <td>1</td>\n",
              "      <td>Butadiene Market, By Application (Polybutadien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-28</th>\n",
              "      <td>0.600374</td>\n",
              "      <td>0.392759</td>\n",
              "      <td>0.523834</td>\n",
              "      <td>0.424789</td>\n",
              "      <td>0.195329</td>\n",
              "      <td>0.008094</td>\n",
              "      <td>0.853954</td>\n",
              "      <td>0.357091</td>\n",
              "      <td>0</td>\n",
              "      <td>Exxon sues EU in move to block new windfall ta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-29</th>\n",
              "      <td>0.508146</td>\n",
              "      <td>0.400534</td>\n",
              "      <td>0.562507</td>\n",
              "      <td>0.521098</td>\n",
              "      <td>0.222456</td>\n",
              "      <td>0.158359</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.522474</td>\n",
              "      <td>0</td>\n",
              "      <td>Global Car Care Products Market 2023-2027 Publ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-12-30</th>\n",
              "      <td>0.599916</td>\n",
              "      <td>0.444452</td>\n",
              "      <td>0.582740</td>\n",
              "      <td>0.531163</td>\n",
              "      <td>0.263573</td>\n",
              "      <td>0.172017</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.551144</td>\n",
              "      <td>1</td>\n",
              "      <td>Global Polypropylene Nonwoven Fabric Market 20...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>694 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74a2617f-1d41-421d-bedc-4e63d37846c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-74a2617f-1d41-421d-bedc-4e63d37846c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-74a2617f-1d41-421d-bedc-4e63d37846c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "all_train_df = data_norm.join(text_data_df, how = 'inner')\n",
        "all_train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "56e91800",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56e91800",
        "outputId": "3c57a715-44b7-4117-e829-b8b1e3432dcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "all_train = all_train_df.values\n",
        "\n",
        "window_size = no_of_days_to_lookback\n",
        "\n",
        "X_numerical_train = []\n",
        "y_train = []\n",
        "X_text_train = []\n",
        "X_text_train_curr = []\n",
        "\n",
        "\n",
        "for i in range(window_size, len(all_train) - no_of_days_to_lookforward + 1):\n",
        "    X_numerical_train.append(all_train[i-window_size: i, :-2])\n",
        "    \n",
        "    # split and append sequence of text\n",
        "    curr_seq = all_train[i-window_size: i, -1]\n",
        "    for j in range(window_size):\n",
        "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
        "        X_text_train_curr = X_text_train_curr + split_curr_seq\n",
        "    \n",
        "    if len(X_text_train_curr) > max_text_per_iter:\n",
        "        X_text_train_curr = X_text_train_curr[:max_text_per_iter]\n",
        "    \n",
        "    X_text_train.append(X_text_train_curr)\n",
        "        \n",
        "    # target labels\n",
        "    y_train.append(all_train[i:i+no_of_days_to_lookforward, -2])\n",
        "\n",
        "X_numerical_train, y_train = np.array(X_numerical_train).astype(np.float16), np.array(y_train).astype(np.int32)\n",
        "print(type(X_numerical_train))\n",
        "print(type(y_train))\n",
        "\n",
        "X_numerical_train = torch.from_numpy(X_numerical_train).type(torch.Tensor)\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e404c5e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e404c5e2",
        "outputId": "6bb477fd-8e36-4d9e-94b3-c29302819fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "689\n",
            "689\n",
            "689\n",
            "torch.Size([689, 5, 8])\n"
          ]
        }
      ],
      "source": [
        "print(len(X_numerical_train))\n",
        "print(len(X_text_train))\n",
        "print(len(y_train))\n",
        "print(X_numerical_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "745ef2ef",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "745ef2ef",
        "outputId": "e3288a68-65b7-4036-81ec-eacd8a379922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "689\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "print(len(X_text_train))\n",
        "print(len(X_text_train[2]))\n",
        "# print(X_text_train[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90dc1ed8",
      "metadata": {
        "id": "90dc1ed8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b5b453b0",
      "metadata": {
        "id": "b5b453b0"
      },
      "source": [
        "## Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dc5998e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "8c7c3a6b6d1a4642bc5f4503be04e0ca",
            "2d82da33f32b4054b9600c699d496825",
            "470f74d8aa694f1187e84a4b9b404a2b",
            "4126bc1ac18940dc9bfa4b8caa7c5c2b",
            "a5f14796059d42a8b3cacdc0d63efabc",
            "1b9e43395e9349d292556f9205584311",
            "94a23a65225343d2a5fdc529ff60b52d",
            "9e57ba525e9b46c09af41166fbd677aa",
            "6b28748c58114cc99b5080f31c1bf1d8",
            "7464d262662d442ab1b70af8ba97bcc2",
            "8c5c1f7f880847d2a798e2fa9199c6f3",
            "bcea816cb13f4e83944c0677ad534421",
            "065d56c744bf46c98ff5b8c0f58fe902",
            "ba71ae99f9bc46afbe3ed18569b8194c",
            "e3e0b6c1cb1c4aab988dbfa2a8a5db3d",
            "0b38aab2492d4c5ab3974c328341f002",
            "1ac74024b3b44cc4bd60d0bb108249eb",
            "37746a0c303b410c973283c53a99ab84",
            "8dc88cead5054337a48421bf3b630fb6",
            "f7903d3e955a4270bddc87874a5635c8",
            "f6ed8ed8164d46a5a0db1027504442ac",
            "fc217683da604572a2293f0e640b72e7",
            "8711220981c44cc4a608933cc945226d",
            "3b30cf9917504d0cb797951e5c3a2e2f",
            "41944f7727ef40308eccf8410af1a7bc",
            "b42e45f4d4ed4eeb9d88a73375ce4e12",
            "00c946d4ed2e4eb991758a021ef73df5",
            "e22bc3f6dc79410099072fe23d7dde29",
            "0aa5b1650da6467b8d559b5dbb4b75cd",
            "69bf5f1e12e84e769b8b021a7aab4da5",
            "3bd9b4e592484443855b93f1b52af368",
            "5c9b355bb8c54289922b7c188d3f6914",
            "e479c1a42cfa40dcbbb6523aaa862d69"
          ]
        },
        "id": "dc5998e6",
        "outputId": "369785ff-a3e9-471f-968b-677dd7c09abd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c7c3a6b6d1a4642bc5f4503be04e0ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bcea816cb13f4e83944c0677ad534421"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8711220981c44cc4a608933cc945226d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
        "\n",
        "class SiameseDataloader(Dataset):\n",
        "    \n",
        "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
        "        self.X_numerical_train = X_numerical_train\n",
        "        self.X_text_train = X_text_train\n",
        "        self.MAX_LEN = MAX_LEN\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        \n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "        token_type_ids = []\n",
        "        input_seq = []\n",
        "\n",
        "        for sent in X_text_train[index]:\n",
        "            encoded_sent = self.tokenizer.encode_plus(\n",
        "                text=sent,\n",
        "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
        "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
        "                pad_to_max_length=True,         # Pad sentence to max length \n",
        "                #return_attention_mask=True      # Return attention mask\n",
        "                return_token_type_ids=True\n",
        "                )\n",
        "            input_ids.append(encoded_sent.get('input_ids'))\n",
        "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
        "\n",
        "        # Convert lists to tensors\n",
        "        input_ids = torch.tensor(input_ids)\n",
        "        attention_masks = torch.tensor(attention_masks)\n",
        "        token_type_ids = torch.tensor(token_type_ids)\n",
        "\n",
        "\n",
        "        return {\n",
        "            'x_numerical': X_numerical_train[index],\n",
        "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(y_train[index], dtype=torch.long)\n",
        "        }\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_numerical_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "28f5fe04",
      "metadata": {
        "id": "28f5fe04"
      },
      "outputs": [],
      "source": [
        "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ffaf95",
      "metadata": {
        "id": "47ffaf95"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534fa3fa",
      "metadata": {
        "id": "534fa3fa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0cda822",
      "metadata": {
        "id": "c0cda822"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bd1b75e",
      "metadata": {
        "id": "5bd1b75e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a942555c",
      "metadata": {
        "id": "a942555c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a236ebbb",
      "metadata": {
        "id": "a236ebbb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7bd91c9",
      "metadata": {
        "id": "b7bd91c9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c16bd7f",
      "metadata": {
        "id": "5c16bd7f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ea6ee1e",
      "metadata": {
        "id": "7ea6ee1e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bcf87d32",
      "metadata": {
        "id": "bcf87d32"
      },
      "source": [
        "## Build model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e4e33819",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4e33819",
        "outputId": "2eadeddc-19aa-4d90-8a95-3c32621acbdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "class SiameseModel(nn.Module):\n",
        "    def __init__(self, input_dim1, input_dim2, \n",
        "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
        "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
        "        super(SiameseModel, self).__init__()\n",
        "        self.input_dim1 = input_dim1\n",
        "        self.input_dim2 = input_dim2\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.hidden_dim3 = hidden_dim3\n",
        "        self.hidden_dim4 = hidden_dim4\n",
        "        self.num_layers1 = num_layers1\n",
        "        self.num_layers2 = num_layers2\n",
        "        self.output_dim1 = output_dim1\n",
        "        self.output_dim2 = output_dim2\n",
        "        \n",
        "        \n",
        "\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
        "        \n",
        "        \n",
        "        self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(input_dim2, hidden_dim2, num_layers2, batch_first=True)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim2, output_dim2)\n",
        "        self.fc3 = nn.Linear(output_dim1+output_dim2, hidden_dim3)\n",
        "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
        "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x1, ids, masks, token_type_ids):\n",
        "        #left tower with numerical features\n",
        "        \n",
        "        h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
        "        h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
        "        out1 = self.fc1(h_out1)\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "        # right tower with roberta on textual features  \n",
        "        #TODO\n",
        "        e2 = torch.zeros(1,max_text_per_iter,1024).to(device)\n",
        "        \n",
        "        for k in range(ids.shape[1]):\n",
        "            seq_ids = ids[:,k,:]\n",
        "            seq_masks = masks[:,k,:]\n",
        "            seq_token_type_ids = token_type_ids[:,k,:]\n",
        "\n",
        "\n",
        "            e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
        "\n",
        "            e2k1 = e2k[0][:, 0, :]  #first 0 is for 'CLS' token\n",
        "            e2[:,k,:] = e2k1\n",
        "    \n",
        "    \n",
        "        print(e2.shape)        \n",
        "        h_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
        "        c_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
        "        ula2, (h_out2, _) = self.lstm2(e2, (h_20, c_20))\n",
        "        h_out2 = h_out2.view(-1, self.hidden_dim2)\n",
        "        out2 = self.fc2(h_out2)\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "        # siamese merging layers\n",
        "        \n",
        "        output = torch.cat((out1, out2),1)\n",
        "        output = F.relu(self.fc3(output))\n",
        "        output = F.relu(self.fc4(output))\n",
        "        output = self.fc5(output)\n",
        "        return output\n",
        "    \n",
        "#TODO : correct these values\n",
        "model = SiameseModel(input_dim1 = 8, input_dim2 = 1024, \n",
        "                 hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 128, hidden_dim4 = 64,\n",
        "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256).to(device)\n",
        "\n",
        "\n",
        "    \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33bdcfab",
      "metadata": {
        "id": "33bdcfab"
      },
      "outputs": [],
      "source": [
        "print(model)\n",
        "print(len(list(model.parameters())))\n",
        "# for i in range(len(list(model.parameters()))):\n",
        "#     print(list(model.parameters())[i].size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05f5b46a",
      "metadata": {
        "id": "05f5b46a"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "088c2407",
      "metadata": {
        "id": "088c2407"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_arr = np.zeros(num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "699d13c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "699d13c0",
        "outputId": "ce704638-c27b-4d48-af68-1d8da310d9ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "0it [00:00, ?it/s]<ipython-input-13-d1890b62b243>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'ids': torch.tensor(input_ids, dtype=torch.long),\n",
            "<ipython-input-13-d1890b62b243>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
            "<ipython-input-13-d1890b62b243>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
            "<ipython-input-13-d1890b62b243>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'targets': torch.tensor(y_train[index], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ids shape: torch.Size([8, 20, 10])\n",
            "k: 0\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 1\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 2\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 3\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 4\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 5\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 6\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 7\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 8\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 9\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 10\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 11\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 12\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 13\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 14\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 15\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 16\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 17\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 18\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n",
            "k: 19\n",
            "torch.Size([1, 20, 1024])\n",
            "torch.Size([8, 10, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:02, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0347,  0.0103, -0.0021,  0.0048, -0.0080,  0.0321, -0.0219, -0.0189,\n",
            "          0.0093, -0.0111,  0.0426, -0.0360,  0.0406,  0.0394, -0.0170,  0.0346,\n",
            "         -0.0117,  0.0181, -0.0182,  0.0299, -0.0168, -0.0041, -0.0244,  0.0039,\n",
            "          0.0221, -0.0234,  0.0097,  0.0085,  0.0204, -0.0188,  0.0123, -0.0329,\n",
            "          0.0207,  0.0429, -0.0025, -0.0123, -0.0199,  0.0261, -0.0227,  0.0178,\n",
            "         -0.0400,  0.0064, -0.0291, -0.0080, -0.0205,  0.0204,  0.0135, -0.0148,\n",
            "         -0.0146,  0.0114,  0.0098, -0.0213,  0.0155, -0.0048, -0.0310, -0.0245,\n",
            "          0.0084, -0.0281,  0.0272,  0.0429,  0.0051, -0.0069, -0.0042,  0.0334,\n",
            "          0.0378, -0.0093,  0.0155, -0.0124,  0.0118,  0.0033,  0.0279, -0.0099,\n",
            "         -0.0411, -0.0242, -0.0111,  0.0224,  0.0136, -0.0213, -0.0065, -0.0228,\n",
            "          0.0117,  0.0145, -0.0112, -0.0374,  0.0105,  0.0262,  0.0052,  0.0163,\n",
            "         -0.0189,  0.0100, -0.0271,  0.0071,  0.0228,  0.0172,  0.0181,  0.0441,\n",
            "         -0.0141,  0.0033,  0.0128,  0.0003, -0.0412, -0.0174, -0.0480, -0.0106,\n",
            "          0.0135, -0.0216,  0.0381, -0.0049,  0.0230,  0.0315,  0.0126, -0.0102,\n",
            "          0.0036, -0.0097,  0.0328, -0.0244, -0.0061,  0.0142,  0.0412, -0.0045,\n",
            "          0.0251, -0.0113,  0.0313, -0.0284,  0.0232,  0.0409, -0.0147,  0.0372,\n",
            "         -0.0289, -0.0048, -0.0088, -0.0091, -0.0397,  0.0002, -0.0152, -0.0306,\n",
            "         -0.0195,  0.0312, -0.0209, -0.0096, -0.0290,  0.0015,  0.0179,  0.0010,\n",
            "          0.0155,  0.0139,  0.0069, -0.0022,  0.0072, -0.0346, -0.0468, -0.0035,\n",
            "          0.0100, -0.0080,  0.0237,  0.0202, -0.0020, -0.0175,  0.0081, -0.0279,\n",
            "          0.0206, -0.0199, -0.0079, -0.0194, -0.0293,  0.0228, -0.0287,  0.0130,\n",
            "          0.0029, -0.0076, -0.0124,  0.0031,  0.0314,  0.0003, -0.0026,  0.0209,\n",
            "          0.0125,  0.0296, -0.0136, -0.0185,  0.0213,  0.0191, -0.0253, -0.0185,\n",
            "          0.0402, -0.0226,  0.0355, -0.0319, -0.0161,  0.0080, -0.0099,  0.0058,\n",
            "         -0.0033,  0.0263,  0.0028, -0.0166, -0.0400,  0.0209,  0.0277, -0.0035,\n",
            "         -0.0118,  0.0310, -0.0004, -0.0486, -0.0173,  0.0100,  0.0258,  0.0406,\n",
            "         -0.0491, -0.0031,  0.0226, -0.0139, -0.0188, -0.0295, -0.0220, -0.0300,\n",
            "         -0.0272,  0.0335,  0.0060,  0.0118, -0.0201,  0.0158, -0.0343,  0.0017,\n",
            "          0.0291,  0.0238, -0.0142, -0.0194,  0.0355,  0.0049, -0.0129, -0.0048,\n",
            "          0.0144, -0.0150,  0.0195,  0.0380, -0.0248, -0.0093,  0.0042,  0.0142,\n",
            "         -0.0015,  0.0322,  0.0119, -0.0023,  0.0159,  0.0378,  0.0254,  0.0114,\n",
            "         -0.0088, -0.0132,  0.0073, -0.0098,  0.0199,  0.0065, -0.0034, -0.0249]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-174cafca6446>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_numerical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'y_pred:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-66af5cb875f8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, ids, masks, token_type_ids)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0me2k1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me2k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m#first 0 is for 'CLS' token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0me2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me2k1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (1) must match the existing size (8) at non-singleton dimension 0.  Target sizes: [1, 1024].  Tensor sizes: [8, 1024]"
          ]
        }
      ],
      "source": [
        "roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
        "train_loss_record = []\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = []\n",
        "    train_loss_sum = []\n",
        "    \n",
        "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
        "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        masks = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        # debugging roberta encoder and second lstm\n",
        "        '''\n",
        "        debug starts here\n",
        "        '''\n",
        "        if idx > 1:\n",
        "            break\n",
        "        batch_size_here = data['ids'].shape[0]\n",
        "        print('batch_size_here:', batch_size_here)\n",
        "        e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
        "        print('ids shape:', ids.shape)\n",
        "        \n",
        "        for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
        "            print('k:', k)\n",
        "            seq_ids = ids[:,k,:].to(device)\n",
        "            seq_masks = masks[:,k,:].to(device)\n",
        "            seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
        "\n",
        "\n",
        "            e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
        "            print(e2.shape)\n",
        "            print(e2k[1].shape)\n",
        "            #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
        "            # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
        "            e2k1 = e2k[0][:, 0, :]  \n",
        "            e2[:,k,:] = e2k1\n",
        "    \n",
        "    \n",
        "        \n",
        "\n",
        "        lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
        "        fc2 = nn.Linear(768, 256)\n",
        "\n",
        "        h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
        "        c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
        "        ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
        "        h_out2 = h_out2.view(-1, 768)\n",
        "        out2 = fc2(h_out2)\n",
        "        \n",
        "\n",
        "    #     print(ids.shape)\n",
        "    #     print(masks.shape)\n",
        "    #     print(token_type_ids.shape)\n",
        "    \n",
        "        print(out2)\n",
        "\n",
        "\n",
        "        \n",
        "        '''\n",
        "        debug ends here\n",
        "        '''\n",
        "        \n",
        "\n",
        "    \n",
        "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
        "        print('y_pred:', y_pred)\n",
        "        loss = criterion(y_pred, targets.reshape(-1))\n",
        "        \n",
        "         # Zero out gradient, else they will accumulate between epochs\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update parameters\n",
        "        optimiser.step()\n",
        "        \n",
        "        \n",
        "        \n",
        "        train_loss.append(loss.data.cpu())\n",
        "        train_loss_sum.append(loss.data.cpu())\n",
        "        \n",
        "        if epoch % 10 == 0 and epoch !=0:\n",
        "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())\n",
        "            \n",
        "            \n",
        "#         if ((idx + 1) % 50) == 0:\n",
        "#             print(train_log_string % (datetime.now(), epoch, idx + 1, len(train), np.mean(train_loss)))\n",
        "#             train_loss = []\n",
        "                \n",
        "                \n",
        "#         loss_arr[epoch] = loss.item()\n",
        "        wandb.log({'avg loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
        "\n",
        "       \n",
        "    \n",
        "    # Record at every epoch\n",
        "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
        "    train_loss_record.append(np.mean(train_loss_sum))\n",
        "    wandb.log({'avg loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
        "\n",
        "            \n",
        "    \n",
        "        \n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "bb6bbec1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb6bbec1",
        "outputId": "2d9cf132-d73c-449d-a9f9-c0c6d62f71dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 10, 1024])\n",
            "torch.Size([8, 1024])\n",
            "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0589,  0.0271,  0.0038,  ..., -0.0061,  0.1218,  0.0452],\n",
            "         [-0.0107, -0.3682, -0.4580,  ...,  0.0408, -0.1197, -0.3368],\n",
            "         [ 0.0166, -0.0007, -0.3236,  ...,  0.0483, -0.1545, -0.3394],\n",
            "         ...,\n",
            "         [ 0.0095,  0.0630, -0.2020,  ..., -0.2553,  0.3228, -0.0762],\n",
            "         [ 0.1974, -0.3321, -0.0183,  ..., -0.0484,  0.4155,  0.2522],\n",
            "         [-0.0343,  0.0405,  0.0157,  ..., -0.0327,  0.0948,  0.0205]],\n",
            "\n",
            "        [[-0.0589,  0.0271,  0.0038,  ..., -0.0061,  0.1218,  0.0452],\n",
            "         [-0.0107, -0.3682, -0.4580,  ...,  0.0408, -0.1197, -0.3368],\n",
            "         [ 0.0166, -0.0007, -0.3236,  ...,  0.0483, -0.1545, -0.3394],\n",
            "         ...,\n",
            "         [ 0.0095,  0.0630, -0.2020,  ..., -0.2553,  0.3228, -0.0762],\n",
            "         [ 0.1974, -0.3321, -0.0183,  ..., -0.0484,  0.4155,  0.2522],\n",
            "         [-0.0343,  0.0405,  0.0157,  ..., -0.0327,  0.0948,  0.0205]],\n",
            "\n",
            "        [[-0.0589,  0.0271,  0.0038,  ..., -0.0061,  0.1218,  0.0452],\n",
            "         [-0.0107, -0.3682, -0.4580,  ...,  0.0408, -0.1197, -0.3368],\n",
            "         [ 0.0166, -0.0007, -0.3236,  ...,  0.0483, -0.1545, -0.3394],\n",
            "         ...,\n",
            "         [ 0.0095,  0.0630, -0.2020,  ..., -0.2553,  0.3228, -0.0762],\n",
            "         [ 0.1974, -0.3321, -0.0183,  ..., -0.0484,  0.4155,  0.2522],\n",
            "         [-0.0343,  0.0405,  0.0157,  ..., -0.0327,  0.0948,  0.0205]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.0589,  0.0271,  0.0038,  ..., -0.0061,  0.1218,  0.0452],\n",
            "         [-0.0107, -0.3682, -0.4580,  ...,  0.0408, -0.1197, -0.3368],\n",
            "         [ 0.0166, -0.0007, -0.3236,  ...,  0.0483, -0.1545, -0.3394],\n",
            "         ...,\n",
            "         [ 0.0095,  0.0630, -0.2020,  ..., -0.2553,  0.3228, -0.0762],\n",
            "         [ 0.1974, -0.3321, -0.0183,  ..., -0.0484,  0.4155,  0.2522],\n",
            "         [-0.0343,  0.0405,  0.0157,  ..., -0.0327,  0.0948,  0.0205]],\n",
            "\n",
            "        [[-0.0589,  0.0271,  0.0038,  ..., -0.0061,  0.1218,  0.0452],\n",
            "         [-0.0107, -0.3682, -0.4580,  ...,  0.0408, -0.1197, -0.3368],\n",
            "         [ 0.0166, -0.0007, -0.3236,  ...,  0.0483, -0.1545, -0.3394],\n",
            "         ...,\n",
            "         [ 0.0095,  0.0630, -0.2020,  ..., -0.2553,  0.3228, -0.0762],\n",
            "         [ 0.1974, -0.3321, -0.0183,  ..., -0.0484,  0.4155,  0.2522],\n",
            "         [-0.0343,  0.0405,  0.0157,  ..., -0.0327,  0.0948,  0.0205]],\n",
            "\n",
            "        [[-0.0589,  0.0271,  0.0038,  ..., -0.0061,  0.1218,  0.0452],\n",
            "         [-0.0107, -0.3682, -0.4580,  ...,  0.0408, -0.1197, -0.3368],\n",
            "         [ 0.0166, -0.0007, -0.3236,  ...,  0.0483, -0.1545, -0.3394],\n",
            "         ...,\n",
            "         [ 0.0095,  0.0630, -0.2020,  ..., -0.2553,  0.3228, -0.0762],\n",
            "         [ 0.1974, -0.3321, -0.0183,  ..., -0.0484,  0.4155,  0.2522],\n",
            "         [-0.0343,  0.0405,  0.0157,  ..., -0.0327,  0.0948,  0.0205]]],\n",
            "       device='cuda:0', grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[ 0.5462,  0.0489, -0.6189,  ..., -0.0547,  0.9020,  0.0476],\n",
            "        [ 0.5462,  0.0489, -0.6189,  ..., -0.0547,  0.9020,  0.0476],\n",
            "        [ 0.5462,  0.0489, -0.6189,  ..., -0.0547,  0.9020,  0.0476],\n",
            "        ...,\n",
            "        [ 0.5462,  0.0489, -0.6189,  ..., -0.0547,  0.9020,  0.0476],\n",
            "        [ 0.5462,  0.0489, -0.6189,  ..., -0.0547,  0.9020,  0.0476],\n",
            "        [ 0.5462,  0.0489, -0.6189,  ..., -0.0547,  0.9020,  0.0476]],\n",
            "       device='cuda:0', grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ],
      "source": [
        "print(e2k[0].shape)\n",
        "print(e2k[1].shape)\n",
        "print(e2k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aac5f8f",
      "metadata": {
        "id": "4aac5f8f",
        "outputId": "003ebc43-ca7b-468f-8b9d-3249ac5c5223"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1370,  0.0461, -0.1471]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1122c8c",
      "metadata": {
        "id": "e1122c8c",
        "outputId": "8e7d8934-7b49-4c72-c7b1-7928f9dc0e36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "targets.reshape(-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3049d3f4",
      "metadata": {
        "id": "3049d3f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1807d2b1",
      "metadata": {
        "id": "1807d2b1"
      },
      "outputs": [],
      "source": [
        "plt.plot(loss_arr, label=\"Training loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf315ee",
      "metadata": {
        "id": "2cf315ee"
      },
      "outputs": [],
      "source": [
        "\n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c7c3a6b6d1a4642bc5f4503be04e0ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d82da33f32b4054b9600c699d496825",
              "IPY_MODEL_470f74d8aa694f1187e84a4b9b404a2b",
              "IPY_MODEL_4126bc1ac18940dc9bfa4b8caa7c5c2b"
            ],
            "layout": "IPY_MODEL_a5f14796059d42a8b3cacdc0d63efabc"
          }
        },
        "2d82da33f32b4054b9600c699d496825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b9e43395e9349d292556f9205584311",
            "placeholder": "​",
            "style": "IPY_MODEL_94a23a65225343d2a5fdc529ff60b52d",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "470f74d8aa694f1187e84a4b9b404a2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e57ba525e9b46c09af41166fbd677aa",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b28748c58114cc99b5080f31c1bf1d8",
            "value": 898823
          }
        },
        "4126bc1ac18940dc9bfa4b8caa7c5c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7464d262662d442ab1b70af8ba97bcc2",
            "placeholder": "​",
            "style": "IPY_MODEL_8c5c1f7f880847d2a798e2fa9199c6f3",
            "value": " 899k/899k [00:00&lt;00:00, 4.23MB/s]"
          }
        },
        "a5f14796059d42a8b3cacdc0d63efabc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b9e43395e9349d292556f9205584311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94a23a65225343d2a5fdc529ff60b52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e57ba525e9b46c09af41166fbd677aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b28748c58114cc99b5080f31c1bf1d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7464d262662d442ab1b70af8ba97bcc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c5c1f7f880847d2a798e2fa9199c6f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcea816cb13f4e83944c0677ad534421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_065d56c744bf46c98ff5b8c0f58fe902",
              "IPY_MODEL_ba71ae99f9bc46afbe3ed18569b8194c",
              "IPY_MODEL_e3e0b6c1cb1c4aab988dbfa2a8a5db3d"
            ],
            "layout": "IPY_MODEL_0b38aab2492d4c5ab3974c328341f002"
          }
        },
        "065d56c744bf46c98ff5b8c0f58fe902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac74024b3b44cc4bd60d0bb108249eb",
            "placeholder": "​",
            "style": "IPY_MODEL_37746a0c303b410c973283c53a99ab84",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "ba71ae99f9bc46afbe3ed18569b8194c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dc88cead5054337a48421bf3b630fb6",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7903d3e955a4270bddc87874a5635c8",
            "value": 456318
          }
        },
        "e3e0b6c1cb1c4aab988dbfa2a8a5db3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6ed8ed8164d46a5a0db1027504442ac",
            "placeholder": "​",
            "style": "IPY_MODEL_fc217683da604572a2293f0e640b72e7",
            "value": " 456k/456k [00:00&lt;00:00, 1.08MB/s]"
          }
        },
        "0b38aab2492d4c5ab3974c328341f002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac74024b3b44cc4bd60d0bb108249eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37746a0c303b410c973283c53a99ab84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc88cead5054337a48421bf3b630fb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7903d3e955a4270bddc87874a5635c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f6ed8ed8164d46a5a0db1027504442ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc217683da604572a2293f0e640b72e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8711220981c44cc4a608933cc945226d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b30cf9917504d0cb797951e5c3a2e2f",
              "IPY_MODEL_41944f7727ef40308eccf8410af1a7bc",
              "IPY_MODEL_b42e45f4d4ed4eeb9d88a73375ce4e12"
            ],
            "layout": "IPY_MODEL_00c946d4ed2e4eb991758a021ef73df5"
          }
        },
        "3b30cf9917504d0cb797951e5c3a2e2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e22bc3f6dc79410099072fe23d7dde29",
            "placeholder": "​",
            "style": "IPY_MODEL_0aa5b1650da6467b8d559b5dbb4b75cd",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "41944f7727ef40308eccf8410af1a7bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69bf5f1e12e84e769b8b021a7aab4da5",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bd9b4e592484443855b93f1b52af368",
            "value": 482
          }
        },
        "b42e45f4d4ed4eeb9d88a73375ce4e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9b355bb8c54289922b7c188d3f6914",
            "placeholder": "​",
            "style": "IPY_MODEL_e479c1a42cfa40dcbbb6523aaa862d69",
            "value": " 482/482 [00:00&lt;00:00, 38.9kB/s]"
          }
        },
        "00c946d4ed2e4eb991758a021ef73df5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e22bc3f6dc79410099072fe23d7dde29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa5b1650da6467b8d559b5dbb4b75cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69bf5f1e12e84e769b8b021a7aab4da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd9b4e592484443855b93f1b52af368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c9b355bb8c54289922b7c188d3f6914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e479c1a42cfa40dcbbb6523aaa862d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}