{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ff5a093",
      "metadata": {
        "id": "7ff5a093",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ab0f08-2994-4b5c-e676-54093a4b73c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.21)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.22.4)\n",
            "Requirement already satisfied: requests>=2.26 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.27.1)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2022.7.1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26->yfinance) (3.4)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.5-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.27.1-py2.py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=b607e11d9f0a9bb84ef71e35d8b146783ed7a86ec6ca6b119657228d5c4a3f2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.27.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.5\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install transformers\n",
        "!pip install wandb\n",
        "!pip install beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1a3524a9",
      "metadata": {
        "id": "1a3524a9"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import mpl, plt\n",
        "import math, time\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from operator import itemgetter\n",
        "from tqdm import tqdm\n",
        "from math import sqrt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "24afc749",
      "metadata": {
        "id": "24afc749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492956d2-49cf-457f-e96d-f174e6ff9582"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e128245b",
      "metadata": {
        "id": "e128245b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "36a56468-a2d8-4382-de9d-4bb5348e44f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvisriv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230710_024348-lbph1cg4</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/visriv/stock_prediction/runs/lbph1cg4' target=\"_blank\">grateful-cherry-44</a></strong> to <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">https://wandb.ai/visriv/stock_prediction</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/visriv/stock_prediction/runs/lbph1cg4' target=\"_blank\">https://wandb.ai/visriv/stock_prediction/runs/lbph1cg4</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/visriv/stock_prediction/runs/lbph1cg4?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7fc7a25d92d0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login()\n",
        "wandb.init(project=\"stock_prediction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76ea47cc",
      "metadata": {
        "id": "76ea47cc"
      },
      "source": [
        "### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9a8dec6d",
      "metadata": {
        "id": "9a8dec6d"
      },
      "outputs": [],
      "source": [
        "no_of_days_to_lookforward = 1\n",
        "no_of_days_to_lookback = 5\n",
        "up_threshold = 0.015\n",
        "down_threshold = -0.015\n",
        "max_text_per_iter = 20\n",
        "batch_size = 8\n",
        "MAX_LEN = 10\n",
        "num_epochs = 200\n",
        "save_freq_epoch = 10\n",
        "run_id = str(43)\n",
        "output_path = '/content/drive/MyDrive/machine_learning/projects/xai-seq/output/run_' + run_id\n",
        "!mkdir $output_path\n",
        "# !mkdir /content/drive/MyDrive/machine_learning/projects/xai-seq/output/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af59387d",
      "metadata": {
        "id": "af59387d"
      },
      "source": [
        "### Get stocks data for last N days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6ebb836a",
      "metadata": {
        "id": "6ebb836a"
      },
      "outputs": [],
      "source": [
        "!mkdir data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "64983989",
      "metadata": {
        "id": "64983989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0952ff99-96a5-4053-9aaa-cd7b22ad4966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "stock_symbols = [ 'XOM']\n",
        "no_of_days = 4*365\n",
        "\n",
        "EXPORT_DATA_FOLDER = './data/'\n",
        "# !mkdir data\n",
        "# Set the start and end dates for the data\n",
        "# here matching it with dates of news text available\n",
        "train_start = datetime.strptime('2020/01/04', '%Y/%m/%d')\n",
        "train_end = datetime.strptime('2022/09/30', '%Y/%m/%d')\n",
        "test_start = datetime.strptime('2022/10/01', '%Y/%m/%d')\n",
        "test_end = datetime.strptime('2023/01/04', '%Y/%m/%d')\n",
        "\n",
        "\n",
        "# start = datetime.datetime.now() - datetime.timedelta(days=no_of_days)\n",
        "# end = datetime.datetime.now()\n",
        "\n",
        "# Get training data\n",
        "for symbol in stock_symbols:\n",
        "    # Download the historical price and volume data using yfinance\n",
        "    train_data_raw = yf.download(symbol, start=train_start, end=train_end)\n",
        "\n",
        "    # Normalize features by percent of changes between today and yesterday\n",
        "    pct_change_open = train_data_raw['Open'].pct_change().fillna(0)\n",
        "    pct_change_high = train_data_raw['High'].pct_change().fillna(0)\n",
        "    pct_change_high_over_open = (train_data_raw['High']-train_data_raw['Open'])/train_data_raw['Open']\n",
        "    pct_change_low = train_data_raw['Low'].pct_change().fillna(0)\n",
        "    pct_change_low_over_open = (train_data_raw['Low']-train_data_raw['Open'])/train_data_raw['Open']\n",
        "    pct_change_close = train_data_raw['Close'].pct_change().fillna(0)\n",
        "    pct_change_close_over_open = (train_data_raw['Close']-train_data_raw['Open'])/train_data_raw['Open']\n",
        "    pct_change_adjclose = train_data_raw['Adj Close'].pct_change().fillna(0)\n",
        "    pct_change_adjclose_over_open = (train_data_raw['Adj Close']-train_data_raw['Open'])/train_data_raw['Open']\n",
        "    pct_change_volume = train_data_raw['Volume'].pct_change().fillna(0)\n",
        "\n",
        "    # Prepare labels: 2 means the close price of tomorow is higher than today's close price; 1 is down; 0 means the movement is between up_threshold and down_threshold\n",
        "    label = np.where(pct_change_close > up_threshold, 2, np.where(pct_change_close < down_threshold, 1, 0))[1:]\n",
        "    label = np.append(label, 0)\n",
        "\n",
        "    # Construct a train_data_norm data frame\n",
        "    train_data_norm = pd.DataFrame({'Open_norm':pct_change_open,\n",
        "                              'High_norm':pct_change_high,\n",
        "                              'Low_norm': pct_change_low,\n",
        "                              'Close_norm':pct_change_close,\n",
        "                              'Volume_norm':pct_change_volume,\n",
        "                              'High-Open_norm':pct_change_high_over_open,\n",
        "                              'Low-Open_norm':pct_change_low_over_open,\n",
        "                              'Close-Open_norm':pct_change_close_over_open,\n",
        "                              'Label_2up1down':label})\n",
        "\n",
        "    # Normalize by min-max normalization after the pct normalization\n",
        "    train_data_norm['Open_norm'] = train_data_norm['Open_norm'].apply(lambda x: (x - train_data_norm['Open_norm'].min()) / (train_data_norm['Open_norm'].max() - train_data_norm['Open_norm'].min()))\n",
        "    train_data_norm['High_norm'] = train_data_norm['High_norm'].apply(lambda x: (x - train_data_norm['High_norm'].min()) / (train_data_norm['High_norm'].max() - train_data_norm['High_norm'].min()))\n",
        "    train_data_norm['Low_norm'] = train_data_norm['Low_norm'].apply(lambda x: (x - train_data_norm['Low_norm'].min()) / (train_data_norm['Low_norm'].max() - train_data_norm['Low_norm'].min()))\n",
        "    train_data_norm['Close_norm'] = train_data_norm['Close_norm'].apply(lambda x: (x - train_data_norm['Close_norm'].min()) / (train_data_norm['Close_norm'].max() - train_data_norm['Close_norm'].min()))\n",
        "    train_data_norm['Volume_norm'] = train_data_norm['Volume_norm'].apply(lambda x: (x - train_data_norm['Volume_norm'].min()) / (train_data_norm['Volume_norm'].max() - train_data_norm['Volume_norm'].min()))\n",
        "    train_data_norm['High-Open_norm'] = train_data_norm['High-Open_norm'].apply(lambda x: (x - train_data_norm['High-Open_norm'].min()) / (train_data_norm['High-Open_norm'].max() - train_data_norm['High-Open_norm'].min()))\n",
        "    train_data_norm['Low-Open_norm'] = train_data_norm['Low-Open_norm'].apply(lambda x: (x - train_data_norm['Low-Open_norm'].min()) / (train_data_norm['Low-Open_norm'].max() - train_data_norm['Low-Open_norm'].min()))\n",
        "    train_data_norm['Close-Open_norm'] = train_data_norm['Close-Open_norm'].apply(lambda x: (x - train_data_norm['Close-Open_norm'].min()) / (train_data_norm['Close-Open_norm'].max() - train_data_norm['Close-Open_norm'].min()))\n",
        "\n",
        "    # Remove the first and the last row, becuase of NAN values\n",
        "    train_data_raw = train_data_raw.iloc[1:-1]\n",
        "    train_data_norm = train_data_norm.iloc[1:-1]\n",
        "\n",
        "    train_data_raw.to_csv(EXPORT_DATA_FOLDER+symbol+'train_raw_data.csv', index=True)\n",
        "    train_data_norm.to_csv(EXPORT_DATA_FOLDER+symbol+'train_norm_data.csv', index=True)\n",
        "\n",
        "\n",
        "# Get test data\n",
        "for symbol in stock_symbols:\n",
        "    # Download the historical price and volume data using yfinance\n",
        "    test_data_raw = yf.download(symbol, start=test_start, end=test_end)\n",
        "\n",
        "    # Normalize features by percent of changes between today and yesterday\n",
        "    pct_change_open = test_data_raw['Open'].pct_change().fillna(0)\n",
        "    pct_change_high = test_data_raw['High'].pct_change().fillna(0)\n",
        "    pct_change_high_over_open = (test_data_raw['High']-test_data_raw['Open'])/test_data_raw['Open']\n",
        "    pct_change_low = test_data_raw['Low'].pct_change().fillna(0)\n",
        "    pct_change_low_over_open = (test_data_raw['Low']-test_data_raw['Open'])/test_data_raw['Open']\n",
        "    pct_change_close = test_data_raw['Close'].pct_change().fillna(0)\n",
        "    pct_change_close_over_open = (test_data_raw['Close']-test_data_raw['Open'])/test_data_raw['Open']\n",
        "    pct_change_adjclose = test_data_raw['Adj Close'].pct_change().fillna(0)\n",
        "    pct_change_adjclose_over_open = (test_data_raw['Adj Close']-test_data_raw['Open'])/test_data_raw['Open']\n",
        "    pct_change_volume = test_data_raw['Volume'].pct_change().fillna(0)\n",
        "\n",
        "    # Prepare labels: 2 means the close price of tomorow is higher than today's close price; 1 is down; 0 means the movement is between up_threshold and down_threshold\n",
        "    label = np.where(pct_change_close > up_threshold, 2, np.where(pct_change_close < down_threshold, 1, 0))[1:]\n",
        "    label = np.append(label, 0)\n",
        "\n",
        "    # Construct a test_data_norm data frame\n",
        "    test_data_norm = pd.DataFrame({'Open_norm':pct_change_open,\n",
        "                              'High_norm':pct_change_high,\n",
        "                              'Low_norm': pct_change_low,\n",
        "                              'Close_norm':pct_change_close,\n",
        "                              'Volume_norm':pct_change_volume,\n",
        "                              'High-Open_norm':pct_change_high_over_open,\n",
        "                              'Low-Open_norm':pct_change_low_over_open,\n",
        "                              'Close-Open_norm':pct_change_close_over_open,\n",
        "                              'Label_2up1down':label})\n",
        "\n",
        "    # Normalize by min-max normalization after the pct normalization\n",
        "    test_data_norm['Open_norm'] = test_data_norm['Open_norm'].apply(lambda x: (x - test_data_norm['Open_norm'].min()) / (test_data_norm['Open_norm'].max() - test_data_norm['Open_norm'].min()))\n",
        "    test_data_norm['High_norm'] = test_data_norm['High_norm'].apply(lambda x: (x - test_data_norm['High_norm'].min()) / (test_data_norm['High_norm'].max() - test_data_norm['High_norm'].min()))\n",
        "    test_data_norm['Low_norm'] = test_data_norm['Low_norm'].apply(lambda x: (x - test_data_norm['Low_norm'].min()) / (test_data_norm['Low_norm'].max() - test_data_norm['Low_norm'].min()))\n",
        "    test_data_norm['Close_norm'] = test_data_norm['Close_norm'].apply(lambda x: (x - test_data_norm['Close_norm'].min()) / (test_data_norm['Close_norm'].max() - test_data_norm['Close_norm'].min()))\n",
        "    test_data_norm['Volume_norm'] = test_data_norm['Volume_norm'].apply(lambda x: (x - test_data_norm['Volume_norm'].min()) / (test_data_norm['Volume_norm'].max() - test_data_norm['Volume_norm'].min()))\n",
        "    test_data_norm['High-Open_norm'] = test_data_norm['High-Open_norm'].apply(lambda x: (x - test_data_norm['High-Open_norm'].min()) / (test_data_norm['High-Open_norm'].max() - test_data_norm['High-Open_norm'].min()))\n",
        "    test_data_norm['Low-Open_norm'] = test_data_norm['Low-Open_norm'].apply(lambda x: (x - test_data_norm['Low-Open_norm'].min()) / (test_data_norm['Low-Open_norm'].max() - test_data_norm['Low-Open_norm'].min()))\n",
        "    test_data_norm['Close-Open_norm'] = test_data_norm['Close-Open_norm'].apply(lambda x: (x - test_data_norm['Close-Open_norm'].min()) / (test_data_norm['Close-Open_norm'].max() - test_data_norm['Close-Open_norm'].min()))\n",
        "\n",
        "    # Remove the first and the last row, becuase of NAN values\n",
        "    test_data_raw = test_data_raw.iloc[1:-1]\n",
        "    test_data_norm = test_data_norm.iloc[1:-1]\n",
        "\n",
        "    test_data_raw.to_csv(EXPORT_DATA_FOLDER+symbol+'test_raw_data.csv', index=True)\n",
        "    test_data_norm.to_csv(EXPORT_DATA_FOLDER+symbol+'test_norm_data.csv', index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "044f2161",
      "metadata": {
        "id": "044f2161"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "9ac476c4",
      "metadata": {
        "id": "9ac476c4"
      },
      "source": [
        "## TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01cc7891",
      "metadata": {
        "id": "01cc7891"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "(2023-06-05)\n",
        "cuda support check\n",
        "//read textual data into correct shape\n",
        "hyperparam tuning: number of neurons: tune to right number of neurons in FC in model\n",
        "//max_text_per_iter -> code in dataloader to maintain the size\n",
        "\n",
        "(2023-06-07)\n",
        "cuda check\n",
        "roberta encoder fix\n",
        "multi label - how to create target label?\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f1b8731",
      "metadata": {
        "id": "0f1b8731"
      },
      "source": [
        "## Prep textual data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Crawl textual news data from internet"
      ],
      "metadata": {
        "id": "SXhjZ2x4UuT2"
      },
      "id": "SXhjZ2x4UuT2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "from urllib.request import Request\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Parameters\n",
        "n = 3 #the # of article headlines displayed per ticker\n",
        "tickers = ['AAPL', 'TSLA', 'AMZN']\n",
        "\n",
        "\n",
        "\n",
        "# Get Data\n",
        "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
        "news_tables = {}\n",
        "\n",
        "for ticker in tickers:\n",
        "    url = finviz_url + ticker\n",
        "    req = Request(url=url,\n",
        "                  headers={'user-agent': 'Mozilla/5.0',\n",
        "                                   'referer': 'https://...'})\n",
        "    resp = urlopen(req)\n",
        "    html = BeautifulSoup(resp, features=\"lxml\")\n",
        "    news_table = html.find(id='news-table')\n",
        "    news_tables[ticker] = news_table\n",
        "\n",
        "try:\n",
        "    for ticker in tickers:\n",
        "        df = news_tables[ticker]\n",
        "        df_tr = df.findAll('tr')\n",
        "\n",
        "        print ('\\n')\n",
        "        print ('Recent News Headlines for {}: '.format(ticker))\n",
        "\n",
        "        for i, table_row in enumerate(df_tr):\n",
        "            a_text = table_row.a.text\n",
        "            td_text = table_row.td.text\n",
        "            td_text = td_text.strip()\n",
        "            print(a_text,'(',td_text,')')\n",
        "            if i == n-1:\n",
        "                break\n",
        "except KeyError:\n",
        "    pass\n",
        "\n",
        "\n",
        "# Iterate through the news\n",
        "parsed_news = []\n",
        "for file_name, news_table in news_tables.items():\n",
        "    for x in news_table.findAll('tr'):\n",
        "        text = x.a.get_text()\n",
        "        date_scrape = x.td.text.split()\n",
        "\n",
        "        if len(date_scrape) == 1:\n",
        "            time = date_scrape[0]\n",
        "\n",
        "        else:\n",
        "            date = date_scrape[0]\n",
        "            time = date_scrape[1]\n",
        "\n",
        "        ticker = file_name.split('_')[0]\n",
        "\n",
        "        parsed_news.append([ticker, date, time, text])\n",
        "\n"
      ],
      "metadata": {
        "id": "4oOXAgDCUuz_"
      },
      "id": "4oOXAgDCUuz_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Read downloaded data from saved files"
      ],
      "metadata": {
        "id": "yjXll-U6U1fV"
      },
      "id": "yjXll-U6U1fV"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4t4-Er1hFOh7"
      },
      "id": "4t4-Er1hFOh7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a8a06ae3",
      "metadata": {
        "id": "a8a06ae3"
      },
      "outputs": [],
      "source": [
        "text_data_df = pd.read_csv('/content/drive/MyDrive/machine_learning/projects/xai-seq/data/XOM_20200401_20230401_medium.csv',\n",
        "                           sep= ',',\n",
        "                           header= 0,\n",
        "                           engine='python',\n",
        "                           on_bad_lines = 'skip')\n",
        "text_data_df = text_data_df[['Date', 'News']]\n",
        "\n",
        "\n",
        "text_data_df = text_data_df.groupby('Date')['News'].apply('$$$###'.join)\n",
        "\n",
        "text_data_df.index = pd.to_datetime(text_data_df.index, dayfirst=True)\n",
        "# text_data_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3155ea81",
      "metadata": {
        "id": "3155ea81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98d669b-e671-403a-d38c-29b40d4bb3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020-04-01 00:00:00\n",
            "2022-09-28 00:00:00\n",
            "2022-10-04 00:00:00\n",
            "2022-12-30 00:00:00\n"
          ]
        }
      ],
      "source": [
        "all_train_df = train_data_norm.join(text_data_df, how = 'inner')\n",
        "all_test_df = test_data_norm.join(text_data_df, how = 'inner')\n",
        "\n",
        "print(all_train_df.index.min())\n",
        "print(all_train_df.index.max())\n",
        "print(all_test_df.index.min())\n",
        "print(all_test_df.index.max())"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2WWhDJkjpOYV"
      },
      "id": "2WWhDJkjpOYV",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Merge textual and numerical data\n"
      ],
      "metadata": {
        "id": "nuUgt-MnU-aV"
      },
      "id": "nuUgt-MnU-aV"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "56e91800",
      "metadata": {
        "id": "56e91800",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef57e3da-ded5-45cf-85be-985acff1c74a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "624\n",
            "624\n",
            "624\n",
            "torch.Size([624, 5, 8])\n",
            "624\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "all_train = all_train_df.values\n",
        "\n",
        "window_size = no_of_days_to_lookback\n",
        "\n",
        "X_numerical_train = []\n",
        "y_train = []\n",
        "X_text_train = []\n",
        "X_text_train_curr = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for i in range(window_size, len(all_train) - no_of_days_to_lookforward + 1):\n",
        "    X_numerical_train.append(all_train[i-window_size: i, :-2])\n",
        "\n",
        "    # split and append sequence of text\n",
        "    curr_seq = all_train[i-window_size: i, -1]\n",
        "    for j in range(window_size):\n",
        "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
        "        X_text_train_curr = X_text_train_curr + split_curr_seq\n",
        "\n",
        "    if len(X_text_train_curr) > max_text_per_iter:\n",
        "        X_text_train_curr = X_text_train_curr[:max_text_per_iter]\n",
        "\n",
        "    X_text_train.append(X_text_train_curr)\n",
        "\n",
        "    # target labels\n",
        "    y_train.append(all_train[i:i+no_of_days_to_lookforward, -2])\n",
        "\n",
        "X_numerical_train, y_train = np.array(X_numerical_train).astype(np.float16), np.array(y_train).astype(np.int32)\n",
        "print(type(X_numerical_train))\n",
        "print(type(y_train))\n",
        "\n",
        "X_numerical_train = torch.from_numpy(X_numerical_train).type(torch.Tensor)\n",
        "y_train = torch.from_numpy(y_train).long()\n",
        "\n",
        "print(len(X_numerical_train))\n",
        "print(len(X_text_train))\n",
        "print(len(y_train))\n",
        "print(X_numerical_train.shape)\n",
        "\n",
        "print(len(X_text_train))\n",
        "print(len(X_text_train[2]))\n",
        "# print(X_text_train[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "e404c5e2",
      "metadata": {
        "id": "e404c5e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39dbb607-ee81-4133-bd75-cb9662af3485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "57\n",
            "57\n",
            "57\n",
            "torch.Size([57, 5, 8])\n",
            "57\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "all_test = all_test_df.values\n",
        "\n",
        "\n",
        "X_numerical_test = []\n",
        "y_test = []\n",
        "X_text_test = []\n",
        "X_text_test_curr = []\n",
        "\n",
        "for i in range(window_size, len(all_test) - no_of_days_to_lookforward + 1):\n",
        "    X_numerical_test.append(all_test[i-window_size: i, :-2])\n",
        "\n",
        "    # split and append sequence of text (in reverse order to add the latest news first)\n",
        "    curr_seq = all_test[i-window_size: i, -1]\n",
        "    for j in range(window_size):\n",
        "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
        "        X_text_test_curr = X_text_test_curr + split_curr_seq\n",
        "\n",
        "    if len(X_text_test_curr) > max_text_per_iter:\n",
        "        X_text_test_curr = X_text_test_curr[:max_text_per_iter]\n",
        "\n",
        "    X_text_test.append(X_text_test_curr)\n",
        "\n",
        "    # target labels\n",
        "    y_test.append(all_test[i:i+no_of_days_to_lookforward, -2])\n",
        "\n",
        "X_numerical_test, y_test = np.array(X_numerical_test).astype(np.float16), np.array(y_test).astype(np.int32)\n",
        "print(type(X_numerical_test))\n",
        "print(type(y_test))\n",
        "\n",
        "X_numerical_test = torch.from_numpy(X_numerical_test).type(torch.Tensor)\n",
        "y_test = torch.from_numpy(y_test).long()\n",
        "\n",
        "print(len(X_numerical_test))\n",
        "print(len(X_text_test))\n",
        "print(len(y_test))\n",
        "print(X_numerical_test.shape)\n",
        "\n",
        "print(len(X_text_test))\n",
        "print(len(X_text_test[2]))\n",
        "# print(X_text_test[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5b453b0",
      "metadata": {
        "id": "b5b453b0"
      },
      "source": [
        "## Data loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "dc5998e6",
      "metadata": {
        "id": "dc5998e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2b00d9e860804a00aad4c4c479b6693b",
            "532fe7382d19473382074e63160e59f0",
            "5cb882f1ce1446cd8c56fc61e2578258",
            "44211108739a412699e699cb8b42bdef",
            "d6da1d58a418482f9ef88aeb188f9a12",
            "5dfd954b0cea4309a8ed413cf5b63b3d",
            "91e33bedba6b4947bd85a98918c81d8a",
            "bf398476acf04b529c6431c323b0e369",
            "79b15719a8e7408d9859e10eed54f40d",
            "68078c857c464f738ca8a9066522b72b",
            "762508b939314a389febe592e793dcd0",
            "b8230ead9aab46d7a731ac4f1b9d3b0d",
            "88df138a31ab4ed585940691910fc8d9",
            "29b3bbb278934ee291d32cd6596ea089",
            "253431593e364e5e9f7e422eeeaa9d01",
            "724753fce8a74174b8fbda624cbd29e8",
            "4459f5a866ba483abd5a738d7dafac12",
            "090c353a653c4d1cbf3a5be16cac839a",
            "c7dc1efb98dc47aba64f5d4704ce5438",
            "a50e6fc25e6d404dbeeecd0ec2519bcb",
            "903cc83cbdd4436b80eadecc8a6b4fa1",
            "8b371e36be1147aaa93d8afec45a02b0",
            "9d0e925643b04e7b9c44b9850e515aa8",
            "38aed2bbd4f44a4f89883bb2aeb8f4dc",
            "95feaed825fc44d3b4b778e1e0dddcc1",
            "3c3220c3fa494ceaaaa25fdcd2df6996",
            "ae06f80de8e340b88ed0261cc27588f0",
            "e619a06a597949c59765ea183000b0fb",
            "2db2c5673aba41b9883d023aa68ef9fc",
            "767ec606f83b4442bc1856e034ff3665",
            "f36894983ad4461393e8c1c97c98a539",
            "46845ba415e342f892a9895c02bed3d9",
            "a22b73570d3e4ceba0338fb7a1ce05ed"
          ]
        },
        "outputId": "d22f0ba3-0aec-4fd5-eb19-07b17f5f7981"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b00d9e860804a00aad4c4c479b6693b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8230ead9aab46d7a731ac4f1b9d3b0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d0e925643b04e7b9c44b9850e515aa8"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
        "\n",
        "class SiameseDataloader(Dataset):\n",
        "\n",
        "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
        "        self.X_numerical_train = X_numerical_train\n",
        "        self.X_text_train = X_text_train\n",
        "        self.MAX_LEN = MAX_LEN\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "\n",
        "        input_ids = []\n",
        "        attention_masks = []\n",
        "        token_type_ids = []\n",
        "        input_seq = []\n",
        "\n",
        "        for sent in X_text_train[index]:\n",
        "            encoded_sent = self.tokenizer.encode_plus(\n",
        "                text=sent,\n",
        "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
        "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
        "                pad_to_max_length=True,         # Pad sentence to max length\n",
        "                #return_attention_mask=True      # Return attention mask\n",
        "                return_token_type_ids=True\n",
        "                )\n",
        "            input_ids.append(encoded_sent.get('input_ids'))\n",
        "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
        "\n",
        "        # Convert lists to tensors\n",
        "        input_ids = torch.tensor(input_ids)\n",
        "        attention_masks = torch.tensor(attention_masks)\n",
        "        token_type_ids = torch.tensor(token_type_ids)\n",
        "\n",
        "\n",
        "        return {\n",
        "            'x_numerical': X_numerical_train[index],\n",
        "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(y_train[index], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_numerical_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "28f5fe04",
      "metadata": {
        "id": "28f5fe04"
      },
      "outputs": [],
      "source": [
        "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcf87d32",
      "metadata": {
        "id": "bcf87d32"
      },
      "source": [
        "## Build model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lstm1, lstm2, roberta, concat, lrelu\n"
      ],
      "metadata": {
        "id": "mfKG9WSMQ74y"
      },
      "id": "mfKG9WSMQ74y"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SiameseModel11(nn.Module):\n",
        "    def __init__(self, input_dim1, input_dim2,\n",
        "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
        "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
        "        super(SiameseModel11, self).__init__()\n",
        "        self.input_dim1 = input_dim1\n",
        "        self.input_dim2 = input_dim2\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.hidden_dim3 = hidden_dim3\n",
        "        self.hidden_dim4 = hidden_dim4\n",
        "        self.num_layers1 = num_layers1\n",
        "        self.num_layers2 = num_layers2\n",
        "        self.output_dim1 = output_dim1\n",
        "        self.output_dim2 = output_dim2\n",
        "\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(input_dim2, hidden_dim2, num_layers2, batch_first=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
        "        self.fc2 = nn.Linear(hidden_dim2, output_dim2)\n",
        "        self.fc3 = nn.Linear(output_dim1+output_dim2, hidden_dim3)\n",
        "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
        "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
        "        self.lrelu = nn.LeakyReLU(0.1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x1, ids, masks, token_type_ids):\n",
        "        #left tower with numerical features\n",
        "        h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
        "        h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
        "        out1 = self.fc1(h_out1)\n",
        "\n",
        "\n",
        "        # right tower with roberta on textual features\n",
        "        batch_size_here = ids.shape[0]\n",
        "        e2 = torch.zeros(batch_size_here, max_text_per_iter,1024).to(device)\n",
        "\n",
        "        for k in range(ids.shape[1]):\n",
        "            seq_ids = ids[:,k,:]\n",
        "            seq_masks = masks[:,k,:]\n",
        "            seq_token_type_ids = token_type_ids[:,k,:]\n",
        "\n",
        "            e2k = self.roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
        "            # first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
        "            # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
        "            e2k1 = e2k[0][:, 0, :]\n",
        "            e2[:,k,:] = e2k1\n",
        "\n",
        "\n",
        "        print(e2.shape)\n",
        "        h_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
        "        c_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
        "        ula2, (h_out2, _) = self.lstm2(e2, (h_20, c_20))\n",
        "        h_out2 = h_out2.view(-1, self.hidden_dim2)\n",
        "        out2 = self.fc2(h_out2)\n",
        "\n",
        "        # siamese merging layers\n",
        "        output = torch.cat((out1, out2),1)\n",
        "        output = self.lrelu(self.fc3(output))\n",
        "        output = self.lrelu(self.fc4(output))\n",
        "\n",
        "\n",
        "        output = self.fc5(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "KJUOPHMMRVK2"
      },
      "id": "KJUOPHMMRVK2",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lstm1, mlp, relu"
      ],
      "metadata": {
        "id": "maQVSQvVR6CP"
      },
      "id": "maQVSQvVR6CP"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SiameseModel10(nn.Module):\n",
        "    def __init__(self, input_dim1, input_dim2,\n",
        "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
        "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
        "        super(SiameseModel10, self).__init__()\n",
        "        self.input_dim1 = input_dim1\n",
        "        self.input_dim2 = input_dim2\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.hidden_dim3 = hidden_dim3\n",
        "        self.hidden_dim4 = hidden_dim4\n",
        "        self.num_layers1 = num_layers1\n",
        "        self.num_layers2 = num_layers2\n",
        "        self.output_dim1 = output_dim1\n",
        "        self.output_dim2 = output_dim2\n",
        "\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
        "        self.fc3 = nn.Linear(output_dim1, hidden_dim3)\n",
        "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
        "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x1, ids, masks, token_type_ids):\n",
        "        #left tower with numerical features\n",
        "        h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
        "        h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
        "        out1 = self.fc1(h_out1)\n",
        "\n",
        "\n",
        "        # mlp layers\n",
        "        output = out1\n",
        "        output = F.relu(self.fc3(output))\n",
        "        output = F.relu(self.fc4(output))\n",
        "        output = self.fc5(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "Yc1ZHghiRKPr"
      },
      "id": "Yc1ZHghiRKPr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### lstm1, mlp, lrelu"
      ],
      "metadata": {
        "id": "dcRte1yrTlYo"
      },
      "id": "dcRte1yrTlYo"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SiameseModel10leaky(nn.Module):\n",
        "    def __init__(self, input_dim1,\n",
        "                 hidden_dim1, hidden_dim3, hidden_dim4,\n",
        "                 num_layers1, output_dim1):\n",
        "        super(SiameseModel10leaky, self).__init__()\n",
        "        self.input_dim1 = input_dim1\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim3 = hidden_dim3\n",
        "        self.hidden_dim4 = hidden_dim4\n",
        "        self.num_layers1 = num_layers1\n",
        "        self.output_dim1 = output_dim1\n",
        "\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
        "\n",
        "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
        "        self.fc3 = nn.Linear(output_dim1, hidden_dim3)\n",
        "        # self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
        "        self.fc5 = nn.Linear(hidden_dim3, 3)\n",
        "        self.lrelu = nn.LeakyReLU(0.1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x1, ids, masks, token_type_ids):\n",
        "        #left tower with numerical features\n",
        "        h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
        "        h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
        "        out1 = self.fc1(h_out1)\n",
        "\n",
        "\n",
        "        # mlp layers\n",
        "        output = out1\n",
        "        output = self.lrelu(self.fc3(output))\n",
        "        # output = self.lrelu(self.fc4(output))\n",
        "        output = self.fc5(output)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "7Sm6o_cITpaX"
      },
      "id": "7Sm6o_cITpaX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tranformer, mlp, relu\n"
      ],
      "metadata": {
        "id": "Vo098_3sU_Hk"
      },
      "id": "Vo098_3sU_Hk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4e33819",
      "metadata": {
        "id": "e4e33819"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=MAX_LEN):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        #pe.requires_grad = False\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :]\n",
        "\n",
        "\n",
        "class SiameseModel20(nn.Module):\n",
        "    def __init__(self, input_dim1,\n",
        "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
        "                 num_layers1,  output_dim1,\n",
        "                 nhead, d_transformer, dropout=0.2 ):\n",
        "        super(SiameseModel20, self).__init__()\n",
        "\n",
        "        self.input_dim1 = input_dim1\n",
        "        self.hidden_dim1 = hidden_dim1\n",
        "        self.hidden_dim2 = hidden_dim2\n",
        "        self.hidden_dim3 = hidden_dim3\n",
        "        self.hidden_dim4 = hidden_dim4\n",
        "        self.num_layers1 = num_layers1\n",
        "        self.output_dim1 = output_dim1\n",
        "        self.lrelu = nn.LeakyReLU(0.1)\n",
        "\n",
        "        self.input_embedding  = nn.Linear(input_dim1, d_transformer)\n",
        "        self.src_mask = None\n",
        "        self.pos_encoder = PositionalEncoding(d_model=d_transformer)\n",
        "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_transformer,\n",
        "                                                        nhead=nhead,\n",
        "                                                        dropout=dropout,\n",
        "                                                        batch_first=True,\n",
        "                                                        dim_feedforward = 24)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers1)\n",
        "\n",
        "\n",
        "        # self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(5*d_transformer, output_dim1)\n",
        "        self.fc3 = nn.Linear(output_dim1, hidden_dim3)\n",
        "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
        "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.fc1.bias.data.zero_()\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def forward(self, x1, ids, masks, token_type_ids):\n",
        "        #left tower with numerical features\n",
        "        # h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        # c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
        "        # ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
        "        # h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
        "        # out1 = self.fc1(h_out1)\n",
        "\n",
        "        #transformer encoder\n",
        "        if self.src_mask is None or self.src_mask.size(0) != len(x1):\n",
        "            device = x1.device\n",
        "            mask = self._generate_square_subsequent_mask(len(x1)).to(device)\n",
        "            self.src_mask = mask\n",
        "\n",
        "        x1 = self.input_embedding(x1) # linear transformation before positional embedding\n",
        "\n",
        "        x1 = self.pos_encoder(x1)\n",
        "        output = self.transformer_encoder(x1, self.src_mask)#, self.src_mask)\n",
        "        output = torch.flatten(output, start_dim=1)\n",
        "        # output = output.view(-1, self.hidden_dim1)\n",
        "\n",
        "        out1 = self.fc1(output)\n",
        "\n",
        "\n",
        "        # mlp  layers\n",
        "        output = out1\n",
        "        output = self.lrelu(self.fc3(output))\n",
        "        output = self.lrelu(self.fc4(output))\n",
        "        output = self.fc5(output)\n",
        "        return output\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose a model"
      ],
      "metadata": {
        "id": "p8paRxDJVjWE"
      },
      "id": "p8paRxDJVjWE"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "33bdcfab",
      "metadata": {
        "id": "33bdcfab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5de44213f9934770bafde97d69dc8f2b",
            "c985fad17c00492b8e5615ad02671109",
            "a8b3637bbc7e40f4825e4e06ad26b3b9",
            "5da87bc22274453c8ee7644d9dc24a78",
            "35a025bdc3664cb6bd3aef7938609a3b",
            "f335d2330ea24dbb80e022185603e167",
            "c40c77348c2b41c0934654ccb85d3143",
            "cab0cc33b52e46daa3a42acc16dd8d85",
            "7de6663b55be405cb5a2beeff7bdcd20",
            "6c4ea27c203f4dee8b3ba24bb0f46d40",
            "3de37b924fea4734a6292945436004d0"
          ]
        },
        "outputId": "f6459bbb-2fd4-4009-e241-0ee4cf90787a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5de44213f9934770bafde97d69dc8f2b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SiameseModel11(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-23): 24 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (lstm1): LSTM(8, 20, batch_first=True)\n",
            "  (lstm2): LSTM(1024, 768, batch_first=True)\n",
            "  (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=768, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=266, out_features=10, bias=True)\n",
            "  (fc4): Linear(in_features=10, out_features=8, bias=True)\n",
            "  (fc5): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (lrelu): LeakyReLU(negative_slope=0.1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "model = SiameseModel11(input_dim1 = 8, input_dim2 = 1024,\n",
        "                 hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 10, hidden_dim4 = 8,\n",
        "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256).to(device)\n",
        "\n",
        "# model = SiameseModel10leaky(input_dim1 = 8,\n",
        "#                  hidden_dim1 = 20, output_dim1 = 10, hidden_dim3 = 10, hidden_dim4 = 8,\n",
        "#                  num_layers1 = 1).to(device)\n",
        "\n",
        "# model = SiameseModel20(input_dim1 = 8,\n",
        "#                  hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 10, hidden_dim4 = 8,\n",
        "#                  num_layers1 = 1, output_dim1 = 10,  nhead = 4, d_transformer = 20, dropout = 0.2).to(device)\n",
        "\n",
        "# model = SiameseModel10(input_dim1 = 8, input_dim2 = 1024,\n",
        "#                  hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 10, hidden_dim4 = 8,\n",
        "#                  num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256).to(device)\n",
        "\n",
        "'''\n",
        "SiameseModel10\n",
        "SiameseModel10leaky\n",
        "SiameseModel20\n",
        "'''\n",
        "\n",
        "print(model)\n",
        "# print(len(list(model.parameters())))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.roberta.parameters():\n",
        "    # print(param)\n",
        "    param.requires_grad = False\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d36SUCJmNGd",
        "outputId": "47b27196-f501-4764-96ed-bc1cc0f1f535"
      },
      "id": "7d36SUCJmNGd",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SiameseModel11(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-23): 24 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): RobertaPooler(\n",
            "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (lstm1): LSTM(8, 20, batch_first=True)\n",
            "  (lstm2): LSTM(1024, 768, batch_first=True)\n",
            "  (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
            "  (fc2): Linear(in_features=768, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=266, out_features=10, bias=True)\n",
            "  (fc4): Linear(in_features=10, out_features=8, bias=True)\n",
            "  (fc5): Linear(in_features=8, out_features=3, bias=True)\n",
            "  (lrelu): LeakyReLU(negative_slope=0.1)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
        "print(y_pred)\n",
        "print(y_pred.size())\n"
      ],
      "metadata": {
        "id": "BhZdTSfZmiVj"
      },
      "id": "BhZdTSfZmiVj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FnrD0WkxQr4U"
      },
      "id": "FnrD0WkxQr4U",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.flatten(y_pred, start_dim=1).size()"
      ],
      "metadata": {
        "id": "7tT0kAmpY015"
      },
      "id": "7tT0kAmpY015",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "05f5b46a",
      "metadata": {
        "id": "05f5b46a"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "088c2407",
      "metadata": {
        "id": "088c2407"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "loss_arr = np.zeros(num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"stock_prediction\")"
      ],
      "metadata": {
        "id": "WZI4ATJNYcfp"
      },
      "id": "WZI4ATJNYcfp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "699d13c0",
      "metadata": {
        "id": "699d13c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fbf4362b-845c-4dad-f63f-2d30384ff8f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "<ipython-input-13-96f1b91088ac>:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'ids': torch.tensor(input_ids, dtype=torch.long),\n",
            "<ipython-input-13-96f1b91088ac>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
            "<ipython-input-13-96f1b91088ac>:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
            "<ipython-input-13-96f1b91088ac>:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  'targets': torch.tensor(y_train[index], dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2it [00:03,  1.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:04,  1.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:04,  1.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:05,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:05,  1.36it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:06,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r8it [00:07,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r9it [00:07,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r10it [00:08,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r11it [00:08,  1.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r12it [00:09,  1.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r13it [00:10,  1.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r14it [00:10,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r15it [00:11,  1.63it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r16it [00:11,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r17it [00:12,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r18it [00:13,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r19it [00:13,  1.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r20it [00:14,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r21it [00:15,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r22it [00:15,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r23it [00:17,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r24it [00:19,  1.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r25it [00:21,  1.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r26it [00:22,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r27it [00:23,  1.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r28it [00:24,  1.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r29it [00:25,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r30it [00:26,  1.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r31it [00:27,  1.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r32it [00:28,  1.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r33it [00:29,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r34it [00:30,  1.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r35it [00:32,  1.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r36it [00:34,  1.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r37it [00:36,  1.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r38it [00:38,  1.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r39it [00:38,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r40it [00:39,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r41it [00:40,  1.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r42it [00:41,  1.00it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r43it [00:42,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r44it [00:43,  1.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r45it [00:43,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r46it [00:44,  1.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r47it [00:45,  1.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r48it [00:47,  1.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r49it [00:47,  1.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r50it [00:48,  1.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r51it [00:49,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r52it [00:49,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r53it [00:50,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r54it [00:51,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r55it [00:52,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r56it [00:53,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r57it [00:54,  1.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r58it [00:54,  1.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r59it [00:55,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r60it [00:55,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r61it [00:56,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r62it [00:56,  1.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r63it [00:57,  1.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r64it [00:58,  1.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r65it [00:58,  1.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r66it [00:59,  1.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r67it [00:59,  1.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r68it [01:00,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r69it [01:00,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r70it [01:01,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r71it [01:02,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r72it [01:02,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r73it [01:03,  1.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r74it [01:03,  1.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r75it [01:04,  1.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r76it [01:05,  1.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r77it [01:06,  1.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "78it [01:06,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n",
            "Train Loss at epoch 0: 1.0375598669052124\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1it [00:00,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r2it [00:01,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r3it [00:02,  1.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [00:03,  1.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r5it [00:03,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r6it [00:04,  1.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r7it [00:04,  1.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 20, 1024])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:05,  1.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 20, 1024])\n",
            "test Loss at epoch 0: 1.1023592948913574\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-e35f3db5ac92>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mmodel_to_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_model_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_vocab_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    651\u001b[0m     \u001b[0mpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 653\u001b[0;31m     \u001b[0mpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m     \u001b[0mdata_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_buf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'TorchHistory.add_log_parameters_hook.<locals>.<lambda>'"
          ]
        }
      ],
      "source": [
        "# roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
        "train_loss_record = []\n",
        "wandb.watch(model, log = 'all')\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = []\n",
        "    train_loss_sum = []\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
        "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
        "        ids = data['ids'].to(device, dtype = torch.long)\n",
        "        masks = data['mask'].to(device, dtype = torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
        "        # print('y_pred:', y_pred)\n",
        "        _, pred_label = torch.max(y_pred.data, 1)\n",
        "\n",
        "        loss = criterion(y_pred, targets.reshape(-1))\n",
        "\n",
        "         # Zero out gradient, else they will accumulate between epochs\n",
        "        optimiser.zero_grad()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "\n",
        "        for name, p in model.named_parameters():\n",
        "            if(p.requires_grad) and (\"bias\" not in name):\n",
        "                if p.grad is not None:\n",
        "                    wandb.log({'gradient_' + name: p.grad.abs().mean().cpu().data.numpy()})\n",
        "                else:\n",
        "                    wandb.log({'gradient_' + name: 0})\n",
        "\n",
        "\n",
        "        # plot_grad_flow(model.named_parameters(), idx, epoch) # version 1\n",
        "\n",
        "        # Update parameters\n",
        "        optimiser.step()\n",
        "\n",
        "\n",
        "\n",
        "        train_loss.append(loss.data.cpu())\n",
        "        train_loss_sum.append(loss.data.cpu())\n",
        "\n",
        "\n",
        "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
        "        # Get accuracy\n",
        "        train_total += targets.reshape(-1).size(0)\n",
        "        train_correct += (pred_label == targets.reshape(-1)).sum()\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "    # Record at every epoch\n",
        "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
        "    train_loss_record.append(np.mean(train_loss_sum))\n",
        "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
        "    wandb.log({'train accuracy in this epoch': train_accuracy, 'epoch': epoch})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # evaluate on test set every epoch\n",
        "    test_loss = []\n",
        "    test_loss_sum = []\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
        "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
        "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
        "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
        "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
        "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
        "        _, pred_label = torch.max(y_pred.data, 1)\n",
        "\n",
        "#         print('y_pred:', y_pred)\n",
        "        tloss = criterion(y_pred, test_targets.reshape(-1))\n",
        "\n",
        "        test_loss.append(tloss.data.cpu())\n",
        "        test_loss_sum.append(tloss.data.cpu())\n",
        "\n",
        "        wandb.log({'avg test loss in this batch': tloss.item(), 'epoch': epoch, 'batch_id': idx})\n",
        "\n",
        "        # Get accuracy\n",
        "        total += test_targets.reshape(-1).size(0)\n",
        "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    # Record at every epoch\n",
        "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
        "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
        "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # save the model weights every save_freq_epoch epochs\n",
        "    if (epoch % save_freq_epoch == 0):\n",
        "        output_model_file = output_path + '/roberta_stock_pred_' + str(epoch) + '.bin'\n",
        "        output_vocab_file = output_path\n",
        "\n",
        "        model_to_save = model\n",
        "        torch.save(model_to_save, output_model_file)\n",
        "        tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Czyuam3JfJj2"
      },
      "id": "Czyuam3JfJj2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TB_GL_Ilbfy4"
      },
      "id": "TB_GL_Ilbfy4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb6bbec1",
      "metadata": {
        "id": "bb6bbec1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4aac5f8f",
      "metadata": {
        "id": "4aac5f8f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the model"
      ],
      "metadata": {
        "id": "Kcgrof1frlbM"
      },
      "id": "Kcgrof1frlbM"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e1122c8c",
      "metadata": {
        "id": "e1122c8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac929abd-d2fd-4e8e-dce5-50936546036a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/machine_learning/projects/xai-seq/output/run_1/vocab.json',\n",
              " '/content/drive/MyDrive/machine_learning/projects/xai-seq/output/run_1/merges.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "output_model_file = output_path + '/roberta_stock_pred.bin'\n",
        "output_vocab_file = output_path\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3049d3f4",
      "metadata": {
        "id": "3049d3f4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1807d2b1",
      "metadata": {
        "id": "1807d2b1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cf315ee",
      "metadata": {
        "id": "2cf315ee"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b00d9e860804a00aad4c4c479b6693b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_532fe7382d19473382074e63160e59f0",
              "IPY_MODEL_5cb882f1ce1446cd8c56fc61e2578258",
              "IPY_MODEL_44211108739a412699e699cb8b42bdef"
            ],
            "layout": "IPY_MODEL_d6da1d58a418482f9ef88aeb188f9a12"
          }
        },
        "532fe7382d19473382074e63160e59f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5dfd954b0cea4309a8ed413cf5b63b3d",
            "placeholder": "​",
            "style": "IPY_MODEL_91e33bedba6b4947bd85a98918c81d8a",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "5cb882f1ce1446cd8c56fc61e2578258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf398476acf04b529c6431c323b0e369",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79b15719a8e7408d9859e10eed54f40d",
            "value": 898823
          }
        },
        "44211108739a412699e699cb8b42bdef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68078c857c464f738ca8a9066522b72b",
            "placeholder": "​",
            "style": "IPY_MODEL_762508b939314a389febe592e793dcd0",
            "value": " 899k/899k [00:00&lt;00:00, 9.49MB/s]"
          }
        },
        "d6da1d58a418482f9ef88aeb188f9a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dfd954b0cea4309a8ed413cf5b63b3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91e33bedba6b4947bd85a98918c81d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf398476acf04b529c6431c323b0e369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79b15719a8e7408d9859e10eed54f40d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68078c857c464f738ca8a9066522b72b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "762508b939314a389febe592e793dcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8230ead9aab46d7a731ac4f1b9d3b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88df138a31ab4ed585940691910fc8d9",
              "IPY_MODEL_29b3bbb278934ee291d32cd6596ea089",
              "IPY_MODEL_253431593e364e5e9f7e422eeeaa9d01"
            ],
            "layout": "IPY_MODEL_724753fce8a74174b8fbda624cbd29e8"
          }
        },
        "88df138a31ab4ed585940691910fc8d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4459f5a866ba483abd5a738d7dafac12",
            "placeholder": "​",
            "style": "IPY_MODEL_090c353a653c4d1cbf3a5be16cac839a",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "29b3bbb278934ee291d32cd6596ea089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7dc1efb98dc47aba64f5d4704ce5438",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a50e6fc25e6d404dbeeecd0ec2519bcb",
            "value": 456318
          }
        },
        "253431593e364e5e9f7e422eeeaa9d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_903cc83cbdd4436b80eadecc8a6b4fa1",
            "placeholder": "​",
            "style": "IPY_MODEL_8b371e36be1147aaa93d8afec45a02b0",
            "value": " 456k/456k [00:00&lt;00:00, 17.5MB/s]"
          }
        },
        "724753fce8a74174b8fbda624cbd29e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4459f5a866ba483abd5a738d7dafac12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090c353a653c4d1cbf3a5be16cac839a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7dc1efb98dc47aba64f5d4704ce5438": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a50e6fc25e6d404dbeeecd0ec2519bcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "903cc83cbdd4436b80eadecc8a6b4fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b371e36be1147aaa93d8afec45a02b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d0e925643b04e7b9c44b9850e515aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38aed2bbd4f44a4f89883bb2aeb8f4dc",
              "IPY_MODEL_95feaed825fc44d3b4b778e1e0dddcc1",
              "IPY_MODEL_3c3220c3fa494ceaaaa25fdcd2df6996"
            ],
            "layout": "IPY_MODEL_ae06f80de8e340b88ed0261cc27588f0"
          }
        },
        "38aed2bbd4f44a4f89883bb2aeb8f4dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e619a06a597949c59765ea183000b0fb",
            "placeholder": "​",
            "style": "IPY_MODEL_2db2c5673aba41b9883d023aa68ef9fc",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "95feaed825fc44d3b4b778e1e0dddcc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_767ec606f83b4442bc1856e034ff3665",
            "max": 482,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f36894983ad4461393e8c1c97c98a539",
            "value": 482
          }
        },
        "3c3220c3fa494ceaaaa25fdcd2df6996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46845ba415e342f892a9895c02bed3d9",
            "placeholder": "​",
            "style": "IPY_MODEL_a22b73570d3e4ceba0338fb7a1ce05ed",
            "value": " 482/482 [00:00&lt;00:00, 22.0kB/s]"
          }
        },
        "ae06f80de8e340b88ed0261cc27588f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e619a06a597949c59765ea183000b0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2db2c5673aba41b9883d023aa68ef9fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "767ec606f83b4442bc1856e034ff3665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f36894983ad4461393e8c1c97c98a539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "46845ba415e342f892a9895c02bed3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22b73570d3e4ceba0338fb7a1ce05ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5de44213f9934770bafde97d69dc8f2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c985fad17c00492b8e5615ad02671109",
              "IPY_MODEL_a8b3637bbc7e40f4825e4e06ad26b3b9",
              "IPY_MODEL_5da87bc22274453c8ee7644d9dc24a78"
            ],
            "layout": "IPY_MODEL_35a025bdc3664cb6bd3aef7938609a3b"
          }
        },
        "c985fad17c00492b8e5615ad02671109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f335d2330ea24dbb80e022185603e167",
            "placeholder": "​",
            "style": "IPY_MODEL_c40c77348c2b41c0934654ccb85d3143",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "a8b3637bbc7e40f4825e4e06ad26b3b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cab0cc33b52e46daa3a42acc16dd8d85",
            "max": 1421700479,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7de6663b55be405cb5a2beeff7bdcd20",
            "value": 1421700479
          }
        },
        "5da87bc22274453c8ee7644d9dc24a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c4ea27c203f4dee8b3ba24bb0f46d40",
            "placeholder": "​",
            "style": "IPY_MODEL_3de37b924fea4734a6292945436004d0",
            "value": " 1.42G/1.42G [00:17&lt;00:00, 47.3MB/s]"
          }
        },
        "35a025bdc3664cb6bd3aef7938609a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f335d2330ea24dbb80e022185603e167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c40c77348c2b41c0934654ccb85d3143": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cab0cc33b52e46daa3a42acc16dd8d85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de6663b55be405cb5a2beeff7bdcd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c4ea27c203f4dee8b3ba24bb0f46d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de37b924fea4734a6292945436004d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}