{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5046834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: yfinance in /Users/visriv/Library/Python/3.9/lib/python/site-packages (0.2.18)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.24.1)\n",
      "Requirement already satisfied: requests>=2.26 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (2.28.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (4.11.2)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (2022.7.1)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (4.9.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: cryptography>=3.3.2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (41.0.1)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.5.3)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (2.3.8)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
      "Requirement already satisfied: six>=1.9 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
      "Requirement already satisfied: webencodings in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
      "Requirement already satisfied: pycparser in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /Users/visriv/Library/Python/3.9/lib/python/site-packages (4.29.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: filelock in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: fsspec in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (4.11.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4) (2.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from nltk) (2023.6.3)\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from nltk) (8.1.3)\n",
      "Installing collected packages: joblib, nltk\n",
      "Successfully installed joblib-1.2.0 nltk-3.8.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "!pip install transformers\n",
    "!pip install beautifulsoup4\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4b27869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import mpl, plt\n",
    "import math, time\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "038b76c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e89f966",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:p9hw3tot) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">cool-star-7</strong> at: <a href='https://wandb.ai/visriv/stock_prediction/runs/p9hw3tot' target=\"_blank\">https://wandb.ai/visriv/stock_prediction/runs/p9hw3tot</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230612_144431-p9hw3tot/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:p9hw3tot). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/visriv/Documents/Git/xai-seq/wandb/run-20230612_144432-qiyubr28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/visriv/stock_prediction/runs/qiyubr28' target=\"_blank\">rose-yogurt-8</a></strong> to <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">https://wandb.ai/visriv/stock_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/visriv/stock_prediction/runs/qiyubr28' target=\"_blank\">https://wandb.ai/visriv/stock_prediction/runs/qiyubr28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/visriv/stock_prediction/runs/qiyubr28?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x129930b20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"stock_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f74160",
   "metadata": {},
   "source": [
    "### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df8398dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_days_to_lookforward = 1\n",
    "no_of_days_to_lookback = 5\n",
    "up_threshold = 0.015\n",
    "down_threshold = -0.015\n",
    "max_text_per_iter = 20\n",
    "batch_size = 8\n",
    "MAX_LEN = 10\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf67837",
   "metadata": {},
   "source": [
    "### Get stocks data for last N days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433931d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64983989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "stock_symbols = [ 'XOM']\n",
    "no_of_days = 4*365\n",
    "\n",
    "EXPORT_DATA_FOLDER = './data/'\n",
    "\n",
    "# Set the start and end dates for the data \n",
    "# here matching it with dates of news text available\n",
    "train_start = datetime.strptime('2020/01/04', '%Y/%m/%d')\n",
    "train_end = datetime.strptime('2022/09/30', '%Y/%m/%d')\n",
    "test_start = datetime.strptime('2022/10/01', '%Y/%m/%d')\n",
    "test_end = datetime.strptime('2023/01/04', '%Y/%m/%d')\n",
    "\n",
    "\n",
    "# start = datetime.datetime.now() - datetime.timedelta(days=no_of_days)\n",
    "# end = datetime.datetime.now()\n",
    "\n",
    "# Get training data\n",
    "for symbol in stock_symbols:\n",
    "    # Download the historical price and volume data using yfinance\n",
    "    train_data_raw = yf.download(symbol, start=train_start, end=train_end)\n",
    "\n",
    "    # Normalize features by percent of changes between today and yesterday\n",
    "    pct_change_open = train_data_raw['Open'].pct_change().fillna(0)\n",
    "    pct_change_high = train_data_raw['High'].pct_change().fillna(0)\n",
    "    pct_change_high_over_open = (train_data_raw['High']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_low = train_data_raw['Low'].pct_change().fillna(0)\n",
    "    pct_change_low_over_open = (train_data_raw['Low']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_close = train_data_raw['Close'].pct_change().fillna(0)\n",
    "    pct_change_close_over_open = (train_data_raw['Close']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_adjclose = train_data_raw['Adj Close'].pct_change().fillna(0)\n",
    "    pct_change_adjclose_over_open = (train_data_raw['Adj Close']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_volume = train_data_raw['Volume'].pct_change().fillna(0)\n",
    "\n",
    "    # Prepare labels: 2 means the close price of tomorow is higher than today's close price; 1 is down; 0 means the movement is between up_threshold and down_threshold\n",
    "    label = np.where(pct_change_close > up_threshold, 2, np.where(pct_change_close < down_threshold, 1, 0))[1:]\n",
    "    label = np.append(label, 0)\n",
    "\n",
    "    # Construct a train_data_norm data frame\n",
    "    train_data_norm = pd.DataFrame({'Open_norm':pct_change_open,\n",
    "                              'High_norm':pct_change_high,\n",
    "                              'Low_norm': pct_change_low,\n",
    "                              'Close_norm':pct_change_close,\n",
    "                              'Volume_norm':pct_change_volume,\n",
    "                              'High-Open_norm':pct_change_high_over_open,\n",
    "                              'Low-Open_norm':pct_change_low_over_open,\n",
    "                              'Close-Open_norm':pct_change_close_over_open,\n",
    "                              'Label_2up1down':label})\n",
    "\n",
    "    # Normalize by min-max normalization after the pct normalization\n",
    "    train_data_norm['Open_norm'] = train_data_norm['Open_norm'].apply(lambda x: (x - train_data_norm['Open_norm'].min()) / (train_data_norm['Open_norm'].max() - train_data_norm['Open_norm'].min()))\n",
    "    train_data_norm['High_norm'] = train_data_norm['High_norm'].apply(lambda x: (x - train_data_norm['High_norm'].min()) / (train_data_norm['High_norm'].max() - train_data_norm['High_norm'].min()))\n",
    "    train_data_norm['Low_norm'] = train_data_norm['Low_norm'].apply(lambda x: (x - train_data_norm['Low_norm'].min()) / (train_data_norm['Low_norm'].max() - train_data_norm['Low_norm'].min()))\n",
    "    train_data_norm['Close_norm'] = train_data_norm['Close_norm'].apply(lambda x: (x - train_data_norm['Close_norm'].min()) / (train_data_norm['Close_norm'].max() - train_data_norm['Close_norm'].min()))\n",
    "    train_data_norm['Volume_norm'] = train_data_norm['Volume_norm'].apply(lambda x: (x - train_data_norm['Volume_norm'].min()) / (train_data_norm['Volume_norm'].max() - train_data_norm['Volume_norm'].min()))\n",
    "    train_data_norm['High-Open_norm'] = train_data_norm['High-Open_norm'].apply(lambda x: (x - train_data_norm['High-Open_norm'].min()) / (train_data_norm['High-Open_norm'].max() - train_data_norm['High-Open_norm'].min()))\n",
    "    train_data_norm['Low-Open_norm'] = train_data_norm['Low-Open_norm'].apply(lambda x: (x - train_data_norm['Low-Open_norm'].min()) / (train_data_norm['Low-Open_norm'].max() - train_data_norm['Low-Open_norm'].min()))\n",
    "    train_data_norm['Close-Open_norm'] = train_data_norm['Close-Open_norm'].apply(lambda x: (x - train_data_norm['Close-Open_norm'].min()) / (train_data_norm['Close-Open_norm'].max() - train_data_norm['Close-Open_norm'].min()))\n",
    "\n",
    "    # Remove the first and the last row, becuase of NAN values\n",
    "    train_data_raw = train_data_raw.iloc[1:-1]\n",
    "    train_data_norm = train_data_norm.iloc[1:-1]\n",
    "\n",
    "    train_data_raw.to_csv(EXPORT_DATA_FOLDER+symbol+'train_raw_data.csv', index=True)\n",
    "    train_data_norm.to_csv(EXPORT_DATA_FOLDER+symbol+'train_norm_data.csv', index=True)\n",
    "    \n",
    "    \n",
    "# Get test data\n",
    "for symbol in stock_symbols:\n",
    "    # Download the historical price and volume data using yfinance\n",
    "    test_data_raw = yf.download(symbol, start=test_start, end=test_end)\n",
    "\n",
    "    # Normalize features by percent of changes between today and yesterday\n",
    "    pct_change_open = test_data_raw['Open'].pct_change().fillna(0)\n",
    "    pct_change_high = test_data_raw['High'].pct_change().fillna(0)\n",
    "    pct_change_high_over_open = (test_data_raw['High']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_low = test_data_raw['Low'].pct_change().fillna(0)\n",
    "    pct_change_low_over_open = (test_data_raw['Low']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_close = test_data_raw['Close'].pct_change().fillna(0)\n",
    "    pct_change_close_over_open = (test_data_raw['Close']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_adjclose = test_data_raw['Adj Close'].pct_change().fillna(0)\n",
    "    pct_change_adjclose_over_open = (test_data_raw['Adj Close']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_volume = test_data_raw['Volume'].pct_change().fillna(0)\n",
    "\n",
    "    # Prepare labels: 2 means the close price of tomorow is higher than today's close price; 1 is down; 0 means the movement is between up_threshold and down_threshold\n",
    "    label = np.where(pct_change_close > up_threshold, 2, np.where(pct_change_close < down_threshold, 1, 0))[1:]\n",
    "    label = np.append(label, 0)\n",
    "\n",
    "    # Construct a test_data_norm data frame\n",
    "    test_data_norm = pd.DataFrame({'Open_norm':pct_change_open,\n",
    "                              'High_norm':pct_change_high,\n",
    "                              'Low_norm': pct_change_low,\n",
    "                              'Close_norm':pct_change_close,\n",
    "                              'Volume_norm':pct_change_volume,\n",
    "                              'High-Open_norm':pct_change_high_over_open,\n",
    "                              'Low-Open_norm':pct_change_low_over_open,\n",
    "                              'Close-Open_norm':pct_change_close_over_open,\n",
    "                              'Label_2up1down':label})\n",
    "\n",
    "    # Normalize by min-max normalization after the pct normalization\n",
    "    test_data_norm['Open_norm'] = test_data_norm['Open_norm'].apply(lambda x: (x - test_data_norm['Open_norm'].min()) / (test_data_norm['Open_norm'].max() - test_data_norm['Open_norm'].min()))\n",
    "    test_data_norm['High_norm'] = test_data_norm['High_norm'].apply(lambda x: (x - test_data_norm['High_norm'].min()) / (test_data_norm['High_norm'].max() - test_data_norm['High_norm'].min()))\n",
    "    test_data_norm['Low_norm'] = test_data_norm['Low_norm'].apply(lambda x: (x - test_data_norm['Low_norm'].min()) / (test_data_norm['Low_norm'].max() - test_data_norm['Low_norm'].min()))\n",
    "    test_data_norm['Close_norm'] = test_data_norm['Close_norm'].apply(lambda x: (x - test_data_norm['Close_norm'].min()) / (test_data_norm['Close_norm'].max() - test_data_norm['Close_norm'].min()))\n",
    "    test_data_norm['Volume_norm'] = test_data_norm['Volume_norm'].apply(lambda x: (x - test_data_norm['Volume_norm'].min()) / (test_data_norm['Volume_norm'].max() - test_data_norm['Volume_norm'].min()))\n",
    "    test_data_norm['High-Open_norm'] = test_data_norm['High-Open_norm'].apply(lambda x: (x - test_data_norm['High-Open_norm'].min()) / (test_data_norm['High-Open_norm'].max() - test_data_norm['High-Open_norm'].min()))\n",
    "    test_data_norm['Low-Open_norm'] = test_data_norm['Low-Open_norm'].apply(lambda x: (x - test_data_norm['Low-Open_norm'].min()) / (test_data_norm['Low-Open_norm'].max() - test_data_norm['Low-Open_norm'].min()))\n",
    "    test_data_norm['Close-Open_norm'] = test_data_norm['Close-Open_norm'].apply(lambda x: (x - test_data_norm['Close-Open_norm'].min()) / (test_data_norm['Close-Open_norm'].max() - test_data_norm['Close-Open_norm'].min()))\n",
    "\n",
    "    # Remove the first and the last row, becuase of NAN values\n",
    "    test_data_raw = test_data_raw.iloc[1:-1]\n",
    "    test_data_norm = test_data_norm.iloc[1:-1]\n",
    "\n",
    "    test_data_raw.to_csv(EXPORT_DATA_FOLDER+symbol+'test_raw_data.csv', index=True)\n",
    "    test_data_norm.to_csv(EXPORT_DATA_FOLDER+symbol+'test_norm_data.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c946df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4974ced",
   "metadata": {},
   "source": [
    "## TODO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da5ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "(2023-06-05)\n",
    "cuda support check\n",
    "//read textual data into correct shape\n",
    "hyperparam tuning: number of neurons: tune to right number of neurons in FC in model\n",
    "//max_text_per_iter -> code in dataloader to maintain the size \n",
    "\n",
    "(2023-06-07)\n",
    "cuda check\n",
    "roberta encoder fix\n",
    "multi label - how to create target label?\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dfdf7",
   "metadata": {},
   "source": [
    "## Prep textual data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1eda3",
   "metadata": {},
   "source": [
    "### Crawl textual news data from internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a5d4a4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Recent News Headlines for AAPL: \n",
      "Tech Investors: Pay Attention to Hype Cycles and Adoption Life Cycles ( Jun-17-23 11:50AM )\n",
      "Missing an AirPod? These People Found Free ReplacementsWith Mixed Results ( 09:00AM )\n",
      "Left AirPod Seeking Right AirPod: People Pair Up When One Earbud Goes Missing ( 09:00AM )\n",
      "\n",
      "\n",
      "Recent News Headlines for TSLA: \n",
      "The worlds two richest men had lunch in Paris as Elon Musks grand tour of Europe continues ( Jun-17-23 07:24PM )\n",
      "Cathie Wood Sold More Tesla Stock. She Might Not Be Done. ( 04:39PM )\n",
      "Musk says Tesla close to reaching vehicle autonomy ( 01:36PM )\n",
      "\n",
      "\n",
      "Recent News Headlines for AMZN: \n",
      "5 Dollar Tree Items That Make Great Gifts ( Jun-17-23 12:00PM )\n",
      "10 Stocks That Could Be the Next Apple or Amazon ( 10:31AM )\n",
      "Amazon Stock: Bear vs. Bull ( 10:05AM )\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Parameters \n",
    "n = 3 #the # of article headlines displayed per ticker\n",
    "tickers = ['AAPL', 'TSLA', 'AMZN']\n",
    "\n",
    "\n",
    "\n",
    "# Get Data\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t='\n",
    "news_tables = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = finviz_url + ticker\n",
    "    req = Request(url=url,\n",
    "                  headers={'user-agent': 'Mozilla/5.0',\n",
    "                                   'referer': 'https://...'}) \n",
    "    resp = urlopen(req)    \n",
    "    html = BeautifulSoup(resp, features=\"lxml\")\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "try:\n",
    "    for ticker in tickers:\n",
    "        df = news_tables[ticker]\n",
    "        df_tr = df.findAll('tr')\n",
    "    \n",
    "        print ('\\n')\n",
    "        print ('Recent News Headlines for {}: '.format(ticker))\n",
    "        \n",
    "        for i, table_row in enumerate(df_tr):\n",
    "            a_text = table_row.a.text\n",
    "            td_text = table_row.td.text\n",
    "            td_text = td_text.strip()\n",
    "            print(a_text,'(',td_text,')')\n",
    "            if i == n-1:\n",
    "                break\n",
    "except KeyError:\n",
    "    pass\n",
    "\n",
    "\n",
    "# Iterate through the news\n",
    "parsed_news = []\n",
    "for file_name, news_table in news_tables.items():\n",
    "    for x in news_table.findAll('tr'):\n",
    "        text = x.a.get_text() \n",
    "        date_scrape = x.td.text.split()\n",
    "\n",
    "        if len(date_scrape) == 1:\n",
    "            time = date_scrape[0]\n",
    "            \n",
    "        else:\n",
    "            date = date_scrape[0]\n",
    "            time = date_scrape[1]\n",
    "\n",
    "        ticker = file_name.split('_')[0]\n",
    "        \n",
    "        parsed_news.append([ticker, date, time, text])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d832b747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAPL',\n",
       " 'Jun-17-23',\n",
       " '11:50AM',\n",
       " 'Tech Investors: Pay Attention to Hype Cycles and Adoption Life Cycles']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_news[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff4e8a",
   "metadata": {},
   "source": [
    "### Read downloaded data from saved files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d4f812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_df = pd.read_csv('./data/XOM_20200401_20230401_medium.csv', sep= ',', header= 0)\n",
    "text_data_df = text_data_df[['Date', 'News']]\n",
    "\n",
    "\n",
    "text_data_df = text_data_df.groupby('Date')['News'].apply('$$$###'.join)\n",
    "\n",
    "text_data_df.index = pd.to_datetime(text_data_df.index, dayfirst=True)\n",
    "# text_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10eddacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df = train_data_norm.join(text_data_df, how = 'inner')\n",
    "all_test_df = test_data_norm.join(text_data_df, how = 'inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ad722f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-04-01 00:00:00\n",
      "2022-09-28 00:00:00\n",
      "2022-10-04 00:00:00\n",
      "2022-12-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(all_train_df.index.min())\n",
    "print(all_train_df.index.max())\n",
    "print(all_test_df.index.min())\n",
    "print(all_test_df.index.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca779813",
   "metadata": {},
   "source": [
    "### Merge textual and numerical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56e91800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "624\n",
      "624\n",
      "624\n",
      "torch.Size([624, 5, 8])\n",
      "624\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "all_train = all_train_df.values\n",
    "\n",
    "window_size = no_of_days_to_lookback\n",
    "\n",
    "X_numerical_train = []\n",
    "y_train = []\n",
    "X_text_train = []\n",
    "X_text_train_curr = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(window_size, len(all_train) - no_of_days_to_lookforward + 1):\n",
    "    X_numerical_train.append(all_train[i-window_size: i, :-2])\n",
    "    \n",
    "    # split and append sequence of text\n",
    "    curr_seq = all_train[i-window_size: i, -1]\n",
    "    for j in range(window_size):\n",
    "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
    "        X_text_train_curr = X_text_train_curr + split_curr_seq\n",
    "    \n",
    "    if len(X_text_train_curr) > max_text_per_iter:\n",
    "        X_text_train_curr = X_text_train_curr[:max_text_per_iter]\n",
    "    \n",
    "    X_text_train.append(X_text_train_curr)\n",
    "        \n",
    "    # target labels\n",
    "    y_train.append(all_train[i:i+no_of_days_to_lookforward, -2])\n",
    "\n",
    "X_numerical_train, y_train = np.array(X_numerical_train).astype(np.float16), np.array(y_train).astype(np.int32)\n",
    "print(type(X_numerical_train))\n",
    "print(type(y_train))\n",
    "\n",
    "X_numerical_train = torch.from_numpy(X_numerical_train).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "print(len(X_numerical_train))\n",
    "print(len(X_text_train))\n",
    "print(len(y_train))\n",
    "print(X_numerical_train.shape)\n",
    "\n",
    "print(len(X_text_train))\n",
    "print(len(X_text_train[2]))\n",
    "# print(X_text_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b543f0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "57\n",
      "57\n",
      "57\n",
      "torch.Size([57, 5, 8])\n",
      "57\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "all_test = all_test_df.values\n",
    "\n",
    "\n",
    "X_numerical_test = []\n",
    "y_test = []\n",
    "X_text_test = []\n",
    "X_text_test_curr = []\n",
    "\n",
    "for i in range(window_size, len(all_test) - no_of_days_to_lookforward + 1):\n",
    "    X_numerical_test.append(all_test[i-window_size: i, :-2])\n",
    "    \n",
    "    # split and append sequence of text (in reverse order to add the latest news first)\n",
    "    curr_seq = all_test[i-window_size: i, -1]\n",
    "    for j in range(window_size):\n",
    "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
    "        X_text_test_curr = X_text_test_curr + split_curr_seq\n",
    "    \n",
    "    if len(X_text_test_curr) > max_text_per_iter:\n",
    "        X_text_test_curr = X_text_test_curr[:max_text_per_iter]\n",
    "    \n",
    "    X_text_test.append(X_text_test_curr)\n",
    "        \n",
    "    # target labels\n",
    "    y_test.append(all_test[i:i+no_of_days_to_lookforward, -2])\n",
    "\n",
    "X_numerical_test, y_test = np.array(X_numerical_test).astype(np.float16), np.array(y_test).astype(np.int32)\n",
    "print(type(X_numerical_test))\n",
    "print(type(y_test))\n",
    "\n",
    "X_numerical_test = torch.from_numpy(X_numerical_test).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "print(len(X_numerical_test))\n",
    "print(len(X_text_test))\n",
    "print(len(y_test))\n",
    "print(X_numerical_test.shape)\n",
    "\n",
    "print(len(X_text_test))\n",
    "print(len(X_text_test[2]))\n",
    "# print(X_text_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8968cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n",
      "689\n",
      "689\n",
      "torch.Size([689, 5, 8])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce31714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689\n",
      "20\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425dea0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1e81060",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec05f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
    "\n",
    "class SiameseDataloader(Dataset):\n",
    "    \n",
    "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
    "        self.X_numerical_train = X_numerical_train\n",
    "        self.X_text_train = X_text_train\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        token_type_ids = []\n",
    "        input_seq = []\n",
    "\n",
    "        for sent in X_text_train[index]:\n",
    "            encoded_sent = self.tokenizer.encode_plus(\n",
    "                text=sent,\n",
    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
    "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
    "                pad_to_max_length=True,         # Pad sentence to max length \n",
    "                #return_attention_mask=True      # Return attention mask\n",
    "                return_token_type_ids=True\n",
    "                )\n",
    "            input_ids.append(encoded_sent.get('input_ids'))\n",
    "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'x_numerical': X_numerical_train[index],\n",
    "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(y_train[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df6b94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc39f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47651e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7f4d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6885e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a83eb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dddd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb91ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d64e94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b79f13b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eed8a87",
   "metadata": {},
   "source": [
    "## Build model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54fb01fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, input_dim1, input_dim2, \n",
    "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
    "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.input_dim1 = input_dim1\n",
    "        self.input_dim2 = input_dim2\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.hidden_dim3 = hidden_dim3\n",
    "        self.hidden_dim4 = hidden_dim4\n",
    "        self.num_layers1 = num_layers1\n",
    "        self.num_layers2 = num_layers2\n",
    "        self.output_dim1 = output_dim1\n",
    "        self.output_dim2 = output_dim2\n",
    "        \n",
    "        \n",
    "\n",
    "        self.roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "        \n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_dim2, hidden_dim2, num_layers2, batch_first=True)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim2, output_dim2)\n",
    "        self.fc3 = nn.Linear(output_dim1+output_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x1, ids, masks, token_type_ids):\n",
    "        #left tower with numerical features\n",
    "        h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "        c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "        ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
    "        h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
    "        out1 = self.fc1(h_out1)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # right tower with roberta on textual features  \n",
    "        #TODO\n",
    "        batch_size_here = ids.shape[0]\n",
    "        e2 = torch.zeros(batch_size_here, max_text_per_iter,1024).to(device)\n",
    "        \n",
    "        for k in range(ids.shape[1]):\n",
    "            seq_ids = ids[:,k,:]\n",
    "            seq_masks = masks[:,k,:]\n",
    "            seq_token_type_ids = token_type_ids[:,k,:]\n",
    "\n",
    "\n",
    "            e2k = self.roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "            # print(e2.shape)\n",
    "            # print(e2k[1].shape)\n",
    "            #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "            # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "            e2k1 = e2k[0][:, 0, :]  \n",
    "            e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        print('e2 shape: ', e2.shape)        \n",
    "        h_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "        c_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "        ula2, (h_out2, _) = self.lstm2(e2, (h_20, c_20))\n",
    "        h_out2 = h_out2.view(-1, self.hidden_dim2)\n",
    "        out2 = self.fc2(h_out2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # siamese merging layers\n",
    "        \n",
    "        output = torch.cat((out1, out2),1)\n",
    "        output = F.relu(self.fc3(output))\n",
    "        output = F.relu(self.fc4(output))\n",
    "        output = self.fc5(output)\n",
    "        return output\n",
    "    \n",
    "#TODO : correct these values\n",
    "model = SiameseModel(input_dim1 = 8, input_dim2 = 1024, \n",
    "                 hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 128, hidden_dim4 = 64,\n",
    "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256).to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b96c4800",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SiameseModel(\n",
      "  (roberta): RobertaModel(\n",
      "    (embeddings): RobertaEmbeddings(\n",
      "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
      "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "      (token_type_embeddings): Embedding(1, 1024)\n",
      "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): RobertaEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (12): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (13): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (14): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (15): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (16): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (17): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (18): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (19): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (20): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (21): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (22): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (23): RobertaLayer(\n",
      "          (attention): RobertaAttention(\n",
      "            (self): RobertaSelfAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): RobertaSelfOutput(\n",
      "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): RobertaIntermediate(\n",
      "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): RobertaOutput(\n",
      "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): RobertaPooler(\n",
      "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (lstm1): LSTM(8, 20, batch_first=True)\n",
      "  (lstm2): LSTM(1024, 768, batch_first=True)\n",
      "  (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=266, out_features=128, bias=True)\n",
      "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc5): Linear(in_features=64, out_features=3, bias=True)\n",
      ")\n",
      "409\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "# for i in range(len(list(model.parameters()))):\n",
    "#     print(list(model.parameters())[i].size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64d1362",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3306d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_arr = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6a968c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/visriv/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_34449/3665585654.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'ids': torch.tensor(input_ids, dtype=torch.long),\n",
      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_34449/3665585654.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_34449/3665585654.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_34449/3665585654.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(y_train[index], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1182, 0.0656, 0.0110],\n",
      "        [0.1180, 0.0657, 0.0109],\n",
      "        [0.1183, 0.0653, 0.0107],\n",
      "        [0.1182, 0.0654, 0.0107],\n",
      "        [0.1181, 0.0655, 0.0108],\n",
      "        [0.1182, 0.0655, 0.0107],\n",
      "        [0.1182, 0.0654, 0.0107],\n",
      "        [0.1182, 0.0655, 0.0107]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:20, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 4.9364,  1.2416, -3.3211],\n",
      "        [ 4.9365,  1.2415, -3.3216],\n",
      "        [ 4.9365,  1.2416, -3.3214],\n",
      "        [ 4.9362,  1.2416, -3.3213],\n",
      "        [ 4.9364,  1.2416, -3.3214],\n",
      "        [ 4.9363,  1.2420, -3.3212],\n",
      "        [ 4.9364,  1.2415, -3.3212],\n",
      "        [ 4.9365,  1.2415, -3.3212]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:45, 23.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[-0.3947, -0.1570,  1.1246],\n",
      "        [-0.3946, -0.1570,  1.1245],\n",
      "        [-0.3948, -0.1569,  1.1246],\n",
      "        [-0.3947, -0.1570,  1.1246],\n",
      "        [-0.3947, -0.1570,  1.1246],\n",
      "        [-0.3945, -0.1571,  1.1246],\n",
      "        [-0.3947, -0.1569,  1.1244],\n",
      "        [-0.3947, -0.1570,  1.1246]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:10, 24.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[1.1937, 0.6361, 0.5947],\n",
      "        [1.1941, 0.6360, 0.5948],\n",
      "        [1.1944, 0.6359, 0.5949],\n",
      "        [1.1950, 0.6358, 0.5952],\n",
      "        [1.1938, 0.6360, 0.5946],\n",
      "        [1.1939, 0.6360, 0.5947],\n",
      "        [1.1938, 0.6361, 0.5946],\n",
      "        [1.1944, 0.6360, 0.5950]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:39, 25.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 2.6209,  1.3814, -1.4685],\n",
      "        [ 2.6214,  1.3812, -1.4690],\n",
      "        [ 2.6213,  1.3812, -1.4689],\n",
      "        [ 2.6213,  1.3813, -1.4687],\n",
      "        [ 2.6222,  1.3813, -1.4689],\n",
      "        [ 2.6206,  1.3811, -1.4688],\n",
      "        [ 2.6209,  1.3811, -1.4689],\n",
      "        [ 2.6208,  1.3811, -1.4689]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:08, 27.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.8289,  0.5408, -0.4469],\n",
      "        [ 0.8289,  0.5407, -0.4470],\n",
      "        [ 0.8286,  0.5403, -0.4470],\n",
      "        [ 0.8290,  0.5408, -0.4468],\n",
      "        [ 0.8290,  0.5408, -0.4468],\n",
      "        [ 0.8290,  0.5406, -0.4469],\n",
      "        [ 0.8290,  0.5408, -0.4469],\n",
      "        [ 0.8299,  0.5417, -0.4466]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:35, 27.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 2.5084, -0.3321, -0.8998],\n",
      "        [ 2.5084, -0.3321, -0.8998],\n",
      "        [ 2.5084, -0.3321, -0.8998],\n",
      "        [ 2.5084, -0.3321, -0.8999],\n",
      "        [ 2.5083, -0.3320, -0.8995],\n",
      "        [ 2.5084, -0.3322, -0.8998],\n",
      "        [ 2.5083, -0.3321, -0.8993],\n",
      "        [ 2.5083, -0.3321, -0.8997]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [03:02, 26.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.1175,  0.2811, -0.5423],\n",
      "        [ 1.1175,  0.2809, -0.5427],\n",
      "        [ 1.1175,  0.2811, -0.5422],\n",
      "        [ 1.1175,  0.2813, -0.5419],\n",
      "        [ 1.1175,  0.2812, -0.5423],\n",
      "        [ 1.1176,  0.2814, -0.5418],\n",
      "        [ 1.1175,  0.2812, -0.5422],\n",
      "        [ 1.1175,  0.2812, -0.5421]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:30, 27.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5426,  0.3073, -0.2189],\n",
      "        [ 0.5426,  0.3073, -0.2191],\n",
      "        [ 0.5426,  0.3074, -0.2189],\n",
      "        [ 0.5426,  0.3074, -0.2189],\n",
      "        [ 0.5426,  0.3073, -0.2189],\n",
      "        [ 0.5426,  0.3074, -0.2187],\n",
      "        [ 0.5426,  0.3073, -0.2190],\n",
      "        [ 0.5426,  0.3074, -0.2188]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [04:00, 28.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.2081, 0.2302, 0.0775],\n",
      "        [0.2081, 0.2305, 0.0778],\n",
      "        [0.2082, 0.2304, 0.0777],\n",
      "        [0.2081, 0.2305, 0.0778],\n",
      "        [0.2081, 0.2303, 0.0775],\n",
      "        [0.2081, 0.2301, 0.0774],\n",
      "        [0.2081, 0.2302, 0.0775],\n",
      "        [0.2081, 0.2304, 0.0777]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [04:31, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1528, 0.1796, 0.0789],\n",
      "        [0.1528, 0.1795, 0.0788],\n",
      "        [0.1528, 0.1795, 0.0789],\n",
      "        [0.1528, 0.1795, 0.0789],\n",
      "        [0.1527, 0.1795, 0.0787],\n",
      "        [0.1528, 0.1795, 0.0788],\n",
      "        [0.1528, 0.1795, 0.0789],\n",
      "        [0.1528, 0.1795, 0.0789]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [05:00, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1169, 0.1942, 0.0482],\n",
      "        [0.1168, 0.1942, 0.0481],\n",
      "        [0.1167, 0.1942, 0.0480],\n",
      "        [0.1168, 0.1942, 0.0481],\n",
      "        [0.1168, 0.1943, 0.0481],\n",
      "        [0.1168, 0.1942, 0.0481],\n",
      "        [0.1169, 0.1942, 0.0482],\n",
      "        [0.1168, 0.1942, 0.0481]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [05:27, 28.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1014, 0.1992, 0.0399],\n",
      "        [0.1014, 0.1992, 0.0399],\n",
      "        [0.1013, 0.1992, 0.0399],\n",
      "        [0.1013, 0.1993, 0.0399],\n",
      "        [0.1014, 0.1992, 0.0399],\n",
      "        [0.1013, 0.1992, 0.0399],\n",
      "        [0.1014, 0.1992, 0.0399],\n",
      "        [0.1013, 0.1993, 0.0399]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [05:56, 28.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1136, 0.1665, 0.0523],\n",
      "        [0.1136, 0.1665, 0.0523],\n",
      "        [0.1136, 0.1665, 0.0522],\n",
      "        [0.1136, 0.1665, 0.0523],\n",
      "        [0.1136, 0.1665, 0.0523],\n",
      "        [0.1135, 0.1665, 0.0523],\n",
      "        [0.1136, 0.1665, 0.0523],\n",
      "        [0.1136, 0.1665, 0.0523]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [06:25, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1558, 0.1553, 0.0414],\n",
      "        [0.1558, 0.1552, 0.0413],\n",
      "        [0.1558, 0.1552, 0.0412],\n",
      "        [0.1558, 0.1552, 0.0413],\n",
      "        [0.1558, 0.1552, 0.0413],\n",
      "        [0.1559, 0.1552, 0.0413],\n",
      "        [0.1558, 0.1552, 0.0412],\n",
      "        [0.1558, 0.1553, 0.0413]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [06:56, 29.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.2264, 0.1612, 0.0219],\n",
      "        [0.2265, 0.1612, 0.0219],\n",
      "        [0.2263, 0.1611, 0.0218],\n",
      "        [0.2265, 0.1612, 0.0219],\n",
      "        [0.2264, 0.1612, 0.0219],\n",
      "        [0.2264, 0.1611, 0.0219],\n",
      "        [0.2265, 0.1612, 0.0220],\n",
      "        [0.2264, 0.1612, 0.0219]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [07:23, 28.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.3196, 0.1225, 0.0104],\n",
      "        [0.3197, 0.1225, 0.0104],\n",
      "        [0.3195, 0.1223, 0.0103],\n",
      "        [0.3197, 0.1225, 0.0105],\n",
      "        [0.3196, 0.1225, 0.0104],\n",
      "        [0.3196, 0.1225, 0.0104],\n",
      "        [0.3196, 0.1225, 0.0104],\n",
      "        [0.3197, 0.1226, 0.0105]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [07:48, 27.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4508,  0.0680, -0.0292],\n",
      "        [ 0.4506,  0.0683, -0.0291],\n",
      "        [ 0.4507,  0.0681, -0.0292],\n",
      "        [ 0.4506,  0.0682, -0.0291],\n",
      "        [ 0.4506,  0.0682, -0.0292],\n",
      "        [ 0.4504,  0.0684, -0.0292],\n",
      "        [ 0.4506,  0.0683, -0.0292],\n",
      "        [ 0.4504,  0.0682, -0.0292]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [08:15, 27.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5665, -0.1121,  0.0232],\n",
      "        [ 0.5665, -0.1120,  0.0232],\n",
      "        [ 0.5667, -0.1122,  0.0232],\n",
      "        [ 0.5671, -0.1125,  0.0232],\n",
      "        [ 0.5668, -0.1123,  0.0232],\n",
      "        [ 0.5673, -0.1126,  0.0232],\n",
      "        [ 0.5664, -0.1120,  0.0232],\n",
      "        [ 0.5669, -0.1123,  0.0232]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [08:45, 28.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7910, -0.3969,  0.0714],\n",
      "        [ 0.7901, -0.3964,  0.0712],\n",
      "        [ 0.7904, -0.3967,  0.0712],\n",
      "        [ 0.7902, -0.3964,  0.0712],\n",
      "        [ 0.7904, -0.3965,  0.0712],\n",
      "        [ 0.7902, -0.3966,  0.0712],\n",
      "        [ 0.7906, -0.3967,  0.0713],\n",
      "        [ 0.7897, -0.3962,  0.0711]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [09:09, 26.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.2199, -0.9007,  0.1967],\n",
      "        [ 1.2208, -0.9012,  0.1970],\n",
      "        [ 1.2221, -0.9023,  0.1977],\n",
      "        [ 1.2210, -0.9015,  0.1973],\n",
      "        [ 1.2200, -0.9008,  0.1967],\n",
      "        [ 1.2220, -0.9021,  0.1975],\n",
      "        [ 1.2203, -0.9009,  0.1969],\n",
      "        [ 1.2209, -0.9013,  0.1970]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [09:35, 26.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.5275, -1.3117,  0.3651],\n",
      "        [ 1.5252, -1.3099,  0.3642],\n",
      "        [ 1.5266, -1.3110,  0.3647],\n",
      "        [ 1.5281, -1.3122,  0.3653],\n",
      "        [ 1.5271, -1.3114,  0.3649],\n",
      "        [ 1.5261, -1.3106,  0.3644],\n",
      "        [ 1.5269, -1.3113,  0.3647],\n",
      "        [ 1.5253, -1.3100,  0.3642]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [10:00, 26.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.7967, 0.0946, 0.5965],\n",
      "        [0.7980, 0.0929, 0.5968],\n",
      "        [0.7967, 0.0948, 0.5963],\n",
      "        [0.7964, 0.0952, 0.5964],\n",
      "        [0.7985, 0.0925, 0.5969],\n",
      "        [0.7974, 0.0938, 0.5966],\n",
      "        [0.7976, 0.0935, 0.5967],\n",
      "        [0.7976, 0.0934, 0.5967]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [10:26, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[-0.2102,  3.2822,  1.2552],\n",
      "        [-0.2107,  3.2832,  1.2556],\n",
      "        [-0.2108,  3.2833,  1.2556],\n",
      "        [-0.2109,  3.2833,  1.2555],\n",
      "        [-0.2105,  3.2831,  1.2556],\n",
      "        [-0.2104,  3.2832,  1.2557],\n",
      "        [-0.2104,  3.2825,  1.2553],\n",
      "        [-0.2109,  3.2840,  1.2559]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [10:51, 25.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.2917, 1.0722, 0.5626],\n",
      "        [0.2919, 1.0719, 0.5627],\n",
      "        [0.2917, 1.0724, 0.5627],\n",
      "        [0.2916, 1.0726, 0.5627],\n",
      "        [0.2912, 1.0735, 0.5627],\n",
      "        [0.2913, 1.0735, 0.5628],\n",
      "        [0.2919, 1.0718, 0.5626],\n",
      "        [0.2907, 1.0743, 0.5627]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [11:16, 25.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7102, -0.6845,  0.2856],\n",
      "        [ 0.7106, -0.6848,  0.2859],\n",
      "        [ 0.7113, -0.6852,  0.2862],\n",
      "        [ 0.7116, -0.6856,  0.2865],\n",
      "        [ 0.7111, -0.6852,  0.2862],\n",
      "        [ 0.7110, -0.6851,  0.2860],\n",
      "        [ 0.7115, -0.6854,  0.2864],\n",
      "        [ 0.7117, -0.6857,  0.2866]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [11:41, 25.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6414, -0.5910,  0.3079],\n",
      "        [ 0.6406, -0.5895,  0.3073],\n",
      "        [ 0.6404, -0.5893,  0.3072],\n",
      "        [ 0.6405, -0.5894,  0.3073],\n",
      "        [ 0.6408, -0.5899,  0.3075],\n",
      "        [ 0.6408, -0.5899,  0.3074],\n",
      "        [ 0.6403, -0.5890,  0.3071],\n",
      "        [ 0.6406, -0.5895,  0.3073]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [12:07, 25.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5207, -0.3872,  0.2241],\n",
      "        [ 0.5207, -0.3872,  0.2241],\n",
      "        [ 0.5209, -0.3872,  0.2241],\n",
      "        [ 0.5207, -0.3871,  0.2240],\n",
      "        [ 0.5207, -0.3870,  0.2240],\n",
      "        [ 0.5214, -0.3877,  0.2244],\n",
      "        [ 0.5210, -0.3873,  0.2241],\n",
      "        [ 0.5210, -0.3873,  0.2242]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [12:34, 25.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3863, -0.1840,  0.0744],\n",
      "        [ 0.3856, -0.1834,  0.0741],\n",
      "        [ 0.3855, -0.1833,  0.0740],\n",
      "        [ 0.3856, -0.1834,  0.0741],\n",
      "        [ 0.3846, -0.1827,  0.0737],\n",
      "        [ 0.3866, -0.1841,  0.0745],\n",
      "        [ 0.3853, -0.1831,  0.0739],\n",
      "        [ 0.3859, -0.1836,  0.0742]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [13:00, 25.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.2788, 0.0175, 0.0239],\n",
      "        [0.2791, 0.0171, 0.0238],\n",
      "        [0.2794, 0.0169, 0.0238],\n",
      "        [0.2794, 0.0169, 0.0238],\n",
      "        [0.2789, 0.0174, 0.0239],\n",
      "        [0.2792, 0.0171, 0.0238],\n",
      "        [0.2786, 0.0177, 0.0240],\n",
      "        [0.2788, 0.0174, 0.0239]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [13:25, 25.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.2906, -0.0657,  0.0400],\n",
      "        [ 0.2897, -0.0649,  0.0401],\n",
      "        [ 0.2898, -0.0651,  0.0401],\n",
      "        [ 0.2895, -0.0647,  0.0402],\n",
      "        [ 0.2900, -0.0651,  0.0401],\n",
      "        [ 0.2901, -0.0653,  0.0401],\n",
      "        [ 0.2898, -0.0650,  0.0402],\n",
      "        [ 0.2897, -0.0649,  0.0402]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "31it [13:50, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3707, -0.1950, -0.0488],\n",
      "        [ 0.3713, -0.1951, -0.0488],\n",
      "        [ 0.3704, -0.1949, -0.0488],\n",
      "        [ 0.3704, -0.1949, -0.0488],\n",
      "        [ 0.3713, -0.1951, -0.0488],\n",
      "        [ 0.3705, -0.1950, -0.0488],\n",
      "        [ 0.3713, -0.1952, -0.0490],\n",
      "        [ 0.3705, -0.1949, -0.0488]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [14:16, 25.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5380, -0.4234, -0.2303],\n",
      "        [ 0.5376, -0.4233, -0.2302],\n",
      "        [ 0.5381, -0.4234, -0.2303],\n",
      "        [ 0.5376, -0.4233, -0.2301],\n",
      "        [ 0.5373, -0.4232, -0.2301],\n",
      "        [ 0.5379, -0.4233, -0.2302],\n",
      "        [ 0.5362, -0.4230, -0.2300],\n",
      "        [ 0.5379, -0.4234, -0.2302]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "33it [14:42, 25.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7199, -0.7893, -0.2472],\n",
      "        [ 0.7205, -0.7894, -0.2474],\n",
      "        [ 0.7193, -0.7893, -0.2473],\n",
      "        [ 0.7195, -0.7893, -0.2473],\n",
      "        [ 0.7207, -0.7894, -0.2474],\n",
      "        [ 0.7209, -0.7895, -0.2474],\n",
      "        [ 0.7199, -0.7893, -0.2474],\n",
      "        [ 0.7205, -0.7894, -0.2474]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "34it [15:08, 25.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7789, -0.9752, -0.1440],\n",
      "        [ 0.7787, -0.9753, -0.1440],\n",
      "        [ 0.7790, -0.9753, -0.1440],\n",
      "        [ 0.7792, -0.9753, -0.1441],\n",
      "        [ 0.7794, -0.9753, -0.1440],\n",
      "        [ 0.7786, -0.9752, -0.1440],\n",
      "        [ 0.7784, -0.9752, -0.1440],\n",
      "        [ 0.7792, -0.9753, -0.1440]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [15:33, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.9555, -1.3263, -0.1367],\n",
      "        [ 0.9555, -1.3264, -0.1367],\n",
      "        [ 0.9545, -1.3262, -0.1367],\n",
      "        [ 0.9554, -1.3264, -0.1367],\n",
      "        [ 0.9554, -1.3264, -0.1367],\n",
      "        [ 0.9557, -1.3264, -0.1367],\n",
      "        [ 0.9553, -1.3263, -0.1366],\n",
      "        [ 0.9554, -1.3263, -0.1367]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [15:58, 25.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.0070, -1.5334, -0.0175],\n",
      "        [ 1.0072, -1.5334, -0.0175],\n",
      "        [ 1.0077, -1.5334, -0.0176],\n",
      "        [ 1.0070, -1.5335, -0.0175],\n",
      "        [ 1.0073, -1.5334, -0.0175],\n",
      "        [ 1.0074, -1.5334, -0.0175],\n",
      "        [ 1.0070, -1.5334, -0.0175],\n",
      "        [ 1.0067, -1.5334, -0.0175]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "37it [16:25, 25.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.2332, -1.9121, -0.0882],\n",
      "        [ 1.2339, -1.9121, -0.0881],\n",
      "        [ 1.2341, -1.9121, -0.0881],\n",
      "        [ 1.2338, -1.9121, -0.0881],\n",
      "        [ 1.2337, -1.9121, -0.0881],\n",
      "        [ 1.2343, -1.9122, -0.0881],\n",
      "        [ 1.2339, -1.9121, -0.0881],\n",
      "        [ 1.2343, -1.9121, -0.0881]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38it [16:50, 25.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.2012, -1.7675, -0.1051],\n",
      "        [ 1.2016, -1.7675, -0.1051],\n",
      "        [ 1.2005, -1.7675, -0.1053],\n",
      "        [ 1.2023, -1.7674, -0.1051],\n",
      "        [ 1.2012, -1.7675, -0.1051],\n",
      "        [ 1.2015, -1.7676, -0.1051],\n",
      "        [ 1.2016, -1.7674, -0.1051],\n",
      "        [ 1.2014, -1.7675, -0.1051]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [17:18, 26.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.9955, -1.3159, -0.0740],\n",
      "        [ 0.9959, -1.3159, -0.0738],\n",
      "        [ 0.9957, -1.3161, -0.0738],\n",
      "        [ 0.9970, -1.3152, -0.0739],\n",
      "        [ 0.9953, -1.3161, -0.0738],\n",
      "        [ 0.9957, -1.3159, -0.0738],\n",
      "        [ 0.9961, -1.3157, -0.0739],\n",
      "        [ 0.9960, -1.3158, -0.0739]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "40it [17:58, 30.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6408, -0.8255,  0.0958],\n",
      "        [ 0.6407, -0.8256,  0.0957],\n",
      "        [ 0.6413, -0.8255,  0.0953],\n",
      "        [ 0.6411, -0.8256,  0.0955],\n",
      "        [ 0.6404, -0.8256,  0.0960],\n",
      "        [ 0.6409, -0.8255,  0.0957],\n",
      "        [ 0.6403, -0.8255,  0.0961],\n",
      "        [ 0.6404, -0.8256,  0.0960]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "41it [18:30, 30.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4002, -0.4836,  0.1415],\n",
      "        [ 0.4002, -0.4836,  0.1414],\n",
      "        [ 0.4005, -0.4835,  0.1411],\n",
      "        [ 0.4005, -0.4835,  0.1412],\n",
      "        [ 0.4004, -0.4835,  0.1413],\n",
      "        [ 0.3999, -0.4837,  0.1415],\n",
      "        [ 0.4001, -0.4837,  0.1415],\n",
      "        [ 0.4004, -0.4836,  0.1413]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [18:59, 30.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.2616, -0.2473,  0.1411],\n",
      "        [ 0.2617, -0.2473,  0.1410],\n",
      "        [ 0.2619, -0.2472,  0.1409],\n",
      "        [ 0.2614, -0.2475,  0.1413],\n",
      "        [ 0.2619, -0.2472,  0.1410],\n",
      "        [ 0.2617, -0.2473,  0.1410],\n",
      "        [ 0.2615, -0.2474,  0.1412],\n",
      "        [ 0.2616, -0.2473,  0.1410]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "43it [19:30, 30.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.1806, -0.0959,  0.1426],\n",
      "        [ 0.1805, -0.0960,  0.1426],\n",
      "        [ 0.1806, -0.0959,  0.1425],\n",
      "        [ 0.1804, -0.0961,  0.1427],\n",
      "        [ 0.1807, -0.0958,  0.1425],\n",
      "        [ 0.1803, -0.0961,  0.1427],\n",
      "        [ 0.1806, -0.0959,  0.1426],\n",
      "        [ 0.1803, -0.0961,  0.1428]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "44it [19:57, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1320, 0.0130, 0.1167],\n",
      "        [0.1320, 0.0131, 0.1166],\n",
      "        [0.1313, 0.0126, 0.1173],\n",
      "        [0.1322, 0.0132, 0.1164],\n",
      "        [0.1322, 0.0131, 0.1164],\n",
      "        [0.1320, 0.0131, 0.1166],\n",
      "        [0.1319, 0.0129, 0.1167],\n",
      "        [0.1319, 0.0130, 0.1168]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [20:23, 28.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1218, 0.0786, 0.0743],\n",
      "        [0.1214, 0.0785, 0.0745],\n",
      "        [0.1216, 0.0786, 0.0744],\n",
      "        [0.1219, 0.0788, 0.0742],\n",
      "        [0.1219, 0.0788, 0.0742],\n",
      "        [0.1215, 0.0786, 0.0744],\n",
      "        [0.1218, 0.0787, 0.0743],\n",
      "        [0.1219, 0.0788, 0.0742]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "46it [20:51, 28.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1255, 0.1186, 0.0089],\n",
      "        [0.1253, 0.1186, 0.0089],\n",
      "        [0.1255, 0.1186, 0.0089],\n",
      "        [0.1255, 0.1186, 0.0089],\n",
      "        [0.1258, 0.1187, 0.0090],\n",
      "        [0.1254, 0.1186, 0.0090],\n",
      "        [0.1255, 0.1186, 0.0089],\n",
      "        [0.1255, 0.1186, 0.0089]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "47it [21:19, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1122, 0.1290, 0.0034],\n",
      "        [0.1121, 0.1288, 0.0034],\n",
      "        [0.1122, 0.1290, 0.0035],\n",
      "        [0.1122, 0.1290, 0.0035],\n",
      "        [0.1123, 0.1291, 0.0035],\n",
      "        [0.1124, 0.1292, 0.0036],\n",
      "        [0.1122, 0.1290, 0.0035],\n",
      "        [0.1122, 0.1290, 0.0034]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "48it [21:45, 27.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1152, 0.1182, 0.0058],\n",
      "        [0.1153, 0.1180, 0.0058],\n",
      "        [0.1153, 0.1182, 0.0058],\n",
      "        [0.1153, 0.1182, 0.0058],\n",
      "        [0.1153, 0.1182, 0.0058],\n",
      "        [0.1152, 0.1182, 0.0057],\n",
      "        [0.1152, 0.1182, 0.0057],\n",
      "        [0.1152, 0.1182, 0.0058]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "49it [22:11, 27.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1289, 0.0858, 0.0189],\n",
      "        [0.1294, 0.0853, 0.0194],\n",
      "        [0.1296, 0.0852, 0.0195],\n",
      "        [0.1292, 0.0855, 0.0192],\n",
      "        [0.1296, 0.0852, 0.0195],\n",
      "        [0.1291, 0.0855, 0.0191],\n",
      "        [0.1292, 0.0855, 0.0192],\n",
      "        [0.1284, 0.0861, 0.0185]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "50it [22:38, 26.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1579, 0.0437, 0.0341],\n",
      "        [0.1580, 0.0436, 0.0342],\n",
      "        [0.1575, 0.0439, 0.0337],\n",
      "        [0.1579, 0.0437, 0.0341],\n",
      "        [0.1577, 0.0438, 0.0339],\n",
      "        [0.1578, 0.0438, 0.0340],\n",
      "        [0.1583, 0.0435, 0.0344],\n",
      "        [0.1576, 0.0439, 0.0339]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "51it [23:08, 27.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.1838, 0.0383, 0.0448],\n",
      "        [0.1838, 0.0383, 0.0448],\n",
      "        [0.1837, 0.0384, 0.0447],\n",
      "        [0.1840, 0.0382, 0.0450],\n",
      "        [0.1838, 0.0383, 0.0449],\n",
      "        [0.1845, 0.0381, 0.0454],\n",
      "        [0.1843, 0.0381, 0.0453],\n",
      "        [0.1846, 0.0380, 0.0456]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "52it [23:39, 28.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[0.2348, 0.0077, 0.0734],\n",
      "        [0.2345, 0.0078, 0.0732],\n",
      "        [0.2348, 0.0078, 0.0734],\n",
      "        [0.2347, 0.0078, 0.0734],\n",
      "        [0.2342, 0.0080, 0.0729],\n",
      "        [0.2338, 0.0083, 0.0724],\n",
      "        [0.2347, 0.0078, 0.0733],\n",
      "        [0.2347, 0.0078, 0.0733]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "53it [24:08, 29.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.2941, -0.0300,  0.1159],\n",
      "        [ 0.2940, -0.0301,  0.1159],\n",
      "        [ 0.2943, -0.0298,  0.1161],\n",
      "        [ 0.2938, -0.0302,  0.1158],\n",
      "        [ 0.2939, -0.0301,  0.1158],\n",
      "        [ 0.2939, -0.0301,  0.1158],\n",
      "        [ 0.2945, -0.0297,  0.1162],\n",
      "        [ 0.2942, -0.0300,  0.1160]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "54it [24:41, 30.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3472, -0.0548,  0.1273],\n",
      "        [ 0.3468, -0.0549,  0.1270],\n",
      "        [ 0.3469, -0.0549,  0.1271],\n",
      "        [ 0.3467, -0.0549,  0.1270],\n",
      "        [ 0.3474, -0.0546,  0.1275],\n",
      "        [ 0.3472, -0.0547,  0.1274],\n",
      "        [ 0.3474, -0.0547,  0.1275],\n",
      "        [ 0.3472, -0.0548,  0.1273]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "55it [25:17, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4009, -0.0408,  0.1112],\n",
      "        [ 0.4005, -0.0410,  0.1109],\n",
      "        [ 0.4013, -0.0407,  0.1115],\n",
      "        [ 0.4010, -0.0408,  0.1113],\n",
      "        [ 0.4007, -0.0409,  0.1110],\n",
      "        [ 0.4007, -0.0409,  0.1110],\n",
      "        [ 0.4007, -0.0409,  0.1110],\n",
      "        [ 0.4006, -0.0410,  0.1109]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "56it [25:47, 31.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4614, -0.0307,  0.0867],\n",
      "        [ 0.4622, -0.0303,  0.0870],\n",
      "        [ 0.4621, -0.0303,  0.0870],\n",
      "        [ 0.4614, -0.0306,  0.0867],\n",
      "        [ 0.4618, -0.0305,  0.0869],\n",
      "        [ 0.4617, -0.0305,  0.0868],\n",
      "        [ 0.4625, -0.0302,  0.0872],\n",
      "        [ 0.4620, -0.0304,  0.0869]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "57it [26:13, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5531, -0.0830,  0.1289],\n",
      "        [ 0.5528, -0.0830,  0.1288],\n",
      "        [ 0.5539, -0.0828,  0.1291],\n",
      "        [ 0.5529, -0.0830,  0.1288],\n",
      "        [ 0.5532, -0.0830,  0.1289],\n",
      "        [ 0.5528, -0.0831,  0.1288],\n",
      "        [ 0.5537, -0.0828,  0.1291],\n",
      "        [ 0.5532, -0.0830,  0.1289]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "58it [26:41, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6496, -0.1386,  0.1498],\n",
      "        [ 0.6492, -0.1385,  0.1496],\n",
      "        [ 0.6490, -0.1385,  0.1495],\n",
      "        [ 0.6490, -0.1385,  0.1495],\n",
      "        [ 0.6483, -0.1384,  0.1492],\n",
      "        [ 0.6488, -0.1385,  0.1494],\n",
      "        [ 0.6484, -0.1384,  0.1492],\n",
      "        [ 0.6492, -0.1385,  0.1496]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "59it [27:12, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.8290, -0.2629,  0.1939],\n",
      "        [ 0.8276, -0.2625,  0.1934],\n",
      "        [ 0.8267, -0.2622,  0.1930],\n",
      "        [ 0.8275, -0.2625,  0.1933],\n",
      "        [ 0.8281, -0.2626,  0.1935],\n",
      "        [ 0.8255, -0.2618,  0.1925],\n",
      "        [ 0.8285, -0.2628,  0.1937],\n",
      "        [ 0.8272, -0.2624,  0.1932]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "60it [27:41, 29.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.9815, -0.3692,  0.1877],\n",
      "        [ 0.9837, -0.3702,  0.1886],\n",
      "        [ 0.9837, -0.3702,  0.1886],\n",
      "        [ 0.9835, -0.3701,  0.1885],\n",
      "        [ 0.9840, -0.3703,  0.1887],\n",
      "        [ 0.9840, -0.3703,  0.1887],\n",
      "        [ 0.9850, -0.3708,  0.1892],\n",
      "        [ 0.9824, -0.3696,  0.1880]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "61it [28:14, 30.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.1861, -0.5111,  0.1719],\n",
      "        [ 1.1844, -0.5104,  0.1719],\n",
      "        [ 1.1853, -0.5108,  0.1719],\n",
      "        [ 1.1836, -0.5101,  0.1719],\n",
      "        [ 1.1850, -0.5107,  0.1719],\n",
      "        [ 1.1845, -0.5105,  0.1719],\n",
      "        [ 1.1852, -0.5108,  0.1719],\n",
      "        [ 1.1849, -0.5106,  0.1719]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62it [28:53, 33.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.4823, -0.6715,  0.0929],\n",
      "        [ 1.4838, -0.6721,  0.0926],\n",
      "        [ 1.4847, -0.6725,  0.0925],\n",
      "        [ 1.4833, -0.6719,  0.0927],\n",
      "        [ 1.4833, -0.6719,  0.0927],\n",
      "        [ 1.4826, -0.6716,  0.0928],\n",
      "        [ 1.4828, -0.6717,  0.0928],\n",
      "        [ 1.4808, -0.6709,  0.0930]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "63it [29:22, 31.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.2998, -0.5743,  0.1037],\n",
      "        [ 1.3013, -0.5750,  0.1040],\n",
      "        [ 1.2991, -0.5740,  0.1035],\n",
      "        [ 1.2983, -0.5736,  0.1033],\n",
      "        [ 1.3013, -0.5749,  0.1040],\n",
      "        [ 1.2991, -0.5740,  0.1035],\n",
      "        [ 1.2995, -0.5741,  0.1036],\n",
      "        [ 1.2996, -0.5742,  0.1036]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "64it [29:49, 30.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 1.1245, -0.4906,  0.1373],\n",
      "        [ 1.1228, -0.4897,  0.1365],\n",
      "        [ 1.1227, -0.4896,  0.1365],\n",
      "        [ 1.1232, -0.4899,  0.1367],\n",
      "        [ 1.1233, -0.4900,  0.1368],\n",
      "        [ 1.1240, -0.4904,  0.1371],\n",
      "        [ 1.1227, -0.4896,  0.1365],\n",
      "        [ 1.1229, -0.4897,  0.1366]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "65it [30:16, 29.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.8628, -0.3370,  0.1193],\n",
      "        [ 0.8612, -0.3359,  0.1183],\n",
      "        [ 0.8628, -0.3370,  0.1194],\n",
      "        [ 0.8624, -0.3367,  0.1191],\n",
      "        [ 0.8628, -0.3369,  0.1193],\n",
      "        [ 0.8635, -0.3375,  0.1199],\n",
      "        [ 0.8635, -0.3375,  0.1198],\n",
      "        [ 0.8620, -0.3364,  0.1188]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "66it [30:50, 30.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6474, -0.2277,  0.1247],\n",
      "        [ 0.6469, -0.2275,  0.1242],\n",
      "        [ 0.6476, -0.2278,  0.1248],\n",
      "        [ 0.6472, -0.2276,  0.1245],\n",
      "        [ 0.6479, -0.2279,  0.1251],\n",
      "        [ 0.6479, -0.2279,  0.1252],\n",
      "        [ 0.6475, -0.2277,  0.1247],\n",
      "        [ 0.6483, -0.2281,  0.1255]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "67it [31:26, 32.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5288, -0.1478,  0.1401],\n",
      "        [ 0.5286, -0.1478,  0.1399],\n",
      "        [ 0.5281, -0.1476,  0.1393],\n",
      "        [ 0.5285, -0.1478,  0.1397],\n",
      "        [ 0.5287, -0.1478,  0.1400],\n",
      "        [ 0.5287, -0.1478,  0.1400],\n",
      "        [ 0.5286, -0.1478,  0.1399],\n",
      "        [ 0.5287, -0.1478,  0.1399]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "68it [32:08, 35.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4541, -0.0955,  0.0910],\n",
      "        [ 0.4542, -0.0956,  0.0911],\n",
      "        [ 0.4544, -0.0956,  0.0913],\n",
      "        [ 0.4541, -0.0955,  0.0910],\n",
      "        [ 0.4543, -0.0956,  0.0912],\n",
      "        [ 0.4542, -0.0956,  0.0911],\n",
      "        [ 0.4541, -0.0955,  0.0910],\n",
      "        [ 0.4542, -0.0955,  0.0911]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "69it [32:40, 34.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3935, -0.0486,  0.0293],\n",
      "        [ 0.3935, -0.0486,  0.0292],\n",
      "        [ 0.3936, -0.0486,  0.0293],\n",
      "        [ 0.3936, -0.0486,  0.0293],\n",
      "        [ 0.3934, -0.0486,  0.0292],\n",
      "        [ 0.3934, -0.0486,  0.0293],\n",
      "        [ 0.3936, -0.0486,  0.0293],\n",
      "        [ 0.3936, -0.0486,  0.0293]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "70it [33:10, 33.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3451, -0.0154, -0.0004],\n",
      "        [ 0.3451, -0.0155, -0.0004],\n",
      "        [ 0.3451, -0.0155, -0.0004],\n",
      "        [ 0.3451, -0.0155, -0.0004],\n",
      "        [ 0.3451, -0.0155, -0.0004],\n",
      "        [ 0.3451, -0.0155, -0.0004],\n",
      "        [ 0.3451, -0.0155, -0.0004],\n",
      "        [ 0.3451, -0.0155, -0.0004]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "71it [33:39, 31.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3256, -0.0038, -0.0246],\n",
      "        [ 0.3256, -0.0038, -0.0246],\n",
      "        [ 0.3256, -0.0038, -0.0246],\n",
      "        [ 0.3256, -0.0038, -0.0247],\n",
      "        [ 0.3256, -0.0038, -0.0247],\n",
      "        [ 0.3256, -0.0038, -0.0247],\n",
      "        [ 0.3256, -0.0038, -0.0247],\n",
      "        [ 0.3256, -0.0038, -0.0247]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "72it [34:05, 30.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3209, -0.0016, -0.0398],\n",
      "        [ 0.3210, -0.0016, -0.0396],\n",
      "        [ 0.3210, -0.0016, -0.0397],\n",
      "        [ 0.3210, -0.0016, -0.0396],\n",
      "        [ 0.3211, -0.0016, -0.0396],\n",
      "        [ 0.3210, -0.0016, -0.0397],\n",
      "        [ 0.3210, -0.0016, -0.0397],\n",
      "        [ 0.3211, -0.0016, -0.0396]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "73it [34:36, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3044,  0.0068, -0.0617],\n",
      "        [ 0.3045,  0.0067, -0.0615],\n",
      "        [ 0.3044,  0.0067, -0.0616],\n",
      "        [ 0.3043,  0.0068, -0.0618],\n",
      "        [ 0.3045,  0.0067, -0.0615],\n",
      "        [ 0.3044,  0.0067, -0.0616],\n",
      "        [ 0.3044,  0.0067, -0.0616],\n",
      "        [ 0.3044,  0.0067, -0.0617]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "74it [35:07, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3181, -0.0006, -0.0632],\n",
      "        [ 0.3182, -0.0007, -0.0631],\n",
      "        [ 0.3182, -0.0008, -0.0630],\n",
      "        [ 0.3181, -0.0007, -0.0632],\n",
      "        [ 0.3182, -0.0007, -0.0631],\n",
      "        [ 0.3182, -0.0007, -0.0631],\n",
      "        [ 0.3181, -0.0007, -0.0632],\n",
      "        [ 0.3182, -0.0008, -0.0629]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "75it [35:34, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3406, -0.0187, -0.0544],\n",
      "        [ 0.3406, -0.0188, -0.0541],\n",
      "        [ 0.3407, -0.0186, -0.0547],\n",
      "        [ 0.3407, -0.0187, -0.0545],\n",
      "        [ 0.3407, -0.0187, -0.0545],\n",
      "        [ 0.3407, -0.0187, -0.0543],\n",
      "        [ 0.3407, -0.0187, -0.0543],\n",
      "        [ 0.3407, -0.0187, -0.0544]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "76it [35:59, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3521, -0.0268, -0.0586],\n",
      "        [ 0.3522, -0.0268, -0.0587],\n",
      "        [ 0.3521, -0.0268, -0.0587],\n",
      "        [ 0.3523, -0.0268, -0.0588],\n",
      "        [ 0.3522, -0.0268, -0.0587],\n",
      "        [ 0.3522, -0.0268, -0.0587],\n",
      "        [ 0.3521, -0.0268, -0.0587],\n",
      "        [ 0.3522, -0.0268, -0.0587]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "77it [36:27, 27.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3630, -0.0309, -0.0759],\n",
      "        [ 0.3627, -0.0309, -0.0756],\n",
      "        [ 0.3626, -0.0309, -0.0756],\n",
      "        [ 0.3628, -0.0309, -0.0757],\n",
      "        [ 0.3629, -0.0309, -0.0758],\n",
      "        [ 0.3630, -0.0309, -0.0758],\n",
      "        [ 0.3628, -0.0309, -0.0757],\n",
      "        [ 0.3628, -0.0309, -0.0757]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "78it [36:53, 27.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3792, -0.0412, -0.0836],\n",
      "        [ 0.3793, -0.0412, -0.0837],\n",
      "        [ 0.3792, -0.0413, -0.0836],\n",
      "        [ 0.3793, -0.0412, -0.0837],\n",
      "        [ 0.3792, -0.0413, -0.0836],\n",
      "        [ 0.3792, -0.0412, -0.0836],\n",
      "        [ 0.3794, -0.0412, -0.0837],\n",
      "        [ 0.3792, -0.0413, -0.0836]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "79it [37:19, 27.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3916, -0.0524, -0.0812],\n",
      "        [ 0.3916, -0.0524, -0.0812],\n",
      "        [ 0.3914, -0.0525, -0.0810],\n",
      "        [ 0.3915, -0.0524, -0.0811],\n",
      "        [ 0.3916, -0.0524, -0.0811],\n",
      "        [ 0.3915, -0.0524, -0.0811],\n",
      "        [ 0.3914, -0.0525, -0.0810],\n",
      "        [ 0.3915, -0.0524, -0.0811]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "80it [37:45, 26.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4160, -0.0699, -0.0791],\n",
      "        [ 0.4161, -0.0699, -0.0792],\n",
      "        [ 0.4159, -0.0700, -0.0790],\n",
      "        [ 0.4161, -0.0699, -0.0792],\n",
      "        [ 0.4160, -0.0699, -0.0792],\n",
      "        [ 0.4159, -0.0699, -0.0791],\n",
      "        [ 0.4159, -0.0700, -0.0791],\n",
      "        [ 0.4159, -0.0700, -0.0791]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "81it [38:11, 26.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4367, -0.0818, -0.0887],\n",
      "        [ 0.4365, -0.0819, -0.0886],\n",
      "        [ 0.4367, -0.0818, -0.0887],\n",
      "        [ 0.4366, -0.0818, -0.0887],\n",
      "        [ 0.4366, -0.0818, -0.0887],\n",
      "        [ 0.4367, -0.0818, -0.0888],\n",
      "        [ 0.4368, -0.0818, -0.0888],\n",
      "        [ 0.4368, -0.0818, -0.0888]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "82it [38:38, 26.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4450, -0.0822, -0.1121],\n",
      "        [ 0.4448, -0.0822, -0.1120],\n",
      "        [ 0.4453, -0.0821, -0.1123],\n",
      "        [ 0.4449, -0.0822, -0.1120],\n",
      "        [ 0.4450, -0.0822, -0.1121],\n",
      "        [ 0.4448, -0.0822, -0.1120],\n",
      "        [ 0.4450, -0.0821, -0.1121],\n",
      "        [ 0.4450, -0.0821, -0.1121]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "83it [39:03, 26.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4463, -0.0773, -0.1374],\n",
      "        [ 0.4460, -0.0774, -0.1372],\n",
      "        [ 0.4461, -0.0773, -0.1373],\n",
      "        [ 0.4460, -0.0774, -0.1372],\n",
      "        [ 0.4461, -0.0773, -0.1373],\n",
      "        [ 0.4458, -0.0774, -0.1371],\n",
      "        [ 0.4459, -0.0774, -0.1372],\n",
      "        [ 0.4459, -0.0774, -0.1372]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "84it [39:29, 26.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4492, -0.0743, -0.1601],\n",
      "        [ 0.4492, -0.0743, -0.1601],\n",
      "        [ 0.4491, -0.0743, -0.1600],\n",
      "        [ 0.4494, -0.0742, -0.1601],\n",
      "        [ 0.4494, -0.0742, -0.1601],\n",
      "        [ 0.4493, -0.0743, -0.1601],\n",
      "        [ 0.4493, -0.0743, -0.1601],\n",
      "        [ 0.4492, -0.0743, -0.1601]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "85it [39:55, 26.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4598, -0.0737, -0.1881],\n",
      "        [ 0.4595, -0.0737, -0.1881],\n",
      "        [ 0.4597, -0.0737, -0.1881],\n",
      "        [ 0.4600, -0.0737, -0.1881],\n",
      "        [ 0.4597, -0.0737, -0.1881],\n",
      "        [ 0.4596, -0.0737, -0.1881],\n",
      "        [ 0.4595, -0.0738, -0.1880],\n",
      "        [ 0.4596, -0.0737, -0.1881]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "86it [40:21, 25.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([1, 20, 1024])\n",
      "y_pred: tensor([[ 0.4699, -0.0787, -0.1947]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [40:35, 28.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss at epoch 0: 1.1499820947647095\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4384, -0.0522, -0.2230],\n",
      "        [ 0.4385, -0.0521, -0.2230],\n",
      "        [ 0.4384, -0.0522, -0.2230],\n",
      "        [ 0.4384, -0.0522, -0.2230],\n",
      "        [ 0.4383, -0.0522, -0.2230],\n",
      "        [ 0.4383, -0.0522, -0.2230],\n",
      "        [ 0.4385, -0.0521, -0.2230],\n",
      "        [ 0.4387, -0.0521, -0.2230]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:24, 24.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4109, -0.0271, -0.2536],\n",
      "        [ 0.4112, -0.0270, -0.2537],\n",
      "        [ 0.4116, -0.0269, -0.2537],\n",
      "        [ 0.4114, -0.0270, -0.2537],\n",
      "        [ 0.4114, -0.0270, -0.2537],\n",
      "        [ 0.4114, -0.0270, -0.2537],\n",
      "        [ 0.4114, -0.0270, -0.2537],\n",
      "        [ 0.4113, -0.0270, -0.2537]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [00:49, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4000, -0.0153, -0.2682],\n",
      "        [ 0.4000, -0.0153, -0.2682],\n",
      "        [ 0.3999, -0.0153, -0.2682],\n",
      "        [ 0.3998, -0.0154, -0.2681],\n",
      "        [ 0.4000, -0.0153, -0.2682],\n",
      "        [ 0.3998, -0.0154, -0.2681],\n",
      "        [ 0.4000, -0.0153, -0.2682],\n",
      "        [ 0.3999, -0.0153, -0.2682]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [01:15, 25.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3906, -0.0034, -0.2876],\n",
      "        [ 0.3904, -0.0034, -0.2876],\n",
      "        [ 0.3905, -0.0034, -0.2876],\n",
      "        [ 0.3909, -0.0032, -0.2877],\n",
      "        [ 0.3906, -0.0034, -0.2876],\n",
      "        [ 0.3906, -0.0034, -0.2876],\n",
      "        [ 0.3908, -0.0033, -0.2876],\n",
      "        [ 0.3908, -0.0033, -0.2876]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [01:41, 25.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3715,  0.0132, -0.3050],\n",
      "        [ 0.3718,  0.0134, -0.3050],\n",
      "        [ 0.3715,  0.0133, -0.3050],\n",
      "        [ 0.3712,  0.0131, -0.3049],\n",
      "        [ 0.3714,  0.0132, -0.3049],\n",
      "        [ 0.3714,  0.0132, -0.3049],\n",
      "        [ 0.3715,  0.0132, -0.3049],\n",
      "        [ 0.3715,  0.0132, -0.3050]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [02:06, 25.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3559,  0.0291, -0.3280],\n",
      "        [ 0.3557,  0.0291, -0.3279],\n",
      "        [ 0.3557,  0.0291, -0.3279],\n",
      "        [ 0.3555,  0.0290, -0.3277],\n",
      "        [ 0.3556,  0.0291, -0.3278],\n",
      "        [ 0.3556,  0.0290, -0.3278],\n",
      "        [ 0.3558,  0.0291, -0.3279],\n",
      "        [ 0.3557,  0.0291, -0.3279]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [02:32, 25.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3416,  0.0364, -0.3269],\n",
      "        [ 0.3413,  0.0364, -0.3267],\n",
      "        [ 0.3414,  0.0364, -0.3268],\n",
      "        [ 0.3413,  0.0364, -0.3267],\n",
      "        [ 0.3413,  0.0364, -0.3267],\n",
      "        [ 0.3415,  0.0364, -0.3268],\n",
      "        [ 0.3413,  0.0364, -0.3267],\n",
      "        [ 0.3414,  0.0364, -0.3268]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [02:57, 25.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3261,  0.0437, -0.3245],\n",
      "        [ 0.3260,  0.0436, -0.3244],\n",
      "        [ 0.3260,  0.0436, -0.3244],\n",
      "        [ 0.3261,  0.0437, -0.3245],\n",
      "        [ 0.3261,  0.0437, -0.3245],\n",
      "        [ 0.3259,  0.0436, -0.3242],\n",
      "        [ 0.3258,  0.0436, -0.3243],\n",
      "        [ 0.3260,  0.0437, -0.3245]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [03:23, 25.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3085,  0.0544, -0.3312],\n",
      "        [ 0.3083,  0.0544, -0.3312],\n",
      "        [ 0.3085,  0.0544, -0.3312],\n",
      "        [ 0.3083,  0.0544, -0.3312],\n",
      "        [ 0.3084,  0.0544, -0.3312],\n",
      "        [ 0.3084,  0.0544, -0.3312],\n",
      "        [ 0.3083,  0.0544, -0.3312],\n",
      "        [ 0.3081,  0.0544, -0.3311]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [03:48, 25.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3030,  0.0581, -0.3305],\n",
      "        [ 0.3030,  0.0581, -0.3305],\n",
      "        [ 0.3030,  0.0581, -0.3305],\n",
      "        [ 0.3032,  0.0582, -0.3307],\n",
      "        [ 0.3030,  0.0581, -0.3305],\n",
      "        [ 0.3031,  0.0581, -0.3306],\n",
      "        [ 0.3031,  0.0581, -0.3306],\n",
      "        [ 0.3030,  0.0581, -0.3305]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "10it [04:14, 25.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.2998,  0.0628, -0.3370],\n",
      "        [ 0.2997,  0.0628, -0.3369],\n",
      "        [ 0.2997,  0.0628, -0.3369],\n",
      "        [ 0.2999,  0.0629, -0.3370],\n",
      "        [ 0.2997,  0.0628, -0.3370],\n",
      "        [ 0.3000,  0.0629, -0.3371],\n",
      "        [ 0.2997,  0.0628, -0.3369],\n",
      "        [ 0.2997,  0.0628, -0.3369]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "11it [04:45, 27.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.2983,  0.0685, -0.3496],\n",
      "        [ 0.2985,  0.0686, -0.3497],\n",
      "        [ 0.2984,  0.0685, -0.3497],\n",
      "        [ 0.2985,  0.0686, -0.3498],\n",
      "        [ 0.2985,  0.0686, -0.3498],\n",
      "        [ 0.2984,  0.0685, -0.3497],\n",
      "        [ 0.2987,  0.0687, -0.3499],\n",
      "        [ 0.2985,  0.0686, -0.3497]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "12it [05:11, 26.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3019,  0.0676, -0.3473],\n",
      "        [ 0.3019,  0.0677, -0.3473],\n",
      "        [ 0.3018,  0.0676, -0.3472],\n",
      "        [ 0.3019,  0.0677, -0.3474],\n",
      "        [ 0.3020,  0.0678, -0.3475],\n",
      "        [ 0.3018,  0.0676, -0.3472],\n",
      "        [ 0.3020,  0.0678, -0.3475],\n",
      "        [ 0.3019,  0.0677, -0.3474]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "13it [05:37, 26.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3098,  0.0701, -0.3623],\n",
      "        [ 0.3097,  0.0700, -0.3621],\n",
      "        [ 0.3098,  0.0701, -0.3623],\n",
      "        [ 0.3097,  0.0700, -0.3622],\n",
      "        [ 0.3097,  0.0700, -0.3621],\n",
      "        [ 0.3096,  0.0699, -0.3619],\n",
      "        [ 0.3098,  0.0701, -0.3624],\n",
      "        [ 0.3098,  0.0702, -0.3625]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "14it [06:03, 26.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3251,  0.0662, -0.3696],\n",
      "        [ 0.3251,  0.0661, -0.3695],\n",
      "        [ 0.3251,  0.0661, -0.3695],\n",
      "        [ 0.3251,  0.0662, -0.3696],\n",
      "        [ 0.3251,  0.0662, -0.3697],\n",
      "        [ 0.3250,  0.0661, -0.3695],\n",
      "        [ 0.3250,  0.0661, -0.3694],\n",
      "        [ 0.3251,  0.0661, -0.3696]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "15it [06:28, 25.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3467,  0.0567, -0.3706],\n",
      "        [ 0.3467,  0.0567, -0.3706],\n",
      "        [ 0.3467,  0.0567, -0.3706],\n",
      "        [ 0.3468,  0.0568, -0.3709],\n",
      "        [ 0.3467,  0.0568, -0.3707],\n",
      "        [ 0.3467,  0.0567, -0.3706],\n",
      "        [ 0.3467,  0.0567, -0.3706],\n",
      "        [ 0.3468,  0.0568, -0.3708]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "16it [06:53, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3835,  0.0442, -0.3874],\n",
      "        [ 0.3832,  0.0441, -0.3872],\n",
      "        [ 0.3834,  0.0442, -0.3874],\n",
      "        [ 0.3833,  0.0441, -0.3872],\n",
      "        [ 0.3833,  0.0441, -0.3873],\n",
      "        [ 0.3829,  0.0440, -0.3870],\n",
      "        [ 0.3832,  0.0441, -0.3873],\n",
      "        [ 0.3835,  0.0442, -0.3874]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "17it [07:18, 25.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4129,  0.0334, -0.4012],\n",
      "        [ 0.4130,  0.0334, -0.4012],\n",
      "        [ 0.4132,  0.0335, -0.4014],\n",
      "        [ 0.4130,  0.0334, -0.4013],\n",
      "        [ 0.4132,  0.0335, -0.4014],\n",
      "        [ 0.4131,  0.0334, -0.4013],\n",
      "        [ 0.4130,  0.0334, -0.4012],\n",
      "        [ 0.4131,  0.0334, -0.4014]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "18it [07:44, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4487,  0.0178, -0.4107],\n",
      "        [ 0.4487,  0.0178, -0.4107],\n",
      "        [ 0.4486,  0.0178, -0.4107],\n",
      "        [ 0.4485,  0.0177, -0.4105],\n",
      "        [ 0.4488,  0.0178, -0.4108],\n",
      "        [ 0.4488,  0.0178, -0.4107],\n",
      "        [ 0.4488,  0.0178, -0.4108],\n",
      "        [ 0.4486,  0.0178, -0.4106]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "19it [08:09, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4794, -0.0024, -0.4039],\n",
      "        [ 0.4793, -0.0024, -0.4039],\n",
      "        [ 0.4794, -0.0024, -0.4039],\n",
      "        [ 0.4794, -0.0024, -0.4039],\n",
      "        [ 0.4793, -0.0024, -0.4037],\n",
      "        [ 0.4795, -0.0024, -0.4041],\n",
      "        [ 0.4795, -0.0024, -0.4040],\n",
      "        [ 0.4796, -0.0024, -0.4041]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "20it [08:35, 25.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5235, -0.0275, -0.4091],\n",
      "        [ 0.5238, -0.0275, -0.4094],\n",
      "        [ 0.5237, -0.0275, -0.4093],\n",
      "        [ 0.5230, -0.0275, -0.4086],\n",
      "        [ 0.5236, -0.0275, -0.4092],\n",
      "        [ 0.5235, -0.0275, -0.4091],\n",
      "        [ 0.5237, -0.0275, -0.4093],\n",
      "        [ 0.5237, -0.0275, -0.4093]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "21it [08:59, 25.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5816, -0.0630, -0.4136],\n",
      "        [ 0.5818, -0.0631, -0.4137],\n",
      "        [ 0.5820, -0.0631, -0.4139],\n",
      "        [ 0.5820, -0.0631, -0.4139],\n",
      "        [ 0.5818, -0.0631, -0.4137],\n",
      "        [ 0.5818, -0.0631, -0.4138],\n",
      "        [ 0.5819, -0.0631, -0.4138],\n",
      "        [ 0.5819, -0.0631, -0.4138]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "22it [09:25, 25.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6328, -0.1024, -0.3960],\n",
      "        [ 0.6329, -0.1025, -0.3960],\n",
      "        [ 0.6326, -0.1024, -0.3958],\n",
      "        [ 0.6328, -0.1025, -0.3960],\n",
      "        [ 0.6330, -0.1025, -0.3961],\n",
      "        [ 0.6330, -0.1025, -0.3961],\n",
      "        [ 0.6330, -0.1025, -0.3961],\n",
      "        [ 0.6327, -0.1024, -0.3959]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "23it [09:51, 25.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6465, -0.1305, -0.3407],\n",
      "        [ 0.6465, -0.1305, -0.3408],\n",
      "        [ 0.6464, -0.1305, -0.3407],\n",
      "        [ 0.6466, -0.1305, -0.3408],\n",
      "        [ 0.6465, -0.1305, -0.3407],\n",
      "        [ 0.6464, -0.1304, -0.3407],\n",
      "        [ 0.6465, -0.1305, -0.3407],\n",
      "        [ 0.6468, -0.1306, -0.3409]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "24it [10:16, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6658, -0.1585, -0.2910],\n",
      "        [ 0.6660, -0.1586, -0.2911],\n",
      "        [ 0.6657, -0.1585, -0.2910],\n",
      "        [ 0.6661, -0.1586, -0.2911],\n",
      "        [ 0.6664, -0.1586, -0.2912],\n",
      "        [ 0.6658, -0.1585, -0.2910],\n",
      "        [ 0.6659, -0.1585, -0.2911],\n",
      "        [ 0.6659, -0.1585, -0.2910]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "25it [10:41, 25.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6912, -0.1892, -0.2462],\n",
      "        [ 0.6912, -0.1892, -0.2462],\n",
      "        [ 0.6908, -0.1891, -0.2461],\n",
      "        [ 0.6917, -0.1893, -0.2462],\n",
      "        [ 0.6914, -0.1893, -0.2462],\n",
      "        [ 0.6913, -0.1892, -0.2462],\n",
      "        [ 0.6911, -0.1892, -0.2461],\n",
      "        [ 0.6912, -0.1892, -0.2461]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "26it [11:05, 24.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7081, -0.2157, -0.2064],\n",
      "        [ 0.7079, -0.2157, -0.2064],\n",
      "        [ 0.7079, -0.2156, -0.2064],\n",
      "        [ 0.7083, -0.2158, -0.2064],\n",
      "        [ 0.7083, -0.2158, -0.2064],\n",
      "        [ 0.7074, -0.2155, -0.2063],\n",
      "        [ 0.7082, -0.2157, -0.2064],\n",
      "        [ 0.7080, -0.2157, -0.2064]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "27it [11:35, 26.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7505, -0.2611, -0.1723],\n",
      "        [ 0.7505, -0.2611, -0.1723],\n",
      "        [ 0.7505, -0.2610, -0.1722],\n",
      "        [ 0.7504, -0.2610, -0.1723],\n",
      "        [ 0.7503, -0.2610, -0.1723],\n",
      "        [ 0.7501, -0.2609, -0.1723],\n",
      "        [ 0.7502, -0.2610, -0.1723],\n",
      "        [ 0.7501, -0.2609, -0.1723]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "28it [12:01, 26.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7657, -0.2913, -0.1281],\n",
      "        [ 0.7654, -0.2911, -0.1281],\n",
      "        [ 0.7653, -0.2911, -0.1281],\n",
      "        [ 0.7659, -0.2914, -0.1281],\n",
      "        [ 0.7656, -0.2912, -0.1281],\n",
      "        [ 0.7654, -0.2911, -0.1281],\n",
      "        [ 0.7658, -0.2913, -0.1281],\n",
      "        [ 0.7653, -0.2911, -0.1281]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "29it [12:26, 25.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7622, -0.3013, -0.0970],\n",
      "        [ 0.7623, -0.3013, -0.0970],\n",
      "        [ 0.7626, -0.3015, -0.0970],\n",
      "        [ 0.7625, -0.3014, -0.0970],\n",
      "        [ 0.7626, -0.3014, -0.0970],\n",
      "        [ 0.7624, -0.3013, -0.0970],\n",
      "        [ 0.7625, -0.3014, -0.0970],\n",
      "        [ 0.7626, -0.3014, -0.0970]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "30it [12:51, 25.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7565, -0.3110, -0.0610],\n",
      "        [ 0.7568, -0.3111, -0.0610],\n",
      "        [ 0.7564, -0.3109, -0.0610],\n",
      "        [ 0.7566, -0.3110, -0.0610],\n",
      "        [ 0.7569, -0.3112, -0.0610],\n",
      "        [ 0.7571, -0.3113, -0.0609],\n",
      "        [ 0.7563, -0.3108, -0.0611],\n",
      "        [ 0.7565, -0.3110, -0.0610]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "31it [13:16, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7147, -0.2896, -0.0459],\n",
      "        [ 0.7149, -0.2897, -0.0458],\n",
      "        [ 0.7149, -0.2897, -0.0459],\n",
      "        [ 0.7150, -0.2898, -0.0458],\n",
      "        [ 0.7151, -0.2898, -0.0458],\n",
      "        [ 0.7152, -0.2898, -0.0458],\n",
      "        [ 0.7148, -0.2897, -0.0459],\n",
      "        [ 0.7151, -0.2898, -0.0458]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "32it [13:41, 25.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6830, -0.2717, -0.0428],\n",
      "        [ 0.6824, -0.2714, -0.0429],\n",
      "        [ 0.6827, -0.2716, -0.0429],\n",
      "        [ 0.6827, -0.2716, -0.0428],\n",
      "        [ 0.6828, -0.2716, -0.0428],\n",
      "        [ 0.6829, -0.2717, -0.0428],\n",
      "        [ 0.6825, -0.2715, -0.0429],\n",
      "        [ 0.6827, -0.2716, -0.0428]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "33it [14:07, 25.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6411, -0.2477, -0.0386],\n",
      "        [ 0.6419, -0.2481, -0.0384],\n",
      "        [ 0.6417, -0.2480, -0.0384],\n",
      "        [ 0.6417, -0.2480, -0.0384],\n",
      "        [ 0.6422, -0.2483, -0.0383],\n",
      "        [ 0.6415, -0.2479, -0.0385],\n",
      "        [ 0.6417, -0.2480, -0.0384],\n",
      "        [ 0.6418, -0.2481, -0.0384]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "34it [14:31, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6249, -0.2425, -0.0286],\n",
      "        [ 0.6248, -0.2425, -0.0287],\n",
      "        [ 0.6251, -0.2426, -0.0286],\n",
      "        [ 0.6251, -0.2427, -0.0286],\n",
      "        [ 0.6251, -0.2427, -0.0286],\n",
      "        [ 0.6247, -0.2424, -0.0287],\n",
      "        [ 0.6249, -0.2426, -0.0286],\n",
      "        [ 0.6245, -0.2423, -0.0288]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "35it [14:56, 25.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6398, -0.2581, -0.0178],\n",
      "        [ 0.6400, -0.2582, -0.0178],\n",
      "        [ 0.6398, -0.2581, -0.0178],\n",
      "        [ 0.6398, -0.2581, -0.0178],\n",
      "        [ 0.6400, -0.2582, -0.0178],\n",
      "        [ 0.6398, -0.2581, -0.0178],\n",
      "        [ 0.6398, -0.2581, -0.0178],\n",
      "        [ 0.6399, -0.2582, -0.0178]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "36it [23:48, 177.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6637, -0.2764, -0.0156],\n",
      "        [ 0.6640, -0.2765, -0.0154],\n",
      "        [ 0.6638, -0.2764, -0.0155],\n",
      "        [ 0.6640, -0.2765, -0.0155],\n",
      "        [ 0.6639, -0.2765, -0.0155],\n",
      "        [ 0.6641, -0.2766, -0.0154],\n",
      "        [ 0.6641, -0.2766, -0.0154],\n",
      "        [ 0.6640, -0.2765, -0.0154]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "37it [24:20, 133.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6973, -0.3017, -0.0115],\n",
      "        [ 0.6972, -0.3017, -0.0115],\n",
      "        [ 0.6974, -0.3018, -0.0114],\n",
      "        [ 0.6975, -0.3019, -0.0114],\n",
      "        [ 0.6971, -0.3017, -0.0115],\n",
      "        [ 0.6974, -0.3019, -0.0114],\n",
      "        [ 0.6973, -0.3018, -0.0115],\n",
      "        [ 0.6972, -0.3017, -0.0115]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "38it [24:46, 101.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7402, -0.3343, -0.0059],\n",
      "        [ 0.7402, -0.3343, -0.0059],\n",
      "        [ 0.7398, -0.3341, -0.0060],\n",
      "        [ 0.7401, -0.3342, -0.0059],\n",
      "        [ 0.7401, -0.3342, -0.0059],\n",
      "        [ 0.7401, -0.3342, -0.0059],\n",
      "        [ 0.7398, -0.3340, -0.0060],\n",
      "        [ 0.7403, -0.3344, -0.0058]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "39it [25:11, 78.41s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7529, -0.3434, -0.0080],\n",
      "        [ 0.7527, -0.3432, -0.0080],\n",
      "        [ 0.7525, -0.3431, -0.0081],\n",
      "        [ 0.7528, -0.3433, -0.0080],\n",
      "        [ 0.7527, -0.3432, -0.0080],\n",
      "        [ 0.7525, -0.3431, -0.0081],\n",
      "        [ 0.7528, -0.3433, -0.0080],\n",
      "        [ 0.7528, -0.3433, -0.0080]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "40it [25:39, 63.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 7.8398e-01, -3.6935e-01,  6.1108e-04],\n",
      "        [ 7.8373e-01, -3.6919e-01,  5.2886e-04],\n",
      "        [ 7.8423e-01, -3.6951e-01,  6.8936e-04],\n",
      "        [ 7.8437e-01, -3.6960e-01,  7.3677e-04],\n",
      "        [ 7.8416e-01, -3.6946e-01,  6.6806e-04],\n",
      "        [ 7.8426e-01, -3.6951e-01,  7.0821e-04],\n",
      "        [ 7.8426e-01, -3.6953e-01,  7.0038e-04],\n",
      "        [ 7.8423e-01, -3.6952e-01,  6.8578e-04]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "41it [26:03, 51.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7907, -0.3790,  0.0103],\n",
      "        [ 0.7911, -0.3793,  0.0105],\n",
      "        [ 0.7908, -0.3791,  0.0104],\n",
      "        [ 0.7907, -0.3791,  0.0103],\n",
      "        [ 0.7909, -0.3792,  0.0104],\n",
      "        [ 0.7908, -0.3791,  0.0104],\n",
      "        [ 0.7908, -0.3791,  0.0104],\n",
      "        [ 0.7908, -0.3791,  0.0104]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "42it [26:29, 44.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.8176, -0.4072,  0.0315],\n",
      "        [ 0.8175, -0.4072,  0.0314],\n",
      "        [ 0.8173, -0.4070,  0.0314],\n",
      "        [ 0.8172, -0.4070,  0.0314],\n",
      "        [ 0.8171, -0.4069,  0.0313],\n",
      "        [ 0.8170, -0.4068,  0.0313],\n",
      "        [ 0.8174, -0.4071,  0.0314],\n",
      "        [ 0.8173, -0.4070,  0.0314]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "43it [26:54, 38.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.8513, -0.4407,  0.0534],\n",
      "        [ 0.8510, -0.4405,  0.0533],\n",
      "        [ 0.8513, -0.4407,  0.0534],\n",
      "        [ 0.8512, -0.4406,  0.0533],\n",
      "        [ 0.8517, -0.4410,  0.0536],\n",
      "        [ 0.8510, -0.4405,  0.0533],\n",
      "        [ 0.8513, -0.4407,  0.0534],\n",
      "        [ 0.8515, -0.4408,  0.0535]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "44it [27:17, 33.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.9172, -0.4927,  0.0643],\n",
      "        [ 0.9170, -0.4926,  0.0643],\n",
      "        [ 0.9170, -0.4926,  0.0643],\n",
      "        [ 0.9174, -0.4929,  0.0644],\n",
      "        [ 0.9168, -0.4925,  0.0642],\n",
      "        [ 0.9162, -0.4920,  0.0640],\n",
      "        [ 0.9170, -0.4926,  0.0643],\n",
      "        [ 0.9166, -0.4923,  0.0641]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "45it [27:47, 32.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.9539, -0.5123,  0.0464],\n",
      "        [ 0.9542, -0.5125,  0.0464],\n",
      "        [ 0.9543, -0.5125,  0.0465],\n",
      "        [ 0.9536, -0.5120,  0.0463],\n",
      "        [ 0.9540, -0.5123,  0.0464],\n",
      "        [ 0.9543, -0.5125,  0.0465],\n",
      "        [ 0.9542, -0.5125,  0.0465],\n",
      "        [ 0.9542, -0.5125,  0.0464]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "46it [28:14, 30.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.9592, -0.5164,  0.0446],\n",
      "        [ 0.9592, -0.5164,  0.0446],\n",
      "        [ 0.9591, -0.5164,  0.0446],\n",
      "        [ 0.9591, -0.5163,  0.0446],\n",
      "        [ 0.9594, -0.5165,  0.0447],\n",
      "        [ 0.9597, -0.5167,  0.0448],\n",
      "        [ 0.9592, -0.5164,  0.0446],\n",
      "        [ 0.9592, -0.5164,  0.0446]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "47it [28:37, 28.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.8788, -0.4444,  0.0065],\n",
      "        [ 0.8796, -0.4450,  0.0067],\n",
      "        [ 0.8794, -0.4448,  0.0067],\n",
      "        [ 0.8793, -0.4447,  0.0066],\n",
      "        [ 0.8794, -0.4448,  0.0067],\n",
      "        [ 0.8791, -0.4446,  0.0066],\n",
      "        [ 0.8794, -0.4448,  0.0067],\n",
      "        [ 0.8795, -0.4449,  0.0067]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "48it [29:01, 27.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7977, -0.3751, -0.0257],\n",
      "        [ 0.7974, -0.3748, -0.0258],\n",
      "        [ 0.7976, -0.3750, -0.0258],\n",
      "        [ 0.7980, -0.3752, -0.0256],\n",
      "        [ 0.7978, -0.3751, -0.0257],\n",
      "        [ 0.7975, -0.3749, -0.0258],\n",
      "        [ 0.7970, -0.3746, -0.0259],\n",
      "        [ 0.7975, -0.3749, -0.0258]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "49it [29:26, 26.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6955, -0.2999, -0.0411],\n",
      "        [ 0.6954, -0.2998, -0.0411],\n",
      "        [ 0.6953, -0.2998, -0.0411],\n",
      "        [ 0.6956, -0.2999, -0.0411],\n",
      "        [ 0.6956, -0.2999, -0.0410],\n",
      "        [ 0.6953, -0.2998, -0.0411],\n",
      "        [ 0.6957, -0.3000, -0.0410],\n",
      "        [ 0.6953, -0.2997, -0.0411]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "50it [29:53, 26.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6131, -0.2401, -0.0550],\n",
      "        [ 0.6135, -0.2403, -0.0550],\n",
      "        [ 0.6131, -0.2401, -0.0550],\n",
      "        [ 0.6133, -0.2402, -0.0550],\n",
      "        [ 0.6128, -0.2399, -0.0551],\n",
      "        [ 0.6131, -0.2401, -0.0550],\n",
      "        [ 0.6129, -0.2399, -0.0551],\n",
      "        [ 0.6134, -0.2402, -0.0550]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "51it [30:18, 26.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5453, -0.1914, -0.0708],\n",
      "        [ 0.5451, -0.1913, -0.0708],\n",
      "        [ 0.5452, -0.1913, -0.0708],\n",
      "        [ 0.5451, -0.1913, -0.0708],\n",
      "        [ 0.5453, -0.1913, -0.0708],\n",
      "        [ 0.5450, -0.1912, -0.0709],\n",
      "        [ 0.5452, -0.1913, -0.0708],\n",
      "        [ 0.5452, -0.1913, -0.0708]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "52it [30:44, 26.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4934, -0.1548, -0.0837],\n",
      "        [ 0.4932, -0.1548, -0.0838],\n",
      "        [ 0.4935, -0.1549, -0.0837],\n",
      "        [ 0.4936, -0.1550, -0.0837],\n",
      "        [ 0.4936, -0.1549, -0.0837],\n",
      "        [ 0.4935, -0.1549, -0.0837],\n",
      "        [ 0.4935, -0.1549, -0.0837],\n",
      "        [ 0.4934, -0.1549, -0.0837]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "53it [31:14, 27.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4479, -0.1262, -0.0909],\n",
      "        [ 0.4479, -0.1262, -0.0909],\n",
      "        [ 0.4478, -0.1262, -0.0910],\n",
      "        [ 0.4479, -0.1262, -0.0909],\n",
      "        [ 0.4478, -0.1262, -0.0909],\n",
      "        [ 0.4478, -0.1262, -0.0909],\n",
      "        [ 0.4478, -0.1262, -0.0910],\n",
      "        [ 0.4477, -0.1261, -0.0910]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "54it [31:42, 27.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4197, -0.1066, -0.0999],\n",
      "        [ 0.4195, -0.1065, -0.0999],\n",
      "        [ 0.4197, -0.1066, -0.0999],\n",
      "        [ 0.4197, -0.1066, -0.0999],\n",
      "        [ 0.4196, -0.1066, -0.0999],\n",
      "        [ 0.4197, -0.1066, -0.0999],\n",
      "        [ 0.4197, -0.1066, -0.0999],\n",
      "        [ 0.4197, -0.1066, -0.0999]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "55it [32:11, 28.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3989, -0.0934, -0.1025],\n",
      "        [ 0.3989, -0.0934, -0.1025],\n",
      "        [ 0.3989, -0.0934, -0.1025],\n",
      "        [ 0.3989, -0.0934, -0.1023],\n",
      "        [ 0.3989, -0.0934, -0.1023],\n",
      "        [ 0.3989, -0.0934, -0.1023],\n",
      "        [ 0.3989, -0.0934, -0.1024],\n",
      "        [ 0.3989, -0.0934, -0.1024]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "56it [32:42, 28.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3852, -0.0836, -0.1014],\n",
      "        [ 0.3852, -0.0836, -0.1014],\n",
      "        [ 0.3852, -0.0836, -0.1014],\n",
      "        [ 0.3852, -0.0836, -0.1014],\n",
      "        [ 0.3853, -0.0835, -0.1013],\n",
      "        [ 0.3853, -0.0834, -0.1011],\n",
      "        [ 0.3852, -0.0836, -0.1014],\n",
      "        [ 0.3853, -0.0835, -0.1012]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "57it [33:11, 28.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3641, -0.0723, -0.1078],\n",
      "        [ 0.3642, -0.0724, -0.1078],\n",
      "        [ 0.3640, -0.0723, -0.1078],\n",
      "        [ 0.3641, -0.0724, -0.1078],\n",
      "        [ 0.3641, -0.0724, -0.1078],\n",
      "        [ 0.3641, -0.0724, -0.1078],\n",
      "        [ 0.3641, -0.0724, -0.1078],\n",
      "        [ 0.3641, -0.0724, -0.1078]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "58it [33:39, 28.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3462, -0.0587, -0.1056],\n",
      "        [ 0.3462, -0.0587, -0.1056],\n",
      "        [ 0.3462, -0.0587, -0.1056],\n",
      "        [ 0.3462, -0.0588, -0.1056],\n",
      "        [ 0.3462, -0.0587, -0.1056],\n",
      "        [ 0.3462, -0.0588, -0.1056],\n",
      "        [ 0.3462, -0.0587, -0.1056],\n",
      "        [ 0.3462, -0.0587, -0.1056]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "59it [34:08, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3332, -0.0402, -0.1000],\n",
      "        [ 0.3332, -0.0402, -0.1000],\n",
      "        [ 0.3332, -0.0401, -0.0999],\n",
      "        [ 0.3332, -0.0402, -0.0999],\n",
      "        [ 0.3332, -0.0402, -0.0999],\n",
      "        [ 0.3332, -0.0402, -0.1000],\n",
      "        [ 0.3332, -0.0400, -0.0998],\n",
      "        [ 0.3332, -0.0402, -0.0999]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "60it [34:38, 29.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3260, -0.0303, -0.0972],\n",
      "        [ 0.3260, -0.0303, -0.0972],\n",
      "        [ 0.3260, -0.0303, -0.0972],\n",
      "        [ 0.3260, -0.0303, -0.0972],\n",
      "        [ 0.3260, -0.0303, -0.0972],\n",
      "        [ 0.3260, -0.0303, -0.0972],\n",
      "        [ 0.3260, -0.0303, -0.0972],\n",
      "        [ 0.3260, -0.0303, -0.0972]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "61it [35:07, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3252, -0.0331, -0.1015],\n",
      "        [ 0.3253, -0.0331, -0.1015],\n",
      "        [ 0.3252, -0.0331, -0.1015],\n",
      "        [ 0.3252, -0.0331, -0.1015],\n",
      "        [ 0.3252, -0.0331, -0.1015],\n",
      "        [ 0.3252, -0.0331, -0.1015],\n",
      "        [ 0.3252, -0.0331, -0.1015],\n",
      "        [ 0.3252, -0.0331, -0.1015]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "62it [35:39, 29.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3214, -0.0279, -0.1018],\n",
      "        [ 0.3214, -0.0279, -0.1018],\n",
      "        [ 0.3214, -0.0279, -0.1018],\n",
      "        [ 0.3215, -0.0279, -0.1018],\n",
      "        [ 0.3214, -0.0279, -0.1018],\n",
      "        [ 0.3214, -0.0279, -0.1018],\n",
      "        [ 0.3214, -0.0278, -0.1018],\n",
      "        [ 0.3215, -0.0279, -0.1018]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "63it [36:15, 31.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3215, -0.0295, -0.1087],\n",
      "        [ 0.3215, -0.0295, -0.1087],\n",
      "        [ 0.3215, -0.0295, -0.1087],\n",
      "        [ 0.3215, -0.0295, -0.1087],\n",
      "        [ 0.3215, -0.0295, -0.1087],\n",
      "        [ 0.3215, -0.0295, -0.1087],\n",
      "        [ 0.3215, -0.0295, -0.1087],\n",
      "        [ 0.3215, -0.0295, -0.1087]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "64it [36:45, 31.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3276, -0.0343, -0.1143],\n",
      "        [ 0.3276, -0.0343, -0.1143],\n",
      "        [ 0.3276, -0.0343, -0.1143],\n",
      "        [ 0.3276, -0.0343, -0.1143],\n",
      "        [ 0.3276, -0.0343, -0.1143],\n",
      "        [ 0.3276, -0.0343, -0.1143],\n",
      "        [ 0.3276, -0.0343, -0.1143],\n",
      "        [ 0.3276, -0.0343, -0.1143]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "65it [37:13, 30.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3325, -0.0402, -0.1187],\n",
      "        [ 0.3325, -0.0402, -0.1187],\n",
      "        [ 0.3325, -0.0402, -0.1187],\n",
      "        [ 0.3325, -0.0402, -0.1187],\n",
      "        [ 0.3325, -0.0402, -0.1187],\n",
      "        [ 0.3325, -0.0402, -0.1187],\n",
      "        [ 0.3325, -0.0402, -0.1187],\n",
      "        [ 0.3325, -0.0402, -0.1187]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "66it [37:41, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3392, -0.0486, -0.1249],\n",
      "        [ 0.3392, -0.0486, -0.1249],\n",
      "        [ 0.3392, -0.0486, -0.1249],\n",
      "        [ 0.3392, -0.0486, -0.1249],\n",
      "        [ 0.3392, -0.0486, -0.1249],\n",
      "        [ 0.3392, -0.0486, -0.1249],\n",
      "        [ 0.3392, -0.0486, -0.1249],\n",
      "        [ 0.3392, -0.0486, -0.1249]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "67it [38:11, 29.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3566, -0.0714, -0.1466],\n",
      "        [ 0.3566, -0.0713, -0.1466],\n",
      "        [ 0.3566, -0.0714, -0.1466],\n",
      "        [ 0.3566, -0.0714, -0.1466],\n",
      "        [ 0.3566, -0.0714, -0.1466],\n",
      "        [ 0.3566, -0.0714, -0.1467],\n",
      "        [ 0.3566, -0.0714, -0.1466],\n",
      "        [ 0.3566, -0.0714, -0.1466]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "68it [38:45, 30.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.3809, -0.1061, -0.1743],\n",
      "        [ 0.3809, -0.1061, -0.1743],\n",
      "        [ 0.3809, -0.1061, -0.1743],\n",
      "        [ 0.3810, -0.1061, -0.1743],\n",
      "        [ 0.3809, -0.1061, -0.1743],\n",
      "        [ 0.3809, -0.1061, -0.1743],\n",
      "        [ 0.3810, -0.1061, -0.1742],\n",
      "        [ 0.3809, -0.1062, -0.1745]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "69it [39:18, 31.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4231, -0.1597, -0.2191],\n",
      "        [ 0.4231, -0.1597, -0.2191],\n",
      "        [ 0.4232, -0.1596, -0.2192],\n",
      "        [ 0.4232, -0.1596, -0.2192],\n",
      "        [ 0.4232, -0.1596, -0.2192],\n",
      "        [ 0.4231, -0.1597, -0.2191],\n",
      "        [ 0.4231, -0.1596, -0.2192],\n",
      "        [ 0.4231, -0.1597, -0.2191]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "70it [39:55, 33.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4472, -0.1899, -0.2225],\n",
      "        [ 0.4472, -0.1899, -0.2225],\n",
      "        [ 0.4472, -0.1899, -0.2225],\n",
      "        [ 0.4472, -0.1898, -0.2226],\n",
      "        [ 0.4472, -0.1899, -0.2225],\n",
      "        [ 0.4471, -0.1899, -0.2225],\n",
      "        [ 0.4472, -0.1899, -0.2225],\n",
      "        [ 0.4472, -0.1900, -0.2225]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "71it [40:34, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4487, -0.2115, -0.2012],\n",
      "        [ 0.4486, -0.2115, -0.2012],\n",
      "        [ 0.4486, -0.2115, -0.2012],\n",
      "        [ 0.4487, -0.2114, -0.2012],\n",
      "        [ 0.4486, -0.2115, -0.2012],\n",
      "        [ 0.4487, -0.2115, -0.2012],\n",
      "        [ 0.4486, -0.2115, -0.2012],\n",
      "        [ 0.4487, -0.2115, -0.2012]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "72it [41:38, 43.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4932, -0.2706, -0.2176],\n",
      "        [ 0.4932, -0.2705, -0.2175],\n",
      "        [ 0.4933, -0.2707, -0.2177],\n",
      "        [ 0.4932, -0.2706, -0.2176],\n",
      "        [ 0.4933, -0.2707, -0.2177],\n",
      "        [ 0.4932, -0.2707, -0.2176],\n",
      "        [ 0.4933, -0.2707, -0.2177],\n",
      "        [ 0.4933, -0.2707, -0.2176]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "73it [42:48, 51.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4976, -0.2612, -0.2136],\n",
      "        [ 0.4975, -0.2611, -0.2135],\n",
      "        [ 0.4976, -0.2612, -0.2136],\n",
      "        [ 0.4977, -0.2613, -0.2137],\n",
      "        [ 0.4977, -0.2613, -0.2137],\n",
      "        [ 0.4976, -0.2612, -0.2136],\n",
      "        [ 0.4975, -0.2610, -0.2134],\n",
      "        [ 0.4975, -0.2611, -0.2135]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "74it [43:55, 56.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.4978, -0.2479, -0.2077],\n",
      "        [ 0.4978, -0.2480, -0.2078],\n",
      "        [ 0.4977, -0.2479, -0.2076],\n",
      "        [ 0.4979, -0.2480, -0.2078],\n",
      "        [ 0.4978, -0.2480, -0.2077],\n",
      "        [ 0.4977, -0.2478, -0.2076],\n",
      "        [ 0.4976, -0.2479, -0.2076],\n",
      "        [ 0.4978, -0.2479, -0.2077]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "75it [44:50, 55.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.5439, -0.3122, -0.2310],\n",
      "        [ 0.5438, -0.3121, -0.2310],\n",
      "        [ 0.5439, -0.3122, -0.2310],\n",
      "        [ 0.5439, -0.3121, -0.2310],\n",
      "        [ 0.5439, -0.3121, -0.2310],\n",
      "        [ 0.5438, -0.3121, -0.2309],\n",
      "        [ 0.5438, -0.3121, -0.2309],\n",
      "        [ 0.5440, -0.3122, -0.2311]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "76it [45:31, 51.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.6363, -0.4374, -0.2852],\n",
      "        [ 0.6365, -0.4376, -0.2856],\n",
      "        [ 0.6365, -0.4376, -0.2857],\n",
      "        [ 0.6364, -0.4375, -0.2855],\n",
      "        [ 0.6364, -0.4375, -0.2854],\n",
      "        [ 0.6365, -0.4376, -0.2856],\n",
      "        [ 0.6364, -0.4374, -0.2854],\n",
      "        [ 0.6365, -0.4376, -0.2855]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "77it [46:08, 46.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "y_pred: tensor([[ 0.7309, -0.5269, -0.3673],\n",
      "        [ 0.7310, -0.5270, -0.3674],\n",
      "        [ 0.7309, -0.5269, -0.3673],\n",
      "        [ 0.7311, -0.5271, -0.3674],\n",
      "        [ 0.7309, -0.5269, -0.3673],\n",
      "        [ 0.7311, -0.5271, -0.3674],\n",
      "        [ 0.7309, -0.5269, -0.3673],\n",
      "        [ 0.7309, -0.5269, -0.3673]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [46:42, 36.39s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m     78\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "train_loss_record = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_loss_sum = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        masks = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # debugging roberta encoder and second lstm\n",
    "        '''\n",
    "        debug starts here\n",
    "        '''\n",
    "        # if idx > 1:\n",
    "        #     break\n",
    "        # batch_size_here = data['ids'].shape[0]\n",
    "        # print('batch_size_here:', batch_size_here)\n",
    "        # e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
    "        # print('ids shape:', ids.shape)\n",
    "        \n",
    "        # for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
    "        #     print('k:', k)\n",
    "        #     seq_ids = ids[:,k,:].to(device)\n",
    "        #     seq_masks = masks[:,k,:].to(device)\n",
    "        #     seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
    "\n",
    "\n",
    "        #     e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "        #     print(e2.shape)\n",
    "        #     print(e2k[1].shape)\n",
    "        #     #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "        #     # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "        #     e2k1 = e2k[0][:, 0, :]  \n",
    "        #     e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        # lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
    "        # fc2 = nn.Linear(768, 256)\n",
    "\n",
    "        # h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
    "        # h_out2 = h_out2.view(-1, 768)\n",
    "        # out2 = fc2(h_out2)\n",
    "        \n",
    "\n",
    "    #     print(ids.shape)\n",
    "    #     print(masks.shape)\n",
    "    #     print(token_type_ids.shape)\n",
    "    \n",
    "        # print(out2)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        debug ends here\n",
    "        '''\n",
    "        \n",
    "\n",
    "    \n",
    "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
    "        print('y_pred:', y_pred)\n",
    "        loss = criterion(y_pred, targets.reshape(-1))\n",
    "        \n",
    "         # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loss.append(loss.data.cpu())\n",
    "        train_loss_sum.append(loss.data.cpu())\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())   \n",
    "\n",
    "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "    train_loss_record.append(np.mean(train_loss_sum))\n",
    "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate on test set every epoch\n",
    "    test_loss = []\n",
    "    test_loss_sum = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
    "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
    "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
    "#         print('y_pred:', y_pred)\n",
    "        test_loss = criterion(y_pred, test_targets.reshape(-1))\n",
    "    \n",
    "        test_loss.append(test_loss.data.cpu())\n",
    "        test_loss_sum.append(test_loss.data.cpu()) \n",
    "\n",
    "        wandb.log({'avg test loss in this batch': test_loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "        \n",
    "        # Get accuracy\n",
    "        total += test_targets.reshape(-1).size(0)\n",
    "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
    "    test_loss_record.append(np.mean(test_loss_sum))\n",
    "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
    "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e52034a1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_45605/3665585654.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'ids': torch.tensor(input_ids, dtype=torch.long),\n",
      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_45605/3665585654.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_45605/3665585654.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_45605/3665585654.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  'targets': torch.tensor(y_train[index], dtype=torch.long)\n",
      "1it [00:05,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e2 shape:  torch.Size([8, 20, 1024])\n",
      "tensor([[ 0.1361, -0.0529,  0.0118],\n",
      "        [ 0.1364, -0.0530,  0.0118],\n",
      "        [ 0.1364, -0.0530,  0.0118],\n",
      "        [ 0.1364, -0.0530,  0.0117],\n",
      "        [ 0.1363, -0.0528,  0.0118],\n",
      "        [ 0.1366, -0.0531,  0.0120],\n",
      "        [ 0.1361, -0.0528,  0.0117],\n",
      "        [ 0.1368, -0.0532,  0.0121]], grad_fn=<AddmmBackward0>)\n",
      "e2 shape:  torch.Size([8, 20, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:15,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1365, -0.0530,  0.0119],\n",
      "        [ 0.1364, -0.0529,  0.0118],\n",
      "        [ 0.1362, -0.0529,  0.0120],\n",
      "        [ 0.1366, -0.0531,  0.0119],\n",
      "        [ 0.1364, -0.0529,  0.0118],\n",
      "        [ 0.1365, -0.0530,  0.0120],\n",
      "        [ 0.1364, -0.0530,  0.0120],\n",
      "        [ 0.1362, -0.0529,  0.0116]], grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cc98314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 1, 1, 1, 0, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "print(test_targets.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b5a4db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, pred_label = torch.max(y_pred.data, 1)\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "becf70d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_label == test_targets.reshape(-1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0040dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vocabulary path (./output2) should be a directory\n"
     ]
    }
   ],
   "source": [
    "run_id = str(1)\n",
    "!mkdir output/$run_id\n",
    "output_model_file = 'roberta_stock_pred.bin'\n",
    "output_vocab_file = './output' + str(run_id)\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f95298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3105ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a49d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e1748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_arr, label=\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26f68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
