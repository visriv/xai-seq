diff --git a/stock_pred_seq.ipynb b/stock_pred_seq.ipynb
index 02c088b..297075d 100644
--- a/stock_pred_seq.ipynb
+++ b/stock_pred_seq.ipynb
@@ -3,7 +3,7 @@
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "0035c6ed",
+   "id": "4d8a7718",
    "metadata": {},
    "outputs": [],
    "source": [
@@ -13,29 +13,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 36,
-   "id": "64983989",
-   "metadata": {
-    "scrolled": true
-   },
+   "execution_count": 238,
+   "id": "35eb0af0",
+   "metadata": {},
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1880521505.py:6: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/36207020.py:6: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
       "  plt.style.use('seaborn')\n",
-      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1880521505.py:10: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
-      "  from pandas import datetime\n",
-      "/Users/visriv/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
-      "  from .autonotebook import tqdm as notebook_tqdm\n"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "[*********************100%***********************]  1 of 1 completed\n"
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/36207020.py:10: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
+      "  from pandas import datetime as pd_dt\n"
      ]
     }
    ],
@@ -49,27 +38,96 @@
     "# mpl.rcParams['font.family'] = 'serif'\n",
     "%matplotlib inline\n",
     "\n",
-    "from pandas import datetime\n",
+    "from pandas import datetime as pd_dt\n",
     "import math, time\n",
     "import itertools\n",
-    "import datetime\n",
+    "from datetime import datetime\n",
     "from operator import itemgetter\n",
-    "\n",
+    "from tqdm import tqdm\n",
     "from math import sqrt\n",
     "import torch\n",
     "import torch.nn as nn\n",
-    "from torch.autograd import Variable\n",
+    "from torch.autograd import Variable\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 244,
+   "id": "64399feb",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "\n",
+    "from torch import cuda\n",
+    "device = 'cuda' if cuda.is_available() else 'cpu'"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "5e4a0f5e",
+   "metadata": {},
+   "source": [
+    "### Hyperparams"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 277,
+   "id": "1ee6cf07",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "no_of_days_to_lookback = 5\n",
+    "up_threshold = 0.015\n",
+    "down_threshold = -0.015\n",
+    "max_text_per_iter = 100\n",
+    "batch_size = 32\n",
+    "MAX_LEN = 1000"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 237,
+   "id": "64983989",
+   "metadata": {
+    "collapsed": true
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1895032738.py:6: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
+      "  plt.style.use('seaborn')\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1895032738.py:10: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
+      "  from pandas import datetime as pd_dt\n"
+     ]
+    },
+    {
+     "ename": "ValueError",
+     "evalue": "unconverted data remains: 19",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[237], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m EXPORT_DATA_FOLDER \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Set the start and end dates for the data\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrptime\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m04-01-2019\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43mm-\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m end \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mstrptime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m04-01-2023\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# start = datetime.datetime.now() - datetime.timedelta(days=no_of_days)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# end = datetime.datetime.now()\u001b[39;00m\n",
+      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_strptime_datetime\u001b[39m(\u001b[38;5;28mcls\u001b[39m, data_string, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%a\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mb \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    566\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;124;03m    format string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[38;5;241m=\u001b[39m \u001b[43m_strptime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m     tzname, gmtoff \u001b[38;5;241m=\u001b[39m tt[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    570\u001b[0m     args \u001b[38;5;241m=\u001b[39m tt[:\u001b[38;5;241m6\u001b[39m] \u001b[38;5;241m+\u001b[39m (fraction,)\n",
+      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/_strptime.py:352\u001b[0m, in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime data \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m does not match format \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    350\u001b[0m                      (data_string, \u001b[38;5;28mformat\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data_string) \u001b[38;5;241m!=\u001b[39m found\u001b[38;5;241m.\u001b[39mend():\n\u001b[0;32m--> 352\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munconverted data remains: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    353\u001b[0m                       data_string[found\u001b[38;5;241m.\u001b[39mend():])\n\u001b[1;32m    355\u001b[0m iso_year \u001b[38;5;241m=\u001b[39m year \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m month \u001b[38;5;241m=\u001b[39m day \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
+      "\u001b[0;31mValueError\u001b[0m: unconverted data remains: 19"
+     ]
+    }
+   ],
+   "source": [
     "\n",
     "# Set hyperparameters\n",
     "stock_symbols = [ 'XOM']\n",
     "no_of_days = 4*365\n",
-    "up_threshold = 0.015\n",
-    "down_threshold = -0.015\n",
+    "\n",
     "EXPORT_DATA_FOLDER = './data/'\n",
     "\n",
     "# Set the start and end dates for the data\n",
-    "start = datetime.strptime('04-01-2019', '%m/%d/%y ')\n",
-    "end = datetime.strptime('04-01-2023', '%m/%d/%y ')\n",
+    "start = datetime.strptime('04-01-2019', '%m-%d-%y')\n",
+    "end = datetime.strptime('04-01-2023', '%m-%d-%y')\n",
     "\n",
     "\n",
     "# start = datetime.datetime.now() - datetime.timedelta(days=no_of_days)\n",
@@ -128,8 +186,10 @@
   {
    "cell_type": "code",
    "execution_count": 92,
-   "id": "f10e33cb",
-   "metadata": {},
+   "id": "26d90996",
+   "metadata": {
+    "collapsed": true
+   },
    "outputs": [
     {
      "data": {
@@ -149,13 +209,11 @@
      "output_type": "execute_result"
     }
    ],
-   "source": [
-    "data_norm.index"
-   ]
+   "source": []
   },
   {
    "cell_type": "markdown",
-   "id": "22ef7030",
+   "id": "bede9fea",
    "metadata": {},
    "source": [
     "## TODO (2023-06-05)\n"
@@ -164,21 +222,21 @@
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "23b593c6",
+   "id": "0b7e84e3",
    "metadata": {},
    "outputs": [],
    "source": [
     "'''\n",
     "cuda support check\n",
-    "read textual data into correct shape\n",
+    "//read textual data into correct shape\n",
     "hyperparam tuning: number of neurons: tune to right number of neurons in FC in model\n",
-    "max_text_per_iter -> code in dataloader to maintain the size \n",
+    "//max_text_per_iter -> code in dataloader to maintain the size \n",
     "'''"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "9e43d39e",
+   "id": "8d282939",
    "metadata": {},
    "source": [
     "## Prep textual data"
@@ -186,35 +244,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 96,
-   "id": "11b67ab0",
-   "metadata": {
-    "collapsed": true
-   },
-   "outputs": [
-    {
-     "data": {
-      "text/plain": [
-       "Date\n",
-       "2021-01-01    Tomato processor's accrued production costs fa...\n",
-       "2022-01-01    Industrial Alcohol Market Forecasts to 2028 – ...\n",
-       "2023-01-01    Global Cumene Market Research Report 2022-2032...\n",
-       "2020-10-01    Press Release: SBM Offshore awarded contracts ...\n",
-       "2021-10-01    JPMorgan 's Own Employee Travel Numbers Now He...\n",
-       "                                    ...                        \n",
-       "2021-08-09    Climate Change Is a ‘Hammer Hitting Us on the ...\n",
-       "2022-08-09    KASE - Trading in common shares US30231G1022 (...\n",
-       "2020-09-09    TAP Clouds Italy’s LNG Import Plans The immine...\n",
-       "2021-09-09    Storm's Fallout Cripples U.S. Oil Output --- S...\n",
-       "2022-09-09    Thermoplastic Elastomer Market Forecasts to 20...\n",
-       "Name: News, Length: 1065, dtype: object"
-      ]
-     },
-     "execution_count": 96,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
+   "execution_count": 108,
+   "id": "13509a65",
+   "metadata": {},
+   "outputs": [],
    "source": [
     "text_data_df = pd.read_csv('./data/XOM_20200401_20230401_medium.csv', sep= ',', header= 0)\n",
     "text_data_df = text_data_df[['Date', 'News']]\n",
@@ -223,16 +256,14 @@
     "text_data_df = text_data_df.groupby('Date')['News'].apply('$$$###'.join)\n",
     "\n",
     "text_data_df.index = pd.to_datetime(text_data_df.index, dayfirst=True)\n",
-    "text_data_df\n"
+    "# text_data_df\n"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 102,
-   "id": "95276237",
-   "metadata": {
-    "collapsed": true
-   },
+   "execution_count": 109,
+   "id": "4703109e",
+   "metadata": {},
    "outputs": [
     {
      "data": {
@@ -475,7 +506,7 @@
        "[458 rows x 10 columns]"
       ]
      },
-     "execution_count": 102,
+     "execution_count": 109,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -487,114 +518,49 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 72,
-   "id": "99b3be01",
-   "metadata": {
-    "collapsed": true
-   },
+   "execution_count": 298,
+   "id": "56e91800",
+   "metadata": {},
    "outputs": [
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Defaulting to user installation because normal site-packages is not writeable\n",
-      "Requirement already satisfied: yfinance in /Users/visriv/Library/Python/3.9/lib/python/site-packages (0.2.18)\n",
-      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (4.11.2)\n",
-      "Requirement already satisfied: numpy>=1.16.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.24.1)\n",
-      "Requirement already satisfied: frozendict>=2.3.4 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (2.3.8)\n",
-      "Requirement already satisfied: appdirs>=1.4.4 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.4.4)\n",
-      "Requirement already satisfied: html5lib>=1.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.1)\n",
-      "Requirement already satisfied: requests>=2.26 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (2.28.2)\n",
-      "Requirement already satisfied: pytz>=2022.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (2022.7.1)\n",
-      "Requirement already satisfied: multitasking>=0.0.7 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (0.0.11)\n",
-      "Requirement already satisfied: pandas>=1.3.0 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (1.5.3)\n",
-      "Requirement already satisfied: cryptography>=3.3.2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (41.0.1)\n",
-      "Requirement already satisfied: lxml>=4.9.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from yfinance) (4.9.2)\n",
-      "Requirement already satisfied: soupsieve>1.2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.4)\n",
-      "Requirement already satisfied: cffi>=1.12 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from cryptography>=3.3.2->yfinance) (1.15.1)\n",
-      "Requirement already satisfied: six>=1.9 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from html5lib>=1.1->yfinance) (1.15.0)\n",
-      "Requirement already satisfied: webencodings in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
-      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
-      "Requirement already satisfied: certifi>=2017.4.17 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (2022.12.7)\n",
-      "Requirement already satisfied: idna<4,>=2.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (3.4)\n",
-      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (2.1.1)\n",
-      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests>=2.26->yfinance) (1.26.14)\n",
-      "Requirement already satisfied: pycparser in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from cffi>=1.12->cryptography>=3.3.2->yfinance) (2.21)\n",
-      "\n",
-      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
-      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
-      "Defaulting to user installation because normal site-packages is not writeable\n",
-      "Collecting transformers\n",
-      "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
-      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
-      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (4.64.1)\n",
-      "Collecting huggingface-hub<1.0,>=0.14.1\n",
-      "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
-      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
-      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (23.0)\n",
-      "Requirement already satisfied: pyyaml>=5.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
-      "Collecting regex!=2019.12.17\n",
-      "  Downloading regex-2023.6.3-cp39-cp39-macosx_10_9_x86_64.whl (294 kB)\n",
-      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
-      "\u001b[?25hRequirement already satisfied: requests in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (2.28.2)\n",
-      "Requirement already satisfied: numpy>=1.17 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from transformers) (1.24.1)\n",
-      "Collecting filelock\n",
-      "  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n",
-      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
-      "  Downloading tokenizers-0.13.3-cp39-cp39-macosx_10_11_x86_64.whl (4.0 MB)\n",
-      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
-      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.4.0)\n",
-      "Requirement already satisfied: fsspec in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
-      "Requirement already satisfied: certifi>=2017.4.17 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2022.12.7)\n",
-      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.1.1)\n",
-      "Requirement already satisfied: idna<4,>=2.5 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4)\n",
-      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/visriv/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (1.26.14)\n",
-      "Installing collected packages: tokenizers, regex, filelock, huggingface-hub, transformers\n",
-      "Successfully installed filelock-3.12.0 huggingface-hub-0.15.1 regex-2023.6.3 tokenizers-0.13.3 transformers-4.29.2\n",
-      "\n",
-      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
-      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
-     ]
-    }
-   ],
-   "source": []
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 103,
-   "id": "56e91800",
-   "metadata": {
-    "scrolled": true
-   },
-   "outputs": [
-    {
-     "ename": "TypeError",
-     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
-     "output_type": "error",
-     "traceback": [
-      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
-      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
-      "Cell \u001b[0;32mIn[103], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m     y_train\u001b[38;5;241m.\u001b[39mappend(all_train[i, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;66;03m#TODO\u001b[39;00m\n\u001b[1;32m     15\u001b[0m X_numerical_train, y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_numerical_train), np\u001b[38;5;241m.\u001b[39marray(y_train)\n\u001b[0;32m---> 17\u001b[0m X_numerical_train \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_numerical_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     18\u001b[0m y_train \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(y_train)\u001b[38;5;241m.\u001b[39mlong()\n",
-      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
+      "<class 'numpy.ndarray'>\n"
      ]
     }
    ],
    "source": [
     "all_train = all_train_df.values\n",
     "\n",
-    "window_size = 5\n",
+    "window_size = no_of_days_to_lookback\n",
     "\n",
     "X_numerical_train = []\n",
     "y_train = []\n",
     "X_text_train = []\n",
+    "X_text_train_curr = []\n",
+    "\n",
     "\n",
     "for i in range(window_size, len(all_train)):\n",
     "    X_numerical_train.append(all_train[i-window_size: i, :-2])\n",
-    "    X_text_train.append(all_train[i-window_size: i, -1])\n",
     "    \n",
-    "    y_train.append(all_train[i, -2]) #TODO\n",
+    "    # split and append sequence\n",
+    "    curr_seq = all_train[i-window_size: i, -1]\n",
+    "    for j in range(window_size):\n",
+    "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
+    "        X_text_train_curr = X_text_train_curr + split_curr_seq\n",
+    "    \n",
+    "    if len(X_text_train_curr) > max_text_per_iter:\n",
+    "        X_text_train_curr = X_text_train_curr[:100]\n",
     "    \n",
-    "X_numerical_train, y_train = np.array(X_numerical_train), np.array(y_train)\n",
+    "    X_text_train.append(X_text_train_curr)\n",
+    "        \n",
+    "#     X_text_train.append(all_train[i-window_size: i, -1])\n",
+    "    \n",
+    "    y_train.append(all_train[i, -2]) \n",
+    "\n",
+    "X_numerical_train, y_train = np.array(X_numerical_train).astype(np.float16), np.array(y_train)\n",
+    "print(type(X_numerical_train))\n",
     "\n",
     "X_numerical_train = torch.from_numpy(X_numerical_train).type(torch.Tensor)\n",
     "y_train = torch.from_numpy(y_train).long()\n",
@@ -603,39 +569,46 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 107,
-   "id": "4f42b932",
+   "execution_count": 305,
+   "id": "b94c6286",
    "metadata": {},
    "outputs": [
     {
-     "data": {
-      "text/plain": [
-       "numpy.ndarray"
-      ]
-     },
-     "execution_count": 107,
-     "metadata": {},
-     "output_type": "execute_result"
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "453\n",
+      "100\n"
+     ]
     }
    ],
    "source": [
-    "type(all_train[0: 5, :-2])"
+    "print(len(X_text_train))\n",
+    "print(len(X_text_train[2]))"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 65,
-   "id": "3a75b237",
+   "execution_count": 162,
+   "id": "db3b65c3",
    "metadata": {},
-   "outputs": [],
-   "source": [
-    "\n",
-    "\n"
-   ]
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "5"
+      ]
+     },
+     "execution_count": 162,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
   },
   {
    "cell_type": "markdown",
-   "id": "524e93cf",
+   "id": "db133575",
    "metadata": {},
    "source": [
     "## Data loader"
@@ -643,29 +616,1407 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 77,
-   "id": "880f0ab1",
+   "execution_count": 332,
+   "id": "1090de88",
    "metadata": {},
    "outputs": [],
    "source": [
     "from torch.utils.data import Dataset\n",
+    "from torch.utils.data import DataLoader\n",
+    "\n",
+    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
+    "\n",
     "class SiameseDataloader(Dataset):\n",
     "    \n",
-    "    def __init__(self, X_numerical_train, y_train, X_text_train):\n",
-    "        \n",
-    "        pass\n",
+    "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
+    "        self.X_numerical_train = X_numerical_train\n",
+    "        self.X_text_train = X_text_train\n",
+    "        self.MAX_LEN = MAX_LEN\n",
+    "        self.tokenizer = tokenizer\n",
     "        \n",
     "    def __getitem__(self, index):\n",
     "\n",
-    "        return (X_train[index], text_train[index]), y_train[index]\n",
+    "        \n",
+    "        input_ids = []\n",
+    "        attention_masks = []\n",
+    "        token_type_ids = []\n",
+    "        input_seq = []\n",
+    "\n",
+    "        for sent in X_text_train[index]:\n",
+    "            encoded_sent = self.tokenizer.encode_plus(\n",
+    "                text=sent,\n",
+    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
+    "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
+    "                pad_to_max_length=True,         # Pad sentence to max length \n",
+    "                #return_attention_mask=True      # Return attention mask\n",
+    "                return_token_type_ids=True\n",
+    "                )\n",
+    "            input_ids.append(encoded_sent.get('input_ids'))\n",
+    "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
+    "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
+    "\n",
+    "        # Convert lists to tensors\n",
+    "        input_ids = torch.tensor(input_ids)\n",
+    "        attention_masks = torch.tensor(attention_masks)\n",
+    "        token_type_ids = torch.tensor(token_type_ids)\n",
+    "\n",
+    "\n",
+    "        return {\n",
+    "            'x_numerical': X_train[index],\n",
+    "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
+    "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
+    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
+    "            'targets': torch.tensor(y_train[index], dtype=torch.float)\n",
+    "        }\n",
+    "    \n",
+    "    \n",
+    "    \n",
+    "    \n",
     "\n",
     "    def __len__(self):\n",
     "        return len(self.X_numerical_train)"
    ]
   },
+  {
+   "cell_type": "code",
+   "execution_count": 333,
+   "id": "f76bedfc",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
+    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 308,
+   "id": "ff62bc3b",
+   "metadata": {
+    "collapsed": true
+   },
+   "outputs": [
+    {
+     "ename": "AttributeError",
+     "evalue": "'list' object has no attribute 'shape'",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[308], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_text_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
+      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
+     ]
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 226,
+   "id": "61a37c88",
+   "metadata": {
+    "collapsed": true
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'ids': torch.tensor(input_ids, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'targets': torch.tensor(y_train[index], dtype=torch.float)\n"
+     ]
+    },
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "0\n",
+      "<class 'dict'>\n",
+      "1\n",
+      "<class 'dict'>\n",
+      "2\n",
+      "<class 'dict'>\n",
+      "3\n",
+      "<class 'dict'>\n",
+      "4\n",
+      "<class 'dict'>\n",
+      "5\n",
+      "<class 'dict'>\n",
+      "6\n",
+      "<class 'dict'>\n",
+      "7\n",
+      "<class 'dict'>\n",
+      "8\n",
+      "<class 'dict'>\n",
+      "9\n",
+      "<class 'dict'>\n",
+      "10\n",
+      "<class 'dict'>\n",
+      "11\n",
+      "<class 'dict'>\n",
+      "12\n",
+      "<class 'dict'>\n",
+      "13\n",
+      "<class 'dict'>\n",
+      "14\n",
+      "<class 'dict'>\n",
+      "15\n",
+      "<class 'dict'>\n",
+      "16\n",
+      "<class 'dict'>\n",
+      "17\n",
+      "<class 'dict'>\n",
+      "18\n",
+      "<class 'dict'>\n",
+      "19\n",
+      "<class 'dict'>\n",
+      "20\n",
+      "<class 'dict'>\n",
+      "21\n",
+      "<class 'dict'>\n",
+      "22\n",
+      "<class 'dict'>\n",
+      "23\n",
+      "<class 'dict'>\n",
+      "24\n",
+      "<class 'dict'>\n",
+      "25\n",
+      "<class 'dict'>\n",
+      "26\n",
+      "<class 'dict'>\n",
+      "27\n",
+      "<class 'dict'>\n",
+      "28\n",
+      "<class 'dict'>\n",
+      "29\n",
+      "<class 'dict'>\n",
+      "30\n",
+      "<class 'dict'>\n",
+      "31\n",
+      "<class 'dict'>\n",
+      "32\n",
+      "<class 'dict'>\n",
+      "33\n",
+      "<class 'dict'>\n",
+      "34\n",
+      "<class 'dict'>\n",
+      "35\n",
+      "<class 'dict'>\n",
+      "36\n",
+      "<class 'dict'>\n",
+      "37\n",
+      "<class 'dict'>\n",
+      "38\n",
+      "<class 'dict'>\n",
+      "39\n",
+      "<class 'dict'>\n",
+      "40\n",
+      "<class 'dict'>\n",
+      "41\n",
+      "<class 'dict'>\n",
+      "42\n",
+      "<class 'dict'>\n",
+      "43\n",
+      "<class 'dict'>\n",
+      "44\n",
+      "<class 'dict'>\n",
+      "45\n",
+      "<class 'dict'>\n",
+      "46\n",
+      "<class 'dict'>\n",
+      "47\n",
+      "<class 'dict'>\n",
+      "48\n",
+      "<class 'dict'>\n",
+      "49\n",
+      "<class 'dict'>\n",
+      "50\n",
+      "<class 'dict'>\n",
+      "51\n",
+      "<class 'dict'>\n",
+      "52\n",
+      "<class 'dict'>\n",
+      "53\n",
+      "<class 'dict'>\n",
+      "54\n",
+      "<class 'dict'>\n",
+      "55\n",
+      "<class 'dict'>\n",
+      "56\n",
+      "<class 'dict'>\n",
+      "57\n",
+      "<class 'dict'>\n",
+      "58\n",
+      "<class 'dict'>\n",
+      "59\n",
+      "<class 'dict'>\n",
+      "60\n",
+      "<class 'dict'>\n",
+      "61\n",
+      "<class 'dict'>\n",
+      "62\n",
+      "<class 'dict'>\n",
+      "63\n",
+      "<class 'dict'>\n",
+      "64\n",
+      "<class 'dict'>\n",
+      "65\n",
+      "<class 'dict'>\n"
+     ]
+    },
+    {
+     "ename": "KeyboardInterrupt",
+     "evalue": "",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[226], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader, \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(idx)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(data))\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 671\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    673\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/utils/data/_utils/fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     60\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
+      "Cell \u001b[0;32mIn[222], line 21\u001b[0m, in \u001b[0;36mSiameseDataloader.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     19\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_text_train[index]:\n\u001b[0;32m---> 21\u001b[0m     encoded_sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Add `[CLS]` and `[SEP]` special tokens\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAX_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m             \u001b[49m\u001b[38;5;66;43;03m# Choose max length to truncate/pad\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_max_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Pad sentence to max length \u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#return_attention_mask=True      # Return attention mask\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     input_ids\u001b[38;5;241m.\u001b[39mappend(encoded_sent\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     30\u001b[0m     attention_masks\u001b[38;5;241m.\u001b[39mappend(encoded_sent\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils_base.py:2727\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2717\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   2718\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   2719\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   2720\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2724\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2725\u001b[0m )\n\u001b[0;32m-> 2727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2730\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2742\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2745\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2746\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils.py:649\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    642\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    647\u001b[0m     )\n\u001b[0;32m--> 649\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_for_model(\n\u001b[1;32m    653\u001b[0m     first_ids,\n\u001b[1;32m    654\u001b[0m     pair_ids\u001b[38;5;241m=\u001b[39msecond_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    668\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    669\u001b[0m )\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils.py:616\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus.<locals>.get_input_ids\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[1;32m    615\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 616\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    617\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/tokenization_utils.py:547\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[0;34m(self, text, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 547\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    548\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/roberta/tokenization_roberta.py:300\u001b[0m, in \u001b[0;36mRobertaTokenizer._tokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m re\u001b[38;5;241m.\u001b[39mfindall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpat, text):\n\u001b[1;32m    297\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbyte_encoder[b] \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m token\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m     )  \u001b[38;5;66;03m# Maps all our bytes to unicode strings, avoiding control tokens of the BPE (spaces in our case)\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m     bpe_tokens\u001b[38;5;241m.\u001b[39mextend(bpe_token \u001b[38;5;28;01mfor\u001b[39;00m bpe_token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbpe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bpe_tokens\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/roberta/tokenization_roberta.py:253\u001b[0m, in \u001b[0;36mRobertaTokenizer.bpe\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbpe\u001b[39m(\u001b[38;5;28mself\u001b[39m, token):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache:\n\u001b[0;32m--> 253\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241m.\u001b[39mcache[token]\n\u001b[1;32m    254\u001b[0m     word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(token)\n\u001b[1;32m    255\u001b[0m     pairs \u001b[38;5;241m=\u001b[39m get_pairs(word)\n",
+      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
+     ]
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 163,
+   "id": "496b3fb7",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "#### Bert tokenizer"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 327,
+   "id": "342145fa",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 210,
+   "id": "eeff9c1f",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 211,
+   "id": "b612204a",
+   "metadata": {},
+   "outputs": [],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 214,
+   "id": "40246b4d",
+   "metadata": {
+    "collapsed": true
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0],\n",
+       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0],\n",
+       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0],\n",
+       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0],\n",
+       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
+       "         0, 0, 0, 0]])"
+      ]
+     },
+     "execution_count": 214,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 192,
+   "id": "a66defb4",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "torch.Size([5, 100])"
+      ]
+     },
+     "execution_count": 192,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 200,
+   "id": "d53a5ede",
+   "metadata": {
+    "collapsed": true
+   },
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "[0,\n",
+       " 12654,\n",
+       " 6932,\n",
+       " 18497,\n",
+       " 1018,\n",
+       " 30,\n",
+       " 7773,\n",
+       " 36,\n",
+       " 13459,\n",
+       " 6,\n",
+       " 289,\n",
+       " 5268,\n",
+       " 6,\n",
+       " 23084,\n",
+       " 5268,\n",
+       " 238,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 36,\n",
+       " 44910,\n",
+       " 2407,\n",
+       " 212,\n",
+       " 1728,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 6,\n",
+       " 10415,\n",
+       " 23822,\n",
+       " 20962,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 6,\n",
+       " 37787,\n",
+       " 12589,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 6,\n",
+       " 10415,\n",
+       " 4104,\n",
+       " 13597,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 238,\n",
+       " 8,\n",
+       " 6131,\n",
+       " 36,\n",
+       " 591,\n",
+       " 2562,\n",
+       " 734,\n",
+       " 13002,\n",
+       " 870,\n",
+       " 35,\n",
+       " 5123,\n",
+       " 463,\n",
+       " 10006,\n",
+       " 2580,\n",
+       " 2091,\n",
+       " 6932,\n",
+       " 18497,\n",
+       " 1018,\n",
+       " 30,\n",
+       " 7773,\n",
+       " 36,\n",
+       " 13459,\n",
+       " 6,\n",
+       " 289,\n",
+       " 5268,\n",
+       " 6,\n",
+       " 23084,\n",
+       " 5268,\n",
+       " 238,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 36,\n",
+       " 44910,\n",
+       " 2407,\n",
+       " 212,\n",
+       " 1728,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 6,\n",
+       " 10415,\n",
+       " 23822,\n",
+       " 20962,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 6,\n",
+       " 37787,\n",
+       " 12589,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 6,\n",
+       " 10415,\n",
+       " 4104,\n",
+       " 13597,\n",
+       " 18357,\n",
+       " 424,\n",
+       " 238,\n",
+       " 8,\n",
+       " 6131,\n",
+       " 36,\n",
+       " 591,\n",
+       " 2562,\n",
+       " 6,\n",
+       " 369,\n",
+       " 730,\n",
+       " 6,\n",
+       " 1005,\n",
+       " 6,\n",
+       " 2367,\n",
+       " 953,\n",
+       " 359,\n",
+       " 1327,\n",
+       " 6,\n",
+       " 391,\n",
+       " 730,\n",
+       " 43,\n",
+       " 111,\n",
+       " 1849,\n",
+       " 1666,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 597,\n",
+       " 3239,\n",
+       " 6331,\n",
+       " 4932,\n",
+       " 29,\n",
+       " 10249,\n",
+       " 4466,\n",
+       " 2521,\n",
+       " 208,\n",
+       " 4,\n",
+       " 250,\n",
+       " 4,\n",
+       " 1234,\n",
+       " 12,\n",
+       " 14699,\n",
+       " 128,\n",
+       " 7405,\n",
+       " 387,\n",
+       " 27144,\n",
+       " 4576,\n",
+       " 500,\n",
+       " 131,\n",
+       " 11011,\n",
+       " 312,\n",
+       " 868,\n",
+       " 3283,\n",
+       " 274,\n",
+       " 3239,\n",
+       " 3966,\n",
+       " 12803,\n",
+       " 35,\n",
+       " 10249,\n",
+       " 4466,\n",
+       " 2521,\n",
+       " 208,\n",
+       " 4,\n",
+       " 250,\n",
+       " 12651,\n",
+       " 1205,\n",
+       " 640,\n",
+       " 1401,\n",
+       " 4,\n",
+       " 506,\n",
+       " 3239,\n",
+       " 6528,\n",
+       " 1033,\n",
+       " 4,\n",
+       " 175,\n",
+       " 73,\n",
+       " 11953,\n",
+       " 73,\n",
+       " 241,\n",
+       " 73,\n",
+       " 12636,\n",
+       " 3506,\n",
+       " 35422,\n",
+       " 274,\n",
+       " 3239,\n",
+       " 3966,\n",
+       " 12,\n",
+       " 41715,\n",
+       " 1584,\n",
+       " 12,\n",
+       " 3669,\n",
+       " 502,\n",
+       " 8835,\n",
+       " 35,\n",
+       " 274,\n",
+       " 3239,\n",
+       " 3966,\n",
+       " 34,\n",
+       " 5530,\n",
+       " 230,\n",
+       " 9993,\n",
+       " 12,\n",
+       " 12804,\n",
+       " 1038,\n",
+       " 138,\n",
+       " 10249,\n",
+       " 4466,\n",
+       " 2521,\n",
+       " 208,\n",
+       " 4,\n",
+       " 250,\n",
+       " 4,\n",
+       " 36,\n",
+       " 534,\n",
+       " 6078,\n",
+       " 43,\n",
+       " 10,\n",
+       " 78,\n",
+       " 12,\n",
+       " 958,\n",
+       " 1666,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 565,\n",
+       " 594,\n",
+       " 763,\n",
+       " 5974,\n",
+       " 603,\n",
+       " 23,\n",
+       " 8406,\n",
+       " 225,\n",
+       " 208,\n",
+       " 26661,\n",
+       " 4484,\n",
+       " 359,\n",
+       " 2169,\n",
+       " 34235,\n",
+       " 7271,\n",
+       " 36,\n",
+       " 46138,\n",
+       " 43,\n",
+       " 111,\n",
+       " 6858,\n",
+       " 17356,\n",
+       " 1258,\n",
+       " 13766,\n",
+       " 347,\n",
+       " 163,\n",
+       " 10296,\n",
+       " 3764,\n",
+       " 100,\n",
+       " 6,\n",
+       " 5102,\n",
+       " 2118,\n",
+       " 975,\n",
+       " 4014,\n",
+       " 6,\n",
+       " 230,\n",
+       " 4581,\n",
+       " 2796,\n",
+       " 4248,\n",
+       " 13675,\n",
+       " 13784,\n",
+       " 35,\n",
+       " 404,\n",
+       " 235,\n",
+       " 4,\n",
+       " 2647,\n",
+       " 6,\n",
+       " 2814,\n",
+       " 124,\n",
+       " 6,\n",
+       " 3370,\n",
+       " 4,\n",
+       " 38,\n",
+       " 437,\n",
+       " 5908,\n",
+       " 21325,\n",
+       " 7930,\n",
+       " 6,\n",
+       " 8406,\n",
+       " 225,\n",
+       " 18,\n",
+       " 2683,\n",
+       " 6,\n",
+       " 1123,\n",
+       " 8,\n",
+       " 18303,\n",
+       " 2066,\n",
+       " 6,\n",
+       " 53,\n",
+       " 67,\n",
+       " 8406,\n",
+       " 225,\n",
+       " 18,\n",
+       " 681,\n",
+       " 1399,\n",
+       " 518,\n",
+       " 2066,\n",
+       " 6,\n",
+       " 61,\n",
+       " 16,\n",
+       " 99,\n",
+       " 42,\n",
+       " 5209,\n",
+       " 16,\n",
+       " 6,\n",
+       " 1666,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 36812,\n",
+       " 366,\n",
+       " 26855,\n",
+       " 4602,\n",
+       " 2565,\n",
+       " 344,\n",
+       " 846,\n",
+       " 590,\n",
+       " 230,\n",
+       " 6842,\n",
+       " 31285,\n",
+       " 382,\n",
+       " 2222,\n",
+       " 7765,\n",
+       " 366,\n",
+       " 2169,\n",
+       " 8,\n",
+       " 928,\n",
+       " 12,\n",
+       " 805,\n",
+       " 6247,\n",
+       " 176,\n",
+       " 6857,\n",
+       " 7248,\n",
+       " 6149,\n",
+       " 102,\n",
+       " 4177,\n",
+       " 6457,\n",
+       " 13212,\n",
+       " 20643,\n",
+       " 33,\n",
+       " 4829,\n",
+       " 10,\n",
+       " 2660,\n",
+       " 5057,\n",
+       " 7,\n",
+       " 5445,\n",
+       " 4363,\n",
+       " 5604,\n",
+       " 8,\n",
+       " 3521,\n",
+       " 36,\n",
+       " 3376,\n",
+       " 104,\n",
+       " 43,\n",
+       " 1616,\n",
+       " 15,\n",
+       " 5,\n",
+       " 382,\n",
+       " 4602,\n",
+       " 2565,\n",
+       " 8,\n",
+       " 11,\n",
+       " 5,\n",
+       " 4602,\n",
+       " 9,\n",
+       " 1625,\n",
+       " 4,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 2796,\n",
+       " 2076,\n",
+       " 21661,\n",
+       " 359,\n",
+       " 15770,\n",
+       " 5061,\n",
+       " 5199,\n",
+       " 1723,\n",
+       " 131,\n",
+       " 17983,\n",
+       " 6910,\n",
+       " 5504,\n",
+       " 8835,\n",
+       " 681,\n",
+       " 4195,\n",
+       " 1002,\n",
+       " 13,\n",
+       " 22242,\n",
+       " 7060,\n",
+       " 62,\n",
+       " 7,\n",
+       " 379,\n",
+       " 4,\n",
+       " 996,\n",
+       " 475,\n",
+       " 8502,\n",
+       " 5657,\n",
+       " 6019,\n",
+       " 41229,\n",
+       " 975,\n",
+       " 4,\n",
+       " 502,\n",
+       " 132,\n",
+       " 36,\n",
+       " 26267,\n",
+       " 26258,\n",
+       " 43,\n",
+       " 111,\n",
+       " 17983,\n",
+       " 122,\n",
+       " 3352,\n",
+       " 5,\n",
+       " 22242,\n",
+       " 7060,\n",
+       " 882,\n",
+       " 7,\n",
+       " 2592,\n",
+       " 379,\n",
+       " 4,\n",
+       " 996,\n",
+       " 153,\n",
+       " 5657,\n",
+       " 9,\n",
+       " 681,\n",
+       " 42,\n",
+       " 76,\n",
+       " 6,\n",
+       " 41,\n",
+       " 712,\n",
+       " 9,\n",
+       " 204,\n",
+       " 4,\n",
+       " 245,\n",
+       " 207,\n",
+       " 31,\n",
+       " 5,\n",
+       " 986,\n",
+       " 3839,\n",
+       " 9,\n",
+       " 501,\n",
+       " 4,\n",
+       " 245,\n",
+       " 153,\n",
+       " 23225,\n",
+       " 6,\n",
+       " 5,\n",
+       " 34353,\n",
+       " 168,\n",
+       " 26,\n",
+       " 15,\n",
+       " 307,\n",
+       " 4,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 4239,\n",
+       " 4929,\n",
+       " 17,\n",
+       " 27,\n",
+       " 29,\n",
+       " 1259,\n",
+       " 22630,\n",
+       " 12848,\n",
+       " 6,\n",
+       " 7803,\n",
+       " 2141,\n",
+       " 4929,\n",
+       " 11714,\n",
+       " 8765,\n",
+       " 579,\n",
+       " 2321,\n",
+       " 1259,\n",
+       " 15,\n",
+       " 294,\n",
+       " 6,\n",
+       " 502,\n",
+       " 290,\n",
+       " 6,\n",
+       " 373,\n",
+       " 20008,\n",
+       " 440,\n",
+       " 4,\n",
+       " 112,\n",
+       " 579,\n",
+       " 485,\n",
+       " 18366,\n",
+       " 534,\n",
+       " 12,\n",
+       " 12804,\n",
+       " 736,\n",
+       " 3096,\n",
+       " 339,\n",
+       " 23,\n",
+       " 12848,\n",
+       " 20514,\n",
+       " 1913,\n",
+       " 4,\n",
+       " 36,\n",
+       " 1000,\n",
+       " 3765,\n",
+       " 43,\n",
+       " 2295,\n",
+       " 1273,\n",
+       " 8,\n",
+       " 41,\n",
+       " 7335,\n",
+       " 14,\n",
+       " 10,\n",
+       " 7176,\n",
+       " 64,\n",
+       " 146,\n",
+       " 10,\n",
+       " 2249,\n",
+       " 77,\n",
+       " 24,\n",
+       " 4922,\n",
+       " 13,\n",
+       " 5,\n",
+       " 1079,\n",
+       " 1666,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 791,\n",
+       " 4,\n",
+       " 104,\n",
+       " 4,\n",
+       " 312,\n",
+       " 6368,\n",
+       " 34994,\n",
+       " 11,\n",
+       " 28905,\n",
+       " 23463,\n",
+       " 131,\n",
+       " 4417,\n",
+       " 5946,\n",
+       " 12423,\n",
+       " 1458,\n",
+       " 2829,\n",
+       " 25,\n",
+       " 208,\n",
+       " 947,\n",
+       " 510,\n",
+       " 1764,\n",
+       " 21,\n",
+       " 59,\n",
+       " 3269,\n",
+       " 20,\n",
+       " 208,\n",
+       " 947,\n",
+       " 510,\n",
+       " 1764,\n",
+       " 1249,\n",
+       " 2829,\n",
+       " 723,\n",
+       " 294,\n",
+       " 6,\n",
+       " 3784,\n",
+       " 5,\n",
+       " 1965,\n",
+       " 7,\n",
+       " 63,\n",
+       " 371,\n",
+       " 12,\n",
+       " 21810,\n",
+       " 593,\n",
+       " 15,\n",
+       " 638,\n",
+       " 6,\n",
+       " 71,\n",
+       " 10,\n",
+       " 1446,\n",
+       " 183,\n",
+       " 4760,\n",
+       " 30,\n",
+       " 6787,\n",
+       " 14389,\n",
+       " 227,\n",
+       " 3077,\n",
+       " 8,\n",
+       " 2687,\n",
+       " 4,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 36138,\n",
+       " 25984,\n",
+       " 2169,\n",
+       " 96,\n",
+       " 22630,\n",
+       " 598,\n",
+       " 4228,\n",
+       " 12848,\n",
+       " 17,\n",
+       " 27,\n",
+       " 29,\n",
+       " 7999,\n",
+       " 6,\n",
+       " 14781,\n",
+       " 312,\n",
+       " 5556,\n",
+       " 1327,\n",
+       " 12,\n",
+       " 12804,\n",
+       " 17316,\n",
+       " 2169,\n",
+       " 8,\n",
+       " 12848,\n",
+       " 20514,\n",
+       " 1913,\n",
+       " 32,\n",
+       " 11,\n",
+       " 5451,\n",
+       " 1431,\n",
+       " 81,\n",
+       " 5,\n",
+       " 1392,\n",
+       " 9,\n",
+       " 12848,\n",
+       " 17,\n",
+       " 27,\n",
+       " 29,\n",
+       " 773,\n",
+       " 11,\n",
+       " 1007,\n",
+       " 1781,\n",
+       " 11,\n",
+       " 7999,\n",
+       " 8,\n",
+       " 14781,\n",
+       " 6,\n",
+       " 5,\n",
+       " 451,\n",
+       " 34,\n",
+       " 26,\n",
+       " 4,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 10567,\n",
+       " 24889,\n",
+       " 1794,\n",
+       " 4742,\n",
+       " 6,\n",
+       " 320,\n",
+       " 10700,\n",
+       " 4541,\n",
+       " 944,\n",
+       " 4,\n",
+       " 394,\n",
+       " 8,\n",
+       " 1007,\n",
+       " 7156,\n",
+       " 6,\n",
+       " 8524,\n",
+       " 23,\n",
+       " 6521,\n",
+       " 610,\n",
+       " 24889,\n",
+       " 1794,\n",
+       " 4742,\n",
+       " 6,\n",
+       " 320,\n",
+       " 394,\n",
+       " 9,\n",
+       " 10700,\n",
+       " 4541,\n",
+       " 944,\n",
+       " 482,\n",
+       " 10,\n",
+       " 2499,\n",
+       " 12,\n",
+       " 805,\n",
+       " 8540,\n",
+       " 9,\n",
+       " 5,\n",
+       " 7556,\n",
+       " 12,\n",
+       " 805,\n",
+       " 2930,\n",
+       " 5979,\n",
+       " 10700,\n",
+       " 221,\n",
+       " 6447,\n",
+       " 36,\n",
+       " 2554,\n",
+       " 35,\n",
+       " 248,\n",
+       " 5433,\n",
+       " 12,\n",
+       " 250,\n",
+       " 6,\n",
+       " 248,\n",
+       " 5433,\n",
+       " 12,\n",
+       " 387,\n",
+       " 238,\n",
+       " 962,\n",
+       " 23,\n",
+       " 6521,\n",
+       " 4,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 27004,\n",
+       " 8,\n",
+       " 5123,\n",
+       " 131,\n",
+       " 17104,\n",
+       " 7829,\n",
+       " 13393,\n",
+       " 506,\n",
+       " 1344,\n",
+       " 5354,\n",
+       " 7,\n",
+       " 291,\n",
+       " 2481,\n",
+       " 111,\n",
+       " 17438,\n",
+       " 15936,\n",
+       " 31,\n",
+       " 14479,\n",
+       " 359,\n",
+       " 13006,\n",
+       " 642,\n",
+       " 7055,\n",
+       " 16,\n",
+       " 19181,\n",
+       " 7498,\n",
+       " 734,\n",
+       " 8835,\n",
+       " 344,\n",
+       " 4154,\n",
+       " 290,\n",
+       " 36,\n",
+       " 42195,\n",
+       " 3569,\n",
+       " 5532,\n",
+       " 43,\n",
+       " 480,\n",
+       " 870,\n",
+       " 10,\n",
+       " 491,\n",
+       " 9989,\n",
+       " 12,\n",
+       " 24221,\n",
+       " 491,\n",
+       " 8627,\n",
+       " 23,\n",
+       " 436,\n",
+       " 7830,\n",
+       " 491,\n",
+       " 480,\n",
+       " 20,\n",
+       " 22,\n",
+       " 35776,\n",
+       " 13393,\n",
+       " 506,\n",
+       " 1344,\n",
+       " 1018,\n",
+       " 111,\n",
+       " 7498,\n",
+       " 6,\n",
+       " 16565,\n",
+       " 6,\n",
+       " 6247,\n",
+       " 43814,\n",
+       " 12,\n",
+       " 1646,\n",
+       " 14052,\n",
+       " 6,\n",
+       " 8,\n",
+       " 6311,\n",
+       " 25303,\n",
+       " 36,\n",
+       " 844,\n",
+       " 2146,\n",
+       " 111,\n",
+       " 291,\n",
+       " 2481,\n",
+       " 30831,\n",
+       " 266,\n",
+       " 34,\n",
+       " 57,\n",
+       " 355,\n",
+       " 7,\n",
+       " 1624,\n",
+       " 2409,\n",
+       " 10006,\n",
+       " 2580,\n",
+       " 4,\n",
+       " 175,\n",
+       " 18,\n",
+       " 1839,\n",
+       " 4,\n",
+       " 1666,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 791,\n",
+       " 3297,\n",
+       " 5680,\n",
+       " 111,\n",
+       " 11518,\n",
+       " 4995,\n",
+       " 2961,\n",
+       " 15556,\n",
+       " 687,\n",
+       " 36,\n",
+       " 21536,\n",
+       " 274,\n",
+       " 7022,\n",
+       " 111,\n",
+       " 41669,\n",
+       " 387,\n",
+       " 176,\n",
+       " 43,\n",
+       " 1009,\n",
+       " 2578,\n",
+       " 259,\n",
+       " 7,\n",
+       " 1217,\n",
+       " 42,\n",
+       " 3780,\n",
+       " 11,\n",
+       " 63,\n",
+       " 1461,\n",
+       " 7390,\n",
+       " 11518,\n",
+       " 4995,\n",
+       " 2961,\n",
+       " 15556,\n",
+       " 687,\n",
+       " 36,\n",
+       " 21536,\n",
+       " 274,\n",
+       " 7022,\n",
+       " 111,\n",
+       " 41669,\n",
+       " 387,\n",
+       " 176,\n",
+       " 43,\n",
+       " 20,\n",
+       " 335,\n",
+       " 11,\n",
+       " 42,\n",
+       " 26449,\n",
+       " 27005,\n",
+       " 20374,\n",
+       " 44484,\n",
+       " 16,\n",
+       " 45,\n",
+       " 1498,\n",
+       " 8,\n",
+       " 189,\n",
+       " 28,\n",
+       " 1714,\n",
+       " 4,\n",
+       " 166,\n",
+       " 189,\n",
+       " 45,\n",
+       " 1331,\n",
+       " 209,\n",
+       " 17152,\n",
+       " 454,\n",
+       " 5,\n",
+       " 6858,\n",
+       " 1666,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 37577,\n",
+       " 29974,\n",
+       " 35,\n",
+       " 15008,\n",
+       " 1740,\n",
+       " 20586,\n",
+       " 12814,\n",
+       " 154,\n",
+       " 7,\n",
+       " 5778,\n",
+       " 7229,\n",
+       " 280,\n",
+       " 55,\n",
+       " 867,\n",
+       " 575,\n",
+       " 59,\n",
+       " 5,\n",
+       " 913,\n",
+       " 9,\n",
+       " 49,\n",
+       " 1781,\n",
+       " 16,\n",
+       " 10180,\n",
+       " 31,\n",
+       " 5,\n",
+       " 382,\n",
+       " 1629,\n",
+       " 1360,\n",
+       " 4700,\n",
+       " 14,\n",
+       " 34,\n",
+       " 28601,\n",
+       " 88,\n",
+       " 10,\n",
+       " 1186,\n",
+       " 9,\n",
+       " 5068,\n",
+       " 4848,\n",
+       " 4964,\n",
+       " 7197,\n",
+       " 6,\n",
+       " 14098,\n",
+       " 11470,\n",
+       " 915,\n",
+       " 1052,\n",
+       " 25,\n",
+       " 2566,\n",
+       " 21977,\n",
+       " 7,\n",
+       " 972,\n",
+       " 49,\n",
+       " 782,\n",
+       " 4,\n",
+       " 42654,\n",
+       " 1629,\n",
+       " 48134,\n",
+       " 791,\n",
+       " 4,\n",
+       " 104,\n",
+       " 4,\n",
+       " 15770,\n",
+       " 27757,\n",
+       " 3764,\n",
+       " 248,\n",
+       " 18103,\n",
+       " 9673,\n",
+       " 12,\n",
+       " 6479,\n",
+       " 11575,\n",
+       " 6,\n",
+       " 2367,\n",
+       " 1409,\n",
+       " 6,\n",
+       " 25951,\n",
+       " 7135,\n",
+       " 5776,\n",
+       " 10381,\n",
+       " 44,\n",
+       " 15375,\n",
+       " 502,\n",
+       " 290,\n",
+       " 36,\n",
+       " 1251,\n",
+       " 43,\n",
+       " 111,\n",
+       " 2298,\n",
+       " 852,\n",
+       " 5157,\n",
+       " 1066,\n",
+       " 7692,\n",
+       " 49,\n",
+       " 2945,\n",
+       " 8,\n",
+       " 425,\n",
+       " 3247,\n",
+       " 15,\n",
+       " 484,\n",
+       " 121,\n",
+       " 4,\n",
+       " 104,\n",
+       " 3358,\n",
+       " 11301,\n",
+       " 451,\n",
+       " 6,\n",
+       " 217,\n",
+       " 6479,\n",
+       " 11575,\n",
+       " 6,\n",
+       " 2367,\n",
+       " 1409,\n",
+       " 8,\n",
+       " 25951,\n",
+       " 7135,\n",
+       " 5776,\n",
+       " 10381,\n",
+       " 6,\n",
+       " 15,\n",
+       " 294,\n",
+       " 4,\n",
+       " 289,\n",
+       " 5969,\n",
+       " 8064,\n",
+       " 26686,\n",
+       " 1009,\n",
+       " 6479,\n",
+       " 11575,\n",
+       " 603,\n",
+       " 4832,\n",
+       " 734,\n",
+       " 42654,\n",
+       " ...]"
+      ]
+     },
+     "execution_count": 200,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
+  },
   {
    "cell_type": "markdown",
-   "id": "4c3a0034",
+   "id": "7b8f0480",
    "metadata": {},
    "source": [
     "## Build model\n"
@@ -673,18 +2024,14 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 74,
-   "id": "651047c6",
+   "execution_count": 334,
+   "id": "13a4d47c",
    "metadata": {},
    "outputs": [
     {
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "Downloading (…)olve/main/vocab.json: 100%|███| 899k/899k [00:00<00:00, 1.06MB/s]\n",
-      "Downloading (…)olve/main/merges.txt: 100%|████| 456k/456k [00:00<00:00, 621kB/s]\n",
-      "Downloading (…)lve/main/config.json: 100%|██████| 482/482 [00:00<00:00, 193kB/s]\n",
-      "Downloading pytorch_model.bin: 100%|███████| 1.43G/1.43G [06:27<00:00, 3.68MB/s]\n",
       "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
       "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
       "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
@@ -698,11 +2045,23 @@
     "\n",
     "class SiameseModel(nn.Module):\n",
     "    def __init__(self, input_dim1, input_dim2, \n",
-    "                 hidden_dim1, hidden_dim2, hidden_dim3, \n",
+    "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
     "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
     "        super(SiameseModel, self).__init__()\n",
-    "        self.tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
-    "        self.text_encoder = RobertaModel.from_pretrained('roberta-large')\n",
+    "        self.input_dim1 = input_dim1\n",
+    "        self.input_dim2 = input_dim2\n",
+    "        self.hidden_dim1 = hidden_dim1\n",
+    "        self.hidden_dim2 = hidden_dim2\n",
+    "        self.hidden_dim3 = hidden_dim3\n",
+    "        self.hidden_dim4 = hidden_dim4\n",
+    "        self.num_layers1 = num_layers1\n",
+    "        self.num_layers2 = num_layers2\n",
+    "        self.output_dim1 = output_dim1\n",
+    "        self.output_dim2 = output_dim2\n",
+    "        \n",
+    "        \n",
+    "\n",
+    "        self.roberta = RobertaModel.from_pretrained(\"roberta-large\")\n",
     "        \n",
     "        \n",
     "        self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
@@ -712,40 +2071,57 @@
     "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
     "        self.fc2 = nn.Linear(hidden_dim2, output_dim2)\n",
     "        self.fc3 = nn.Linear(output_dim1+output_dim2, hidden_dim3)\n",
-    "        self.fc4 = nn.Linear(hidden_dim3, 3)\n",
+    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
+    "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
     "        \n",
     "        \n",
     "        \n",
-    "    def forward(self, x1, x2):\n",
+    "    def forward(self, x1, ids, masks, token_type_ids):\n",
     "        #left tower with numerical features\n",
-    "        h10 = torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1).requires_grad_()\n",
-    "        c10 = torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1).requires_grad_()\n",
-    "        out1, (h1n, c1n) = self.lstm1(x1, (h10.detach(), c10.detach()))\n",
-    "        out1 = self.fc1(out1[:, -1, :]) \n",
     "        \n",
+    "        h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1))\n",
+    "        c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1))\n",
+    "        ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
+    "        h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
+    "        out1 = self.fc1(h_out1)\n",
     "        \n",
-    "        # right tower with roberta on textual features\n",
-    "        encoded_input = self.tokenizer(x2, return_tensors='pt')\n",
-    "        e2 = self.text_encoder(**encoded_input)\n",
     "        \n",
-    "        h20 = torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2).requires_grad_()\n",
-    "        c20 = torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2).requires_grad_()\n",
-    "        out2, (hn, cn) = self.lstm2(x2, (h20.detach(), c20.detach()))\n",
-    "        out2 = self.fc2(out2[:, -1, :]) \n",
+    "        \n",
+    "\n",
+    "        e2 = torch.zeros()\n",
+    "        # right tower with roberta on textual features  \n",
+    "        for k in range(ids.shape[1]):\n",
+    "            seq_ids = ids[:,k,:]\n",
+    "            seq_masks = masks[:,k,:]\n",
+    "            seq_token_type_ids = token_type_ids[:,k,:]\n",
+    "            \n",
+    "            \n",
+    "            e2k = self.roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
+    "            e2k = e2k[0][:, 0, :]\n",
+    "    \n",
+    "        \n",
+    "        \n",
+    "        h_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2))\n",
+    "        c_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2))\n",
+    "        ula2, (h_out2, _) = self.lstm2(x2, (h_20, c_20))\n",
+    "        h_out2 = h_out2.view(-1, self.hidden_dim2)\n",
+    "        out2 = self.fc2(h_out2)\n",
     "        \n",
     "        \n",
     "        \n",
-    "\n",
     "        \n",
-    "        output = torch.cat((out1, out2),1)\n",
-    "        output = F.relu(self.fc3(output))\n",
-    "        output = self.fc4(output)\n",
-    "        return output\n",
+    "        # siamese merging layers\n",
+    "        \n",
+    "#         output = torch.cat((out1, out2),1)\n",
+    "#         output = F.relu(self.fc3(output))\n",
+    "#         output = F.relu(self.fc4(output))\n",
+    "#         output = self.fc5(output)\n",
+    "#         return output\n",
     "    \n",
     "#TODO : correct these values\n",
     "model = SiameseModel(input_dim1 = 8, input_dim2 = 1024, \n",
-    "                 hidden_dim1 = 10, hidden_dim2 = 800, hidden_dim3 = 500, \n",
-    "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 50, output_dim2 = 50)\n",
+    "                 hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 128, hidden_dim4 = 64,\n",
+    "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256)\n",
     "\n",
     "\n",
     "    \n",
@@ -754,8 +2130,8 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 75,
-   "id": "79b6a8b9",
+   "execution_count": 317,
+   "id": "650829c7",
    "metadata": {
     "collapsed": true
    },
@@ -765,7 +2141,7 @@
      "output_type": "stream",
      "text": [
       "SiameseModel(\n",
-      "  (text_encoder): RobertaModel(\n",
+      "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
@@ -1358,440 +2734,28 @@
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
-      "  (lstm1): LSTM(8, 10, batch_first=True)\n",
-      "  (lstm2): LSTM(768, 800, batch_first=True)\n",
-      "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
-      "  (fc2): Linear(in_features=800, out_features=50, bias=True)\n",
-      "  (fc3): Linear(in_features=100, out_features=500, bias=True)\n",
-      "  (fc4): Linear(in_features=500, out_features=3, bias=True)\n",
+      "  (lstm1): LSTM(8, 20, batch_first=True)\n",
+      "  (lstm2): LSTM(1024, 768, batch_first=True)\n",
+      "  (fc1): Linear(in_features=20, out_features=10, bias=True)\n",
+      "  (fc2): Linear(in_features=768, out_features=256, bias=True)\n",
+      "  (fc3): Linear(in_features=266, out_features=128, bias=True)\n",
+      "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
+      "  (fc5): Linear(in_features=64, out_features=3, bias=True)\n",
       ")\n",
-      "407\n",
-      "torch.Size([50265, 1024])\n",
-      "torch.Size([514, 1024])\n",
-      "torch.Size([1, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n"
-     ]
-    },
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([4096, 1024])\n",
-      "torch.Size([4096])\n",
-      "torch.Size([1024, 4096])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([1024, 1024])\n",
-      "torch.Size([1024])\n",
-      "torch.Size([40, 8])\n",
-      "torch.Size([40, 10])\n",
-      "torch.Size([40])\n",
-      "torch.Size([40])\n",
-      "torch.Size([3200, 768])\n",
-      "torch.Size([3200, 800])\n",
-      "torch.Size([3200])\n",
-      "torch.Size([3200])\n",
-      "torch.Size([50, 10])\n",
-      "torch.Size([50])\n",
-      "torch.Size([50, 800])\n",
-      "torch.Size([50])\n",
-      "torch.Size([500, 100])\n",
-      "torch.Size([500])\n",
-      "torch.Size([3, 500])\n",
-      "torch.Size([3])\n"
+      "409\n"
      ]
     }
    ],
    "source": [
     "print(model)\n",
     "print(len(list(model.parameters())))\n",
-    "for i in range(len(list(model.parameters()))):\n",
-    "    print(list(model.parameters())[i].size())\n"
+    "# for i in range(len(list(model.parameters()))):\n",
+    "#     print(list(model.parameters())[i].size())\n"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "bd167a89",
+   "id": "c907601c",
    "metadata": {},
    "source": [
     "## Train model"
@@ -1799,115 +2763,177 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 69,
-   "id": "6f9cc650",
+   "execution_count": 342,
+   "id": "970ab0e7",
    "metadata": {
     "collapsed": true
    },
    "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight']\n",
+      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
+      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
+      "0it [00:00, ?it/s]/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1119740140.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'ids': torch.tensor(input_ids, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1119740140.py:45: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1119740140.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/1119740140.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'targets': torch.tensor(y_train[index], dtype=torch.float)\n"
+     ]
+    },
     {
      "name": "stdout",
      "output_type": "stream",
      "text": [
-      "Epoch  10 MSE:  0.8407482504844666\n",
-      "Epoch  20 MSE:  0.8068487048149109\n",
-      "Epoch  30 MSE:  0.7411683797836304\n",
-      "Epoch  40 MSE:  0.7207826375961304\n",
-      "Epoch  50 MSE:  0.47958889603614807\n",
-      "Epoch  60 MSE:  0.29257601499557495\n",
-      "Epoch  70 MSE:  0.14471979439258575\n",
-      "Epoch  80 MSE:  0.045132964849472046\n",
-      "Epoch  90 MSE:  0.01147476676851511\n",
-      "Epoch  100 MSE:  0.0039354609325528145\n",
-      "Epoch  110 MSE:  0.001934159197844565\n",
-      "Epoch  120 MSE:  0.0012813452631235123\n",
-      "Epoch  130 MSE:  0.0009837034158408642\n",
-      "Epoch  140 MSE:  0.0008080229163169861\n",
-      "Epoch  150 MSE:  0.0006962246261537075\n",
-      "Epoch  160 MSE:  0.0006137943710200489\n",
-      "Epoch  170 MSE:  0.0005495513323694468\n",
-      "Epoch  180 MSE:  0.0004968825378455222\n",
-      "Epoch  190 MSE:  0.00045257911551743746\n",
-      "Epoch  200 MSE:  0.0004146856372244656\n",
-      "Epoch  210 MSE:  0.00038184275035746396\n",
-      "Epoch  220 MSE:  0.0003531062975525856\n",
-      "Epoch  230 MSE:  0.0003277502255514264\n",
-      "Epoch  240 MSE:  0.0003052429819945246\n",
-      "Epoch  250 MSE:  0.0002851351164281368\n",
-      "Epoch  260 MSE:  0.000267079594777897\n",
-      "Epoch  270 MSE:  0.00025078782346099615\n",
-      "Epoch  280 MSE:  0.00023602470173500478\n",
-      "Epoch  290 MSE:  0.00022259485558606684\n",
-      "Epoch  300 MSE:  0.0002103321603499353\n",
-      "Epoch  310 MSE:  0.00019910575065296143\n",
-      "Epoch  320 MSE:  0.00018879210983868688\n",
-      "Epoch  330 MSE:  0.00017928759916685522\n",
-      "Epoch  340 MSE:  0.0001705099130049348\n",
-      "Epoch  350 MSE:  0.00016238645184785128\n",
-      "Epoch  360 MSE:  0.0001548424334032461\n",
-      "Epoch  370 MSE:  0.0001478299527661875\n",
-      "Epoch  380 MSE:  0.00014129634655546397\n",
-      "Epoch  390 MSE:  0.0001352005056105554\n",
-      "Epoch  400 MSE:  0.00012949401570949703\n",
-      "Epoch  410 MSE:  0.0001241543359356001\n",
-      "Epoch  420 MSE:  0.00011914050992345437\n",
-      "Epoch  430 MSE:  0.00011443185940152034\n",
-      "Epoch  440 MSE:  0.00010999880032613873\n",
-      "Epoch  450 MSE:  0.00010582833056105301\n",
-      "Epoch  460 MSE:  0.00010189037857344374\n",
-      "Epoch  470 MSE:  9.817193495109677e-05\n",
-      "Epoch  480 MSE:  9.465834591537714e-05\n",
-      "Epoch  490 MSE:  9.132863488048315e-05\n",
-      "Epoch  500 MSE:  8.817756315693259e-05\n",
-      "Epoch  510 MSE:  8.518871618434787e-05\n",
-      "Epoch  520 MSE:  8.234671986429021e-05\n",
-      "Epoch  530 MSE:  7.964819815242663e-05\n",
-      "Epoch  540 MSE:  7.708567136432976e-05\n",
-      "Epoch  550 MSE:  7.464136433554813e-05\n",
-      "Epoch  560 MSE:  7.231043127831072e-05\n",
-      "Epoch  570 MSE:  7.009095861576498e-05\n",
-      "Epoch  580 MSE:  6.797187961637974e-05\n",
-      "Epoch  590 MSE:  6.594765727641061e-05\n",
-      "Epoch  600 MSE:  6.401153950719163e-05\n",
-      "Epoch  610 MSE:  6.216402107384056e-05\n",
-      "Epoch  620 MSE:  6.039403160684742e-05\n",
-      "Epoch  630 MSE:  5.8696503401733935e-05\n",
-      "Epoch  640 MSE:  5.707578020519577e-05\n",
-      "Epoch  650 MSE:  5.5515476560685784e-05\n",
-      "Epoch  660 MSE:  5.4020911193219945e-05\n",
-      "Epoch  670 MSE:  5.2586528909159824e-05\n",
-      "Epoch  680 MSE:  5.1207523938501254e-05\n",
-      "Epoch  690 MSE:  4.988486034562811e-05\n",
-      "Epoch  700 MSE:  4.8607224016450346e-05\n",
-      "Epoch  710 MSE:  4.7382065531564876e-05\n",
-      "Epoch  720 MSE:  4.619977335096337e-05\n",
-      "Epoch  730 MSE:  4.506563345785253e-05\n",
-      "Epoch  740 MSE:  4.397338489070535e-05\n",
-      "Epoch  750 MSE:  4.2914838559227064e-05\n",
-      "Epoch  760 MSE:  4.189506944385357e-05\n",
-      "Epoch  770 MSE:  4.091285518370569e-05\n",
-      "Epoch  780 MSE:  3.996507075498812e-05\n",
-      "Epoch  790 MSE:  3.9044738514348865e-05\n",
-      "Epoch  800 MSE:  3.8160764233907685e-05\n",
-      "Epoch  810 MSE:  3.730784737854265e-05\n",
-      "Epoch  820 MSE:  3.647780977189541e-05\n",
-      "Epoch  830 MSE:  3.567449311958626e-05\n",
-      "Epoch  840 MSE:  3.489935625111684e-05\n",
-      "Epoch  850 MSE:  3.4149736166000366e-05\n",
-      "Epoch  860 MSE:  3.34188953274861e-05\n",
-      "Epoch  870 MSE:  3.271406239946373e-05\n",
-      "Epoch  880 MSE:  3.20357212331146e-05\n",
-      "Epoch  890 MSE:  3.137230305583216e-05\n",
-      "Epoch  900 MSE:  3.072886829613708e-05\n",
-      "Epoch  910 MSE:  3.0105424229986966e-05\n",
-      "Epoch  920 MSE:  2.950196540041361e-05\n",
-      "Epoch  930 MSE:  2.891439726226963e-05\n",
-      "Epoch  940 MSE:  2.8345370083115995e-05\n",
-      "Epoch  950 MSE:  2.7794885681942105e-05\n",
-      "Epoch  960 MSE:  2.725427293626126e-05\n",
-      "Epoch  970 MSE:  2.6731717298389412e-05\n",
-      "Epoch  980 MSE:  2.62262619799003e-05\n",
-      "Epoch  990 MSE:  2.572947778389789e-05\n"
+      "<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>\n",
+      "<class 'torch.Tensor'>\n",
+      "torch.Size([1, 1000, 1024])\n",
+      "<class 'torch.Tensor'>\n",
+      "<class 'transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions'>\n",
+      "<class 'torch.Tensor'>\n",
+      "torch.Size([1, 1000, 1024])\n",
+      "<class 'torch.Tensor'>\n"
+     ]
+    },
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "0it [00:09, ?it/s]\n"
+     ]
+    },
+    {
+     "ename": "KeyboardInterrupt",
+     "evalue": "",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[342], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m seq_masks \u001b[38;5;241m=\u001b[39m masks[:,k,:]\n\u001b[1;32m     14\u001b[0m seq_token_type_ids \u001b[38;5;241m=\u001b[39m token_type_ids[:,k,:]\n\u001b[0;32m---> 17\u001b[0m e2k \u001b[38;5;241m=\u001b[39m \u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseq_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseq_token_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(e2k))\n\u001b[1;32m     19\u001b[0m e2k1 \u001b[38;5;241m=\u001b[39m e2k[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;66;03m#[:, 0, :]\u001b[39;00m\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/roberta/modeling_roberta.py:852\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    843\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    845\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    846\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    847\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    850\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    851\u001b[0m )\n\u001b[0;32m--> 852\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    865\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/roberta/modeling_roberta.py:527\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    518\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    519\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    520\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    524\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    525\u001b[0m     )\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 527\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    537\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/roberta/modeling_roberta.py:411\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    401\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    410\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 411\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/roberta/modeling_roberta.py:338\u001b[0m, in \u001b[0;36mRobertaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    330\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    336\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    337\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 338\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
+      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/models/roberta/modeling_roberta.py:258\u001b[0m, in \u001b[0;36mRobertaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    255\u001b[0m         relative_position_scores_key \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbhrd,lrd->bhlr\u001b[39m\u001b[38;5;124m\"\u001b[39m, key_layer, positional_embedding)\n\u001b[1;32m    256\u001b[0m         attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m relative_position_scores_query \u001b[38;5;241m+\u001b[39m relative_position_scores_key\n\u001b[0;32m--> 258\u001b[0m attention_scores \u001b[38;5;241m=\u001b[39m \u001b[43mattention_scores\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_head_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Apply the attention mask is (precomputed for all layers in RobertaModel forward() function)\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     attention_scores \u001b[38;5;241m=\u001b[39m attention_scores \u001b[38;5;241m+\u001b[39m attention_mask\n",
+      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
+     ]
+    }
+   ],
+   "source": [
+    "roberta = RobertaModel.from_pretrained(\"roberta-large\")\n",
+    "for idx, data in tqdm(enumerate(train_loader, 0)):\n",
+    "    x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
+    "    ids = data['ids'].to(device, dtype = torch.long)\n",
+    "    masks = data['mask'].to(device, dtype = torch.long)\n",
+    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
+    "    targets = data['targets'].to(device, dtype = torch.long)\n",
+    "    \n",
+    "    # debugging roberta encoder\n",
+    "    \n",
+    "    for k in range(ids.shape[1]):\n",
+    "        seq_ids = ids[:,k,:]\n",
+    "        seq_masks = masks[:,k,:]\n",
+    "        seq_token_type_ids = token_type_ids[:,k,:]\n",
+    "\n",
+    "\n",
+    "        e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
+    "        print(type(e2k))\n",
+    "        e2k1 = e2k[0][:, 0, :]\n",
+    "        print(type(e2k1))\n",
+    "        print((e2k1.shape))\n",
+    "\n",
+    "        print(type(e2k1))\n",
+    "\n",
+    "#     print(ids.shape)\n",
+    "#     print(masks.shape)\n",
+    "#     print(token_type_ids.shape)\n",
+    "#     outputs = model(x_numerical, ids, masks, token_type_ids)\n",
+    "#     print(outputs)\n",
+    "    if idx > 1:\n",
+    "        break\n",
+    "        \n",
+    "        "
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 264,
+   "id": "08cbd764",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "torch.Tensor"
+      ]
+     },
+     "execution_count": 264,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 268,
+   "id": "cd97dbdb",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "torch.Tensor"
+      ]
+     },
+     "execution_count": 268,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": []
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 245,
+   "id": "32e4f69b",
+   "metadata": {
+    "collapsed": true
+   },
+   "outputs": [
+    {
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'ids': torch.tensor(input_ids, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
+      "/var/folders/tw/t5br5nkd2k3f065pr50zxvn80000gn/T/ipykernel_22948/4024197153.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
+      "  'targets': torch.tensor(y_train[index], dtype=torch.float)\n"
+     ]
+    },
+    {
+     "ename": "ValueError",
+     "evalue": "too many values to unpack (expected 3)",
+     "output_type": "error",
+     "traceback": [
+      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
+      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
+      "Cell \u001b[0;32mIn[245], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m loss_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(num_epochs)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (x1, x2, y_train) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     11\u001b[0m         \n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         y_train_pred \u001b[38;5;241m=\u001b[39m model(x1, x2)\n\u001b[1;32m     16\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(y_train_pred, y_train)\n",
+      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
      ]
     }
    ],
@@ -1917,7 +2943,7 @@
     "\n",
     "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
     "\n",
-    "num_epochs = 20\n",
+    "num_epochs = args.n_epochs\n",
     "loss_arr = np.zeros(num_epochs)\n",
     "\n",
     "for t in range(num_epochs):\n",
@@ -1958,7 +2984,7 @@
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "65603dd5",
+   "id": "2b75f2b6",
    "metadata": {},
    "outputs": [],
    "source": [
@@ -1970,7 +2996,7 @@
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "17854251",
+   "id": "95239471",
    "metadata": {},
    "outputs": [],
    "source": [
