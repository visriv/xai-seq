{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f713ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.sdk.wandb_run.Run at 0x11251be20>"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project=\"stock_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce406fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pylab import mpl, plt\n",
    "import math, time\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "from tqdm import tqdm\n",
    "from math import sqrt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59b7da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f039160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_days_to_lookforward = 1\n",
    "no_of_days_to_lookback = 5\n",
    "up_threshold = 0.015\n",
    "down_threshold = -0.015\n",
    "max_text_per_iter = 20\n",
    "batch_size = 8\n",
    "MAX_LEN = 10\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5504757",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_symbols = [ 'XOM']\n",
    "no_of_days = 4*365\n",
    "\n",
    "EXPORT_DATA_FOLDER = './data/'\n",
    "\n",
    "# Set the start and end dates for the data \n",
    "# here matching it with dates of news text available\n",
    "train_start = datetime.strptime('2020/01/04', '%Y/%m/%d')\n",
    "train_end = datetime.strptime('2022/09/30', '%Y/%m/%d')\n",
    "test_start = datetime.strptime('2022/10/01', '%Y/%m/%d')\n",
    "test_end = datetime.strptime('2023/01/04', '%Y/%m/%d')\n",
    "\n",
    "\n",
    "# start = datetime.datetime.now() - datetime.timedelta(days=no_of_days)\n",
    "# end = datetime.datetime.now()\n",
    "\n",
    "# Get training data\n",
    "for symbol in stock_symbols:\n",
    "    # Download the historical price and volume data using yfinance\n",
    "    train_data_raw = yf.download(symbol, start=train_start, end=train_end)\n",
    "\n",
    "    # Normalize features by percent of changes between today and yesterday\n",
    "    pct_change_open = train_data_raw['Open'].pct_change().fillna(0)\n",
    "    pct_change_high = train_data_raw['High'].pct_change().fillna(0)\n",
    "    pct_change_high_over_open = (train_data_raw['High']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_low = train_data_raw['Low'].pct_change().fillna(0)\n",
    "    pct_change_low_over_open = (train_data_raw['Low']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_close = train_data_raw['Close'].pct_change().fillna(0)\n",
    "    pct_change_close_over_open = (train_data_raw['Close']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_adjclose = train_data_raw['Adj Close'].pct_change().fillna(0)\n",
    "    pct_change_adjclose_over_open = (train_data_raw['Adj Close']-train_data_raw['Open'])/train_data_raw['Open']\n",
    "    pct_change_volume = train_data_raw['Volume'].pct_change().fillna(0)\n",
    "\n",
    "    # Prepare labels: 2 means the close price of tomorow is higher than today's close price; 1 is down; 0 means the movement is between up_threshold and down_threshold\n",
    "    label = np.where(pct_change_close > up_threshold, 2, np.where(pct_change_close < down_threshold, 1, 0))[1:]\n",
    "    label = np.append(label, 0)\n",
    "\n",
    "    # Construct a train_data_norm data frame\n",
    "    train_data_norm = pd.DataFrame({'Open_norm':pct_change_open,\n",
    "                              'High_norm':pct_change_high,\n",
    "                              'Low_norm': pct_change_low,\n",
    "                              'Close_norm':pct_change_close,\n",
    "                              'Volume_norm':pct_change_volume,\n",
    "                              'High-Open_norm':pct_change_high_over_open,\n",
    "                              'Low-Open_norm':pct_change_low_over_open,\n",
    "                              'Close-Open_norm':pct_change_close_over_open,\n",
    "                              'Label_2up1down':label})\n",
    "\n",
    "    # Normalize by min-max normalization after the pct normalization\n",
    "    train_data_norm['Open_norm'] = train_data_norm['Open_norm'].apply(lambda x: (x - train_data_norm['Open_norm'].min()) / (train_data_norm['Open_norm'].max() - train_data_norm['Open_norm'].min()))\n",
    "    train_data_norm['High_norm'] = train_data_norm['High_norm'].apply(lambda x: (x - train_data_norm['High_norm'].min()) / (train_data_norm['High_norm'].max() - train_data_norm['High_norm'].min()))\n",
    "    train_data_norm['Low_norm'] = train_data_norm['Low_norm'].apply(lambda x: (x - train_data_norm['Low_norm'].min()) / (train_data_norm['Low_norm'].max() - train_data_norm['Low_norm'].min()))\n",
    "    train_data_norm['Close_norm'] = train_data_norm['Close_norm'].apply(lambda x: (x - train_data_norm['Close_norm'].min()) / (train_data_norm['Close_norm'].max() - train_data_norm['Close_norm'].min()))\n",
    "    train_data_norm['Volume_norm'] = train_data_norm['Volume_norm'].apply(lambda x: (x - train_data_norm['Volume_norm'].min()) / (train_data_norm['Volume_norm'].max() - train_data_norm['Volume_norm'].min()))\n",
    "    train_data_norm['High-Open_norm'] = train_data_norm['High-Open_norm'].apply(lambda x: (x - train_data_norm['High-Open_norm'].min()) / (train_data_norm['High-Open_norm'].max() - train_data_norm['High-Open_norm'].min()))\n",
    "    train_data_norm['Low-Open_norm'] = train_data_norm['Low-Open_norm'].apply(lambda x: (x - train_data_norm['Low-Open_norm'].min()) / (train_data_norm['Low-Open_norm'].max() - train_data_norm['Low-Open_norm'].min()))\n",
    "    train_data_norm['Close-Open_norm'] = train_data_norm['Close-Open_norm'].apply(lambda x: (x - train_data_norm['Close-Open_norm'].min()) / (train_data_norm['Close-Open_norm'].max() - train_data_norm['Close-Open_norm'].min()))\n",
    "\n",
    "    # Remove the first and the last row, becuase of NAN values\n",
    "    train_data_raw = train_data_raw.iloc[1:-1]\n",
    "    train_data_norm = train_data_norm.iloc[1:-1]\n",
    "\n",
    "    train_data_raw.to_csv(EXPORT_DATA_FOLDER+symbol+'train_raw_data.csv', index=True)\n",
    "    train_data_norm.to_csv(EXPORT_DATA_FOLDER+symbol+'train_norm_data.csv', index=True)\n",
    "    \n",
    "    \n",
    "# Get test data\n",
    "for symbol in stock_symbols:\n",
    "    # Download the historical price and volume data using yfinance\n",
    "    test_data_raw = yf.download(symbol, start=test_start, end=test_end)\n",
    "\n",
    "    # Normalize features by percent of changes between today and yesterday\n",
    "    pct_change_open = test_data_raw['Open'].pct_change().fillna(0)\n",
    "    pct_change_high = test_data_raw['High'].pct_change().fillna(0)\n",
    "    pct_change_high_over_open = (test_data_raw['High']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_low = test_data_raw['Low'].pct_change().fillna(0)\n",
    "    pct_change_low_over_open = (test_data_raw['Low']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_close = test_data_raw['Close'].pct_change().fillna(0)\n",
    "    pct_change_close_over_open = (test_data_raw['Close']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_adjclose = test_data_raw['Adj Close'].pct_change().fillna(0)\n",
    "    pct_change_adjclose_over_open = (test_data_raw['Adj Close']-test_data_raw['Open'])/test_data_raw['Open']\n",
    "    pct_change_volume = test_data_raw['Volume'].pct_change().fillna(0)\n",
    "\n",
    "    # Prepare labels: 2 means the close price of tomorow is higher than today's close price; 1 is down; 0 means the movement is between up_threshold and down_threshold\n",
    "    label = np.where(pct_change_close > up_threshold, 2, np.where(pct_change_close < down_threshold, 1, 0))[1:]\n",
    "    label = np.append(label, 0)\n",
    "\n",
    "    # Construct a test_data_norm data frame\n",
    "    test_data_norm = pd.DataFrame({'Open_norm':pct_change_open,\n",
    "                              'High_norm':pct_change_high,\n",
    "                              'Low_norm': pct_change_low,\n",
    "                              'Close_norm':pct_change_close,\n",
    "                              'Volume_norm':pct_change_volume,\n",
    "                              'High-Open_norm':pct_change_high_over_open,\n",
    "                              'Low-Open_norm':pct_change_low_over_open,\n",
    "                              'Close-Open_norm':pct_change_close_over_open,\n",
    "                              'Label_2up1down':label})\n",
    "\n",
    "    # Normalize by min-max normalization after the pct normalization\n",
    "    test_data_norm['Open_norm'] = test_data_norm['Open_norm'].apply(lambda x: (x - test_data_norm['Open_norm'].min()) / (test_data_norm['Open_norm'].max() - test_data_norm['Open_norm'].min()))\n",
    "    test_data_norm['High_norm'] = test_data_norm['High_norm'].apply(lambda x: (x - test_data_norm['High_norm'].min()) / (test_data_norm['High_norm'].max() - test_data_norm['High_norm'].min()))\n",
    "    test_data_norm['Low_norm'] = test_data_norm['Low_norm'].apply(lambda x: (x - test_data_norm['Low_norm'].min()) / (test_data_norm['Low_norm'].max() - test_data_norm['Low_norm'].min()))\n",
    "    test_data_norm['Close_norm'] = test_data_norm['Close_norm'].apply(lambda x: (x - test_data_norm['Close_norm'].min()) / (test_data_norm['Close_norm'].max() - test_data_norm['Close_norm'].min()))\n",
    "    test_data_norm['Volume_norm'] = test_data_norm['Volume_norm'].apply(lambda x: (x - test_data_norm['Volume_norm'].min()) / (test_data_norm['Volume_norm'].max() - test_data_norm['Volume_norm'].min()))\n",
    "    test_data_norm['High-Open_norm'] = test_data_norm['High-Open_norm'].apply(lambda x: (x - test_data_norm['High-Open_norm'].min()) / (test_data_norm['High-Open_norm'].max() - test_data_norm['High-Open_norm'].min()))\n",
    "    test_data_norm['Low-Open_norm'] = test_data_norm['Low-Open_norm'].apply(lambda x: (x - test_data_norm['Low-Open_norm'].min()) / (test_data_norm['Low-Open_norm'].max() - test_data_norm['Low-Open_norm'].min()))\n",
    "    test_data_norm['Close-Open_norm'] = test_data_norm['Close-Open_norm'].apply(lambda x: (x - test_data_norm['Close-Open_norm'].min()) / (test_data_norm['Close-Open_norm'].max() - test_data_norm['Close-Open_norm'].min()))\n",
    "\n",
    "    # Remove the first and the last row, becuase of NAN values\n",
    "    test_data_raw = test_data_raw.iloc[1:-1]\n",
    "    test_data_norm = test_data_norm.iloc[1:-1]\n",
    "\n",
    "    test_data_raw.to_csv(EXPORT_DATA_FOLDER+symbol+'test_raw_data.csv', index=True)\n",
    "    test_data_norm.to_csv(EXPORT_DATA_FOLDER+symbol+'test_norm_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c417de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data_df = pd.read_csv('./data/XOM_20200401_20230401_medium.csv', sep= ',', header= 0)\n",
    "text_data_df = text_data_df[['Date', 'News']]\n",
    "\n",
    "\n",
    "text_data_df = text_data_df.groupby('Date')['News'].apply('$$$###'.join)\n",
    "\n",
    "text_data_df.index = pd.to_datetime(text_data_df.index, dayfirst=True)\n",
    "# text_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163ee2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_df = train_data_norm.join(text_data_df, how = 'inner')\n",
    "all_test_df = test_data_norm.join(text_data_df, how = 'inner')\n",
    "\n",
    "print(all_train_df.index.min())\n",
    "print(all_train_df.index.max())\n",
    "print(all_test_df.index.min())\n",
    "print(all_test_df.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1dc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train = all_train_df.values\n",
    "\n",
    "window_size = no_of_days_to_lookback\n",
    "\n",
    "X_numerical_train = []\n",
    "y_train = []\n",
    "X_text_train = []\n",
    "X_text_train_curr = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(window_size, len(all_train) - no_of_days_to_lookforward + 1):\n",
    "    X_numerical_train.append(all_train[i-window_size: i, :-2])\n",
    "    \n",
    "    # split and append sequence of text\n",
    "    curr_seq = all_train[i-window_size: i, -1]\n",
    "    for j in range(window_size):\n",
    "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
    "        X_text_train_curr = X_text_train_curr + split_curr_seq\n",
    "    \n",
    "    if len(X_text_train_curr) > max_text_per_iter:\n",
    "        X_text_train_curr = X_text_train_curr[:max_text_per_iter]\n",
    "    \n",
    "    X_text_train.append(X_text_train_curr)\n",
    "        \n",
    "    # target labels\n",
    "    y_train.append(all_train[i:i+no_of_days_to_lookforward, -2])\n",
    "\n",
    "X_numerical_train, y_train = np.array(X_numerical_train).astype(np.float16), np.array(y_train).astype(np.int32)\n",
    "print(type(X_numerical_train))\n",
    "print(type(y_train))\n",
    "\n",
    "X_numerical_train = torch.from_numpy(X_numerical_train).type(torch.Tensor)\n",
    "y_train = torch.from_numpy(y_train).long()\n",
    "\n",
    "print(len(X_numerical_train))\n",
    "print(len(X_text_train))\n",
    "print(len(y_train))\n",
    "print(X_numerical_train.shape)\n",
    "\n",
    "print(len(X_text_train))\n",
    "print(len(X_text_train[2]))\n",
    "# print(X_text_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46d7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test = all_test_df.values\n",
    "\n",
    "\n",
    "X_numerical_test = []\n",
    "y_test = []\n",
    "X_text_test = []\n",
    "X_text_test_curr = []\n",
    "\n",
    "for i in range(window_size, len(all_test) - no_of_days_to_lookforward + 1):\n",
    "    X_numerical_test.append(all_test[i-window_size: i, :-2])\n",
    "    \n",
    "    # split and append sequence of text (in reverse order to add the latest news first)\n",
    "    curr_seq = all_test[i-window_size: i, -1]\n",
    "    for j in range(window_size):\n",
    "        split_curr_seq = curr_seq[window_size - 1 -j].split('$$$###')\n",
    "        X_text_test_curr = X_text_test_curr + split_curr_seq\n",
    "    \n",
    "    if len(X_text_test_curr) > max_text_per_iter:\n",
    "        X_text_test_curr = X_text_test_curr[:max_text_per_iter]\n",
    "    \n",
    "    X_text_test.append(X_text_test_curr)\n",
    "        \n",
    "    # target labels\n",
    "    y_test.append(all_test[i:i+no_of_days_to_lookforward, -2])\n",
    "\n",
    "X_numerical_test, y_test = np.array(X_numerical_test).astype(np.float16), np.array(y_test).astype(np.int32)\n",
    "print(type(X_numerical_test))\n",
    "print(type(y_test))\n",
    "\n",
    "X_numerical_test = torch.from_numpy(X_numerical_test).type(torch.Tensor)\n",
    "y_test = torch.from_numpy(y_test).long()\n",
    "\n",
    "print(len(X_numerical_test))\n",
    "print(len(X_text_test))\n",
    "print(len(y_test))\n",
    "print(X_numerical_test.shape)\n",
    "\n",
    "print(len(X_text_test))\n",
    "print(len(X_text_test[2]))\n",
    "# print(X_text_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa187ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4246, 0.3257, 0.4453, 0.4441, 0.1932, 0.4934, 0.8872, 0.5684],\n",
      "        [0.7788, 0.7954, 0.7358, 0.7979, 0.5088, 0.8218, 0.8267, 0.7310],\n",
      "        [0.8540, 0.4360, 0.6265, 0.3726, 0.1608, 0.1741, 0.4355, 0.0930],\n",
      "        [0.4275, 0.2666, 0.6353, 0.6196, 0.1874, 0.2355, 0.8696, 0.5459],\n",
      "        [0.8765, 0.6895, 0.7617, 0.5669, 0.3101, 0.0968, 0.6763, 0.1940]])"
     ]
    }
   ],
   "source": [
    "X_numerical_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26bc773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Exxon Cuts Capital Spending by 30% in Response to Coronavirus; The largest portion of the cuts will be in the Permian Basin, a key U.S. oil... Exxon Mobil Corp. said Tuesday that it would cut its 2020 capital spending by 30% as global demand for oil is sapped by the coronavirus. The largest portion of the $10 billion in cuts will be in the Permian Basin, the largest U.S. oil field ...',\n",
      " 'Wall Street’s Rally Fades This briefing is no longer updating. Read the latest developments in the coronavirus outbreak here. The Treasury is trying to expand the small-business loans program.',\n",
      " 'Coronavirus update: 1.39 million cases globally, 79,091 dead; Wuhan, China, reports zero deaths for first time since January; ExxonMobil... ExxonMobil cuts 2020 capex budget by 30% to combat oversupply and weak demand, while USA parent Gannett adopts poison pill The Chinese city of Wuhan reported zero deaths Tuesday from the coronavirus that causes COVID-19 for the first time ...',\n",
      " 'ExxonMobil Reduces 2020 Capex by 30% ExxonMobil said it is reducing its 2020 capital spending by 30 percent and lowering cash operating expenses by 15 percent in response to low commodity prices resulting from oversupply and demand weakness from the COVID-19 pandemic.',\n",
      " 'Oil downturn fuels talk of creating new cartel; Canada, U.S. mulling idea that could function like OPEC in North America As the oil sector weathers an extreme downturn amid declining demand and increased supply, Canadian oil producers, with support from the Alberta government, are exploring whether to create a North American cartel to manage production and ...',\n",
      " 'Oil Prices Reverse Sharply Lower Ahead Of OPEC Meeting; Exxon Slashes Capital Spending Crude oil prices reversed sharply lower Tuesday even as OPEC gets set to discuss an output cut Thursday and Exxon Mobil slashed its capital spending by 30%.',\n",
      " 'UPDATE 3-U.S. pushes back on call by OPEC+ to join big oil output cuts * U.S. does not commit to cuts, notes output falling * U.S. output next year to fall 2 mln bpd from 2019 peak -DOE * OPEC+ video conference talks due on Thursday',\n",
      " 'UPDATE 2-Exxon could delay third Guyana project as government review drags on (Adds comment from Guyana government, updates share price) April 7 (Reuters) - Exxon Mobil Corp said on Tuesday that production at the Payara project, its third development in Guyana, could be postponed due to delays in government approvals ...',\n",
      " 'Led By Harold Hamm, America’s Oil Frackers Are Slashing Output People on coronavirus lockdown don’t drive around. That’s meant a cataclysmic hit to global oil demand—down by some 30%, or about 30 million barrels per day. With storage tanks and pipeline systems filling up, the Saudis, Russians and other...',\n",
      " 'Oil drop saps gains as Wall Street fades late NEW YORK (Reuters) - Wall Street fell on Tuesday, as a drop in oil prices steepened in the latter stages of the session and erased early gains built on tentative signs that coronavirus outbreaks in some of the biggest U.S. hot spots may be ...',\n",
      " \"Macy's, Kraft Heinz rise; Alcon, NXP Semiconductor fall NEW YORK (AP) — Stocks that moved heavily or traded substantially on Tuesday: Exxon Mobil Corp., up 77 cents to $41.24 The energy giant its slashing its spending plans due to weak demand and a market flooded with an oversupply of oil.\",\n",
      " 'Exxon Mobil Stock Rises 5% Investing.com - Investing.com - Exxon Mobil (NYSE:XOM) Stock rose by 4.97% to trade at $42.45 by 11:48 (15:48 GMT) on Tuesday on the NYSE exchange.',\n",
      " 'ExxonMobil reduces Capex 2020 by 30% ExxonMobil announced that it is reducing its capital expenditure by 2020 by 30% and reducing cash operating expenses by 15% in response to low oil prices.',\n",
      " 'US Shale economy pants for breath after firms cut spending by $27bn [click to view image] Exxon Mobil Corp. more than doubled the budget cuts announced by any other shale company on Tuesday amid an historic crude-market crash.',\n",
      " \"Wall Street advances signs of coronavirus slowdown By Uday Sampath Kumar and Shreyashi Sanyal 7 Apr (Reuters) - Wall Street rose tuesday, faced with the first signs of slowdown in new cases of coronavirus in america's main spotlights, raising hopes that strict confinement measures to contain...\",\n",
      " 'Stocks - Exxon Soars in Premarket on Capex Cut Investing.com - By Geoffrey Smith Investing.com -- Stocks in focus in premarket trading on Tuesday. The market is expected to open higher across the board again, after a broad rally on Monday that lifted major indices by more than 7%. Please ...',\n",
      " 'Stocks - Wall Street Extends Rally at Open; Dow up 930 Points Investing.com - By Geoffrey Smith Investing.com --U.S. stock markets extended Monday’s blistering rally in early trade on Tuesday, on hopes that the Covid-19 pandemic will peak soon, allowing at least a partial lifting of lockdown ...',\n",
      " 'Market movers: Stocks seeing action on Tuesday - and why; A roundup of some of the North American equities that made moves in both... A roundup of some of the North American equities that made moves in both directions On the rise Restaurant Brands International Inc. ( QSR-T ) was up 6.1 per cent in early afternoon trading after Dubai-based private equity firm Gateway ...',\n",
      " 'UPDATE 5-Exxon lops 30% off 2020 spending, deeper and later than rivals (Changes throughout, updates stock price, adds chart, first-quarter outlook) By Jennifer Hiller HOUSTON, April 7 (Reuters) - Exxon Mobil Corp on Tuesday throttled back investment in shale, natural gas and deep water production, cutting ...',\n",
      " \"10:20 EDT Exxon investors may want more details on production cuts, says Wells... 10:20 EDT Exxon investors may want more details on production cuts, says Wells FargoWells Fargo analyst Roger Read says Exxon Mobil's capital expenditure cut to $23B from $33B met his expectations. Investors, however, may be left wanting ...\"]"
     ]
    }
   ],
   "source": [
    "len(X_text_train[0])\n",
    "X_text_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "704c1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
    "\n",
    "class SiameseDataloader(Dataset):\n",
    "    \n",
    "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
    "        self.X_numerical_train = X_numerical_train\n",
    "        self.X_text_train = X_text_train\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        token_type_ids = []\n",
    "        input_seq = []\n",
    "\n",
    "        for sent in X_text_train[index]:\n",
    "            encoded_sent = self.tokenizer.encode_plus(\n",
    "                text=sent,\n",
    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
    "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
    "                pad_to_max_length=True,         # Pad sentence to max length \n",
    "                #return_attention_mask=True      # Return attention mask\n",
    "                return_token_type_ids=True\n",
    "                )\n",
    "            input_ids.append(encoded_sent.get('input_ids'))\n",
    "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'x_numerical': X_numerical_train[index],\n",
    "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(y_train[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f0120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fbf4441",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "    if idx > 1:\n",
    "        break\n",
    "        \n",
    "    \n",
    "    x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "    ids = data['ids'].to(device, dtype = torch.long)\n",
    "    masks = data['mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "    targets = data['targets'].to(device, dtype = torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7334372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6504, 0.5669, 0.6841, 0.5850, 0.2462, 0.3333, 0.9990, 0.5942],\n",
      "         [0.6992, 0.4353, 0.6587, 0.5420, 0.1996, 0.0776, 0.9468, 0.4761],\n",
      "         [0.6108, 0.4353, 0.5005, 0.4270, 0.2791, 0.0438, 0.7686, 0.3164],\n",
      "         [0.4272, 0.3818, 0.5210, 0.5122, 0.2263, 0.3665, 1.0000, 0.6069],\n",
      "         [0.7075, 0.4756, 0.6240, 0.5225, 0.3088, 0.1785, 0.8672, 0.4436]],\n",
      "\n",
      "        [[0.6362, 0.3625, 0.5742, 0.4460, 0.2111, 0.0000, 0.8896, 0.4282],\n",
      "         [0.5767, 0.4607, 0.5884, 0.5176, 0.2417, 0.1074, 0.9478, 0.4736],\n",
      "         [0.6455, 0.4663, 0.6265, 0.5396, 0.2803, 0.0553, 0.9404, 0.4409],\n",
      "         [0.5693, 0.3777, 0.4717, 0.3982, 0.4419, 0.0000, 0.7886, 0.3022],\n",
      "         [0.4878, 0.4260, 0.5649, 0.4915, 0.1412, 0.2593, 0.9790, 0.4521]],\n",
      "\n",
      "        [[0.4551, 0.3179, 0.4626, 0.4565, 0.1854, 0.1486, 0.9238, 0.5156],\n",
      "         [0.6396, 0.4521, 0.6226, 0.5234, 0.2983, 0.0793, 0.9209, 0.4661],\n",
      "         [0.6548, 0.4875, 0.6294, 0.5581, 0.2102, 0.0492, 0.9009, 0.4473],\n",
      "         [0.6235, 0.5146, 0.6265, 0.5371, 0.2194, 0.1559, 0.9370, 0.4460],\n",
      "         [0.5352, 0.3474, 0.4753, 0.3970, 0.2903, 0.1197, 0.8594, 0.3616]],\n",
      "\n",
      "        [[0.5264, 0.4080, 0.5713, 0.5127, 0.1344, 0.1198, 0.9868, 0.4844],\n",
      "         [0.5913, 0.4407, 0.5786, 0.4988, 0.2598, 0.1461, 0.9956, 0.4736],\n",
      "         [0.6157, 0.4397, 0.5864, 0.5435, 0.3154, 0.1094, 0.9717, 0.4958],\n",
      "         [0.6406, 0.5591, 0.6313, 0.6118, 0.3467, 0.2693, 0.9834, 0.5874],\n",
      "         [0.7168, 0.4915, 0.6577, 0.5479, 0.2805, 0.0939, 0.8955, 0.4509]],\n",
      "\n",
      "        [[0.7085, 0.4666, 0.6821, 0.5830, 0.1316, 0.1276, 0.9639, 0.5317],\n",
      "         [0.6724, 0.5024, 0.5767, 0.4490, 0.3025, 0.0869, 0.8105, 0.3079],\n",
      "         [0.5215, 0.3223, 0.5469, 0.5039, 0.2009, 0.0294, 0.8979, 0.4214],\n",
      "         [0.6055, 0.6279, 0.6274, 0.7017, 0.4075, 0.4260, 0.9717, 0.7168],\n",
      "         [0.7871, 0.4907, 0.6680, 0.4316, 0.1860, 0.0748, 0.7695, 0.2754]],\n",
      "\n",
      "        [[0.4617, 0.3523, 0.6831, 0.5986, 0.0984, 0.1676, 0.9551, 0.5474],\n",
      "         [0.5679, 0.4670, 0.5557, 0.5205, 0.2927, 0.3127, 0.9678, 0.6133],\n",
      "         [0.6938, 0.5112, 0.6743, 0.5293, 0.3315, 0.2360, 0.9556, 0.4822],\n",
      "         [0.6689, 0.4968, 0.6377, 0.5596, 0.2817, 0.1901, 0.9229, 0.4431],\n",
      "         [0.5410, 0.3911, 0.5493, 0.5161, 0.1238, 0.2365, 0.9771, 0.5459]],\n",
      "\n",
      "        [[0.6538, 0.4939, 0.7773, 0.6191, 0.1357, 0.1598, 0.9927, 0.4919],\n",
      "         [0.6499, 0.4404, 0.5410, 0.4973, 0.1462, 0.0398, 0.8145, 0.3828],\n",
      "         [0.4963, 0.3506, 0.5312, 0.4702, 0.1985, 0.1103, 0.9238, 0.4851],\n",
      "         [0.5127, 0.3557, 0.4858, 0.4373, 0.3704, 0.1499, 0.9121, 0.5054],\n",
      "         [0.5581, 0.4795, 0.5811, 0.5068, 0.2227, 0.3474, 0.9922, 0.5640]],\n",
      "\n",
      "        [[0.6309, 0.4404, 0.5430, 0.4641, 0.2458, 0.0052, 0.7959, 0.3025],\n",
      "         [0.4756, 0.3472, 0.5425, 0.5059, 0.2260, 0.1216, 0.9697, 0.4976],\n",
      "         [0.6567, 0.5771, 0.6460, 0.6069, 0.4080, 0.2803, 0.9775, 0.5547],\n",
      "         [0.6479, 0.3660, 0.5981, 0.4668, 0.1785, 0.0000, 0.9111, 0.3982],\n",
      "         [0.5732, 0.4326, 0.5342, 0.4683, 0.2339, 0.0551, 0.8721, 0.3684]]])"
     ]
    }
   ],
   "source": [
    "print(x_numerical.shape)\n",
    "x_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91245748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]]])"
     ]
    }
   ],
   "source": [
    "print(ids.shape)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3488b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [2],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1]])"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "946e172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, input_dim1, input_dim2, \n",
    "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
    "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.input_dim1 = input_dim1\n",
    "        self.input_dim2 = input_dim2\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.hidden_dim3 = hidden_dim3\n",
    "        self.hidden_dim4 = hidden_dim4\n",
    "        self.num_layers1 = num_layers1\n",
    "        self.num_layers2 = num_layers2\n",
    "        self.output_dim1 = output_dim1\n",
    "        self.output_dim2 = output_dim2\n",
    "        \n",
    "        \n",
    "\n",
    "#         self.roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "        \n",
    "        \n",
    "#         self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
    "#         self.lstm2 = nn.LSTM(input_dim2, hidden_dim2, num_layers2, batch_first=True)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim2, output_dim2)\n",
    "        self.fc3 = nn.Linear(input_dim1, hidden_dim3)\n",
    "#         self.fc3 = nn.Linear(output_dim1+output_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x1, ids, masks, token_type_ids):\n",
    "        #left tower with numerical features\n",
    "#         h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "#         c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "#         ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
    "#         h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
    "#         out1 = self.fc1(h_out1)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # right tower with roberta on textual features  \n",
    "        #TODO\n",
    "#         batch_size_here = ids.shape[0]\n",
    "#         e2 = torch.zeros(batch_size_here, max_text_per_iter,1024).to(device)\n",
    "        \n",
    "#         for k in range(ids.shape[1]):\n",
    "#             seq_ids = ids[:,k,:]\n",
    "#             seq_masks = masks[:,k,:]\n",
    "#             seq_token_type_ids = token_type_ids[:,k,:]\n",
    "\n",
    "\n",
    "#             e2k = self.roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "#             # print(e2.shape)\n",
    "#             # print(e2k[1].shape)\n",
    "#             #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "#             # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "#             e2k1 = e2k[0][:, 0, :]  \n",
    "#             e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "#         print('e2 shape: ', e2.shape)        \n",
    "#         h_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "#         c_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "#         ula2, (h_out2, _) = self.lstm2(e2, (h_20, c_20))\n",
    "#         h_out2 = h_out2.view(-1, self.hidden_dim2)\n",
    "#         out2 = self.fc2(h_out2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # siamese merging layers\n",
    "        x1 = torch.squeeze(x1[:, 0, :]) #x1[:, 0, :].squeeze()\n",
    "        print('shape of x1 after squeeze:', x1.shape)\n",
    "#         output = torch.cat((out1, out2),1)\n",
    "#         output = F.relu(self.fc3(output))\n",
    "        output = F.relu(self.fc3(x1))\n",
    "        output = F.relu(self.fc4(output))\n",
    "        output = self.fc5(output)\n",
    "        return output\n",
    "    \n",
    "#TODO : correct these values\n",
    "model = SiameseModel(input_dim1 = 8, input_dim2 = 1024, \n",
    "                 hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 128, hidden_dim4 = 64,\n",
    "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256).to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcc56c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "# for i in range(len(list(model.parameters()))):\n",
    "#     print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cf0242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_arr = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6aa4c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "train_loss_record = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_loss_sum = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        masks = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # debugging roberta encoder and second lstm\n",
    "        '''\n",
    "        debug starts here\n",
    "        '''\n",
    "        # if idx > 1:\n",
    "        #     break\n",
    "        # batch_size_here = data['ids'].shape[0]\n",
    "        # print('batch_size_here:', batch_size_here)\n",
    "        # e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
    "        # print('ids shape:', ids.shape)\n",
    "        \n",
    "        # for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
    "        #     print('k:', k)\n",
    "        #     seq_ids = ids[:,k,:].to(device)\n",
    "        #     seq_masks = masks[:,k,:].to(device)\n",
    "        #     seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
    "\n",
    "\n",
    "        #     e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "        #     print(e2.shape)\n",
    "        #     print(e2k[1].shape)\n",
    "        #     #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "        #     # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "        #     e2k1 = e2k[0][:, 0, :]  \n",
    "        #     e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        # lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
    "        # fc2 = nn.Linear(768, 256)\n",
    "\n",
    "        # h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
    "        # h_out2 = h_out2.view(-1, 768)\n",
    "        # out2 = fc2(h_out2)\n",
    "        \n",
    "\n",
    "    #     print(ids.shape)\n",
    "    #     print(masks.shape)\n",
    "    #     print(token_type_ids.shape)\n",
    "    \n",
    "        # print(out2)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        debug ends here\n",
    "        '''\n",
    "        \n",
    "\n",
    "    \n",
    "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
    "        print('y_pred:', y_pred)\n",
    "        print('target:', targets)\n",
    "        loss = criterion(y_pred, targets.reshape(-1))\n",
    "        \n",
    "         # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loss.append(loss.data.cpu())\n",
    "        train_loss_sum.append(loss.data.cpu())\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())   \n",
    "\n",
    "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "    train_loss_record.append(np.mean(train_loss_sum))\n",
    "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate on test set every epoch\n",
    "    tloss = []\n",
    "    test_loss_sum = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
    "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
    "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
    "        _, pred_label = torch.max(y_pred.data, 1)\n",
    "\n",
    "#         print('y_pred:', y_pred)\n",
    "        test_loss = criterion(y_pred, test_targets.reshape(-1))\n",
    "    \n",
    "        tloss.append(test_loss.data.cpu())\n",
    "        test_loss_sum.append(test_loss.data.cpu()) \n",
    "\n",
    "        wandb.log({'avg test loss in this batch': test_loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "        \n",
    "        # Get accuracy\n",
    "        total += test_targets.reshape(-1).size(0)\n",
    "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
    "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
    "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c7baa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "train_loss_record = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_loss_sum = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        masks = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # debugging roberta encoder and second lstm\n",
    "        '''\n",
    "        debug starts here\n",
    "        '''\n",
    "        # if idx > 1:\n",
    "        #     break\n",
    "        # batch_size_here = data['ids'].shape[0]\n",
    "        # print('batch_size_here:', batch_size_here)\n",
    "        # e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
    "        # print('ids shape:', ids.shape)\n",
    "        \n",
    "        # for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
    "        #     print('k:', k)\n",
    "        #     seq_ids = ids[:,k,:].to(device)\n",
    "        #     seq_masks = masks[:,k,:].to(device)\n",
    "        #     seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
    "\n",
    "\n",
    "        #     e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "        #     print(e2.shape)\n",
    "        #     print(e2k[1].shape)\n",
    "        #     #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "        #     # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "        #     e2k1 = e2k[0][:, 0, :]  \n",
    "        #     e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        # lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
    "        # fc2 = nn.Linear(768, 256)\n",
    "\n",
    "        # h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
    "        # h_out2 = h_out2.view(-1, 768)\n",
    "        # out2 = fc2(h_out2)\n",
    "        \n",
    "\n",
    "    #     print(ids.shape)\n",
    "    #     print(masks.shape)\n",
    "    #     print(token_type_ids.shape)\n",
    "    \n",
    "        # print(out2)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        debug ends here\n",
    "        '''\n",
    "        print('shape of x1 = x_numerical : ', x_numerical.shape)    \n",
    "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
    "        print('y_pred:', y_pred)\n",
    "        print('target:', targets)\n",
    "        loss = criterion(y_pred, targets.reshape(-1))\n",
    "        \n",
    "         # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loss.append(loss.data.cpu())\n",
    "        train_loss_sum.append(loss.data.cpu())\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())   \n",
    "\n",
    "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "    train_loss_record.append(np.mean(train_loss_sum))\n",
    "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate on test set every epoch\n",
    "    tloss = []\n",
    "    test_loss_sum = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
    "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
    "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
    "        _, pred_label = torch.max(y_pred.data, 1)\n",
    "\n",
    "#         print('y_pred:', y_pred)\n",
    "        test_loss = criterion(y_pred, test_targets.reshape(-1))\n",
    "    \n",
    "        tloss.append(test_loss.data.cpu())\n",
    "        test_loss_sum.append(test_loss.data.cpu()) \n",
    "\n",
    "        wandb.log({'avg test loss in this batch': test_loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "        \n",
    "        # Get accuracy\n",
    "        total += test_targets.reshape(-1).size(0)\n",
    "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
    "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
    "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6de4ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "train_loss_record = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_loss_sum = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        masks = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # debugging roberta encoder and second lstm\n",
    "        '''\n",
    "        debug starts here\n",
    "        '''\n",
    "        # if idx > 1:\n",
    "        #     break\n",
    "        # batch_size_here = data['ids'].shape[0]\n",
    "        # print('batch_size_here:', batch_size_here)\n",
    "        # e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
    "        # print('ids shape:', ids.shape)\n",
    "        \n",
    "        # for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
    "        #     print('k:', k)\n",
    "        #     seq_ids = ids[:,k,:].to(device)\n",
    "        #     seq_masks = masks[:,k,:].to(device)\n",
    "        #     seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
    "\n",
    "\n",
    "        #     e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "        #     print(e2.shape)\n",
    "        #     print(e2k[1].shape)\n",
    "        #     #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "        #     # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "        #     e2k1 = e2k[0][:, 0, :]  \n",
    "        #     e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        # lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
    "        # fc2 = nn.Linear(768, 256)\n",
    "\n",
    "        # h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
    "        # h_out2 = h_out2.view(-1, 768)\n",
    "        # out2 = fc2(h_out2)\n",
    "        \n",
    "\n",
    "    #     print(ids.shape)\n",
    "    #     print(masks.shape)\n",
    "    #     print(token_type_ids.shape)\n",
    "    \n",
    "        # print(out2)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        debug ends here\n",
    "        '''\n",
    "        print('shape of x1 = x_numerical : ', x_numerical.shape)    \n",
    "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
    "        print('y_pred:', y_pred)\n",
    "        print('target:', targets)\n",
    "        loss = criterion(y_pred, targets.reshape(-1))\n",
    "        \n",
    "         # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loss.append(loss.data.cpu())\n",
    "        train_loss_sum.append(loss.data.cpu())\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())   \n",
    "\n",
    "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "    train_loss_record.append(np.mean(train_loss_sum))\n",
    "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate on test set every epoch\n",
    "    print('starting testing..')\n",
    "    tloss = []\n",
    "    test_loss_sum = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
    "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
    "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        print('shape of x1 = test_x_numerical : ', test_x_numerical.shape)    \n",
    "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
    "        _, pred_label = torch.max(y_pred.data, 1)\n",
    "\n",
    "#         print('y_pred:', y_pred)\n",
    "        test_loss = criterion(y_pred, test_targets.reshape(-1))\n",
    "    \n",
    "        tloss.append(test_loss.data.cpu())\n",
    "        test_loss_sum.append(test_loss.data.cpu()) \n",
    "\n",
    "        wandb.log({'avg test loss in this batch': test_loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "        \n",
    "        # Get accuracy\n",
    "        total += test_targets.reshape(-1).size(0)\n",
    "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
    "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
    "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ff68e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, input_dim1, input_dim2, \n",
    "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
    "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.input_dim1 = input_dim1\n",
    "        self.input_dim2 = input_dim2\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.hidden_dim3 = hidden_dim3\n",
    "        self.hidden_dim4 = hidden_dim4\n",
    "        self.num_layers1 = num_layers1\n",
    "        self.num_layers2 = num_layers2\n",
    "        self.output_dim1 = output_dim1\n",
    "        self.output_dim2 = output_dim2\n",
    "        \n",
    "        \n",
    "\n",
    "#         self.roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "        \n",
    "        \n",
    "#         self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
    "#         self.lstm2 = nn.LSTM(input_dim2, hidden_dim2, num_layers2, batch_first=True)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim2, output_dim2)\n",
    "        self.fc3 = nn.Linear(input_dim1, hidden_dim3)\n",
    "#         self.fc3 = nn.Linear(output_dim1+output_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x1, ids, masks, token_type_ids):\n",
    "        #left tower with numerical features\n",
    "#         h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "#         c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "#         ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
    "#         h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
    "#         out1 = self.fc1(h_out1)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # right tower with roberta on textual features  \n",
    "        #TODO\n",
    "#         batch_size_here = ids.shape[0]\n",
    "#         e2 = torch.zeros(batch_size_here, max_text_per_iter,1024).to(device)\n",
    "        \n",
    "#         for k in range(ids.shape[1]):\n",
    "#             seq_ids = ids[:,k,:]\n",
    "#             seq_masks = masks[:,k,:]\n",
    "#             seq_token_type_ids = token_type_ids[:,k,:]\n",
    "\n",
    "\n",
    "#             e2k = self.roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "#             # print(e2.shape)\n",
    "#             # print(e2k[1].shape)\n",
    "#             #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "#             # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "#             e2k1 = e2k[0][:, 0, :]  \n",
    "#             e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "#         print('e2 shape: ', e2.shape)        \n",
    "#         h_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "#         c_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "#         ula2, (h_out2, _) = self.lstm2(e2, (h_20, c_20))\n",
    "#         h_out2 = h_out2.view(-1, self.hidden_dim2)\n",
    "#         out2 = self.fc2(h_out2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # siamese merging layers\n",
    "        x1 = torch.squeeze(x1[:, 0, :], 1) #x1[:, 0, :].squeeze()\n",
    "        print('shape of x1 after squeeze:', x1.shape)\n",
    "#         output = torch.cat((out1, out2),1)\n",
    "#         output = F.relu(self.fc3(output))\n",
    "        output = F.relu(self.fc3(x1))\n",
    "        output = F.relu(self.fc4(output))\n",
    "        output = self.fc5(output)\n",
    "        return output\n",
    "    \n",
    "#TODO : correct these values\n",
    "model = SiameseModel(input_dim1 = 8, input_dim2 = 1024, \n",
    "                 hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 128, hidden_dim4 = 64,\n",
    "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256).to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e54364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "# for i in range(len(list(model.parameters()))):\n",
    "#     print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc0d1c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.sdk.wandb_run.Run at 0x12aa8d3a0>"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"stock_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e8d1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "train_loss_record = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_loss_sum = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        masks = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # debugging roberta encoder and second lstm\n",
    "        '''\n",
    "        debug starts here\n",
    "        '''\n",
    "        # if idx > 1:\n",
    "        #     break\n",
    "        # batch_size_here = data['ids'].shape[0]\n",
    "        # print('batch_size_here:', batch_size_here)\n",
    "        # e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
    "        # print('ids shape:', ids.shape)\n",
    "        \n",
    "        # for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
    "        #     print('k:', k)\n",
    "        #     seq_ids = ids[:,k,:].to(device)\n",
    "        #     seq_masks = masks[:,k,:].to(device)\n",
    "        #     seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
    "\n",
    "\n",
    "        #     e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "        #     print(e2.shape)\n",
    "        #     print(e2k[1].shape)\n",
    "        #     #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "        #     # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "        #     e2k1 = e2k[0][:, 0, :]  \n",
    "        #     e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        # lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
    "        # fc2 = nn.Linear(768, 256)\n",
    "\n",
    "        # h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
    "        # h_out2 = h_out2.view(-1, 768)\n",
    "        # out2 = fc2(h_out2)\n",
    "        \n",
    "\n",
    "    #     print(ids.shape)\n",
    "    #     print(masks.shape)\n",
    "    #     print(token_type_ids.shape)\n",
    "    \n",
    "        # print(out2)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        debug ends here\n",
    "        '''\n",
    "        print('shape of x1 = x_numerical : ', x_numerical.shape)    \n",
    "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
    "        print('y_pred:', y_pred)\n",
    "        print('target:', targets)\n",
    "        loss = criterion(y_pred, targets.reshape(-1))\n",
    "        \n",
    "         # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loss.append(loss.data.cpu())\n",
    "        train_loss_sum.append(loss.data.cpu())\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())   \n",
    "\n",
    "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "    train_loss_record.append(np.mean(train_loss_sum))\n",
    "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate on test set every epoch\n",
    "    print('starting testing..')\n",
    "    tloss = []\n",
    "    test_loss_sum = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
    "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
    "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        print('shape of x1 = test_x_numerical : ', test_x_numerical.shape)    \n",
    "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
    "        _, pred_label = torch.max(y_pred.data, 1)\n",
    "\n",
    "#         print('y_pred:', y_pred)\n",
    "        test_loss = criterion(y_pred, test_targets.reshape(-1))\n",
    "    \n",
    "        tloss.append(test_loss.data.cpu())\n",
    "        test_loss_sum.append(test_loss.data.cpu()) \n",
    "\n",
    "        wandb.log({'avg test loss in this batch': test_loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "        \n",
    "        # Get accuracy\n",
    "        total += test_targets.reshape(-1).size(0)\n",
    "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
    "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
    "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d7f23ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "train_loss_record = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_loss_sum = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        masks = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # debugging roberta encoder and second lstm\n",
    "        '''\n",
    "        debug starts here\n",
    "        '''\n",
    "        # if idx > 1:\n",
    "        #     break\n",
    "        # batch_size_here = data['ids'].shape[0]\n",
    "        # print('batch_size_here:', batch_size_here)\n",
    "        # e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
    "        # print('ids shape:', ids.shape)\n",
    "        \n",
    "        # for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
    "        #     print('k:', k)\n",
    "        #     seq_ids = ids[:,k,:].to(device)\n",
    "        #     seq_masks = masks[:,k,:].to(device)\n",
    "        #     seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
    "\n",
    "\n",
    "        #     e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "        #     print(e2.shape)\n",
    "        #     print(e2k[1].shape)\n",
    "        #     #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "        #     # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "        #     e2k1 = e2k[0][:, 0, :]  \n",
    "        #     e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        # lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
    "        # fc2 = nn.Linear(768, 256)\n",
    "\n",
    "        # h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
    "        # h_out2 = h_out2.view(-1, 768)\n",
    "        # out2 = fc2(h_out2)\n",
    "        \n",
    "\n",
    "    #     print(ids.shape)\n",
    "    #     print(masks.shape)\n",
    "    #     print(token_type_ids.shape)\n",
    "    \n",
    "        # print(out2)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        debug ends here\n",
    "        '''\n",
    "        print('shape of x1 = x_numerical : ', x_numerical.shape)    \n",
    "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
    "        print('y_pred:', y_pred)\n",
    "        print('target:', targets)\n",
    "        loss = criterion(y_pred, targets.reshape(-1))\n",
    "        \n",
    "         # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loss.append(loss.data.cpu())\n",
    "        train_loss_sum.append(loss.data.cpu())\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())   \n",
    "\n",
    "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "    train_loss_record.append(np.mean(train_loss_sum))\n",
    "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate on test set every epoch\n",
    "    print('starting testing..')\n",
    "    tloss = []\n",
    "    test_loss_sum = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
    "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
    "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        print('shape of x1 = test_x_numerical : ', test_x_numerical.shape)    \n",
    "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
    "        _, pred_label = torch.max(y_pred.data, 1)\n",
    "\n",
    "#         print('y_pred:', y_pred)\n",
    "        test_loss = criterion(y_pred, test_targets.reshape(-1))\n",
    "    \n",
    "        tloss.append(test_loss.data.cpu())\n",
    "        test_loss_sum.append(test_loss.data.cpu()) \n",
    "\n",
    "        wandb.log({'avg test loss in this batch': test_loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "        \n",
    "        # Get accuracy\n",
    "        \n",
    "        total += test_targets.reshape(-1).size(0)\n",
    "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
    "        print('in this epoch, total, correct:', total, correct)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
    "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
    "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "774ad1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_arr = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f509701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.sdk.wandb_run.Run at 0x12aaa9220>"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:xr2m7y5z) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg test loss in this batch</td><td>▃▁▄▅▃▅▁▃▄▅▃▆▅▄▁▃▁▅▆▆▅▆▁▃▅▃▃▄▃▃▅▅▃▁▇▁▅▅▁█</td></tr><tr><td>avg test loss in this epoch</td><td>█▇▇█▇▇█▇▇▆▂▇▇▁█▇▇▁▇▁▇▁▁▁▇▇▇▇▇▇▁▇▂▁▇▇▁▇▇▇</td></tr><tr><td>avg train loss in this batch</td><td>▅▃▅▁▆▆▆▃▆▄▅▆▆▆▃█▆▃▃▅▅█▃▅▆▄▄▄▃▅▆▇▆▆▅▃█▄▆▃</td></tr><tr><td>avg train loss in this epoch</td><td>▁▁▁▆▃▆▁▃▃▆▃▆▃▃█▃▃▃▆▃▆▆▃▁▆▃▆▃▆▆▃▃▃█▁▃▆▆▃▆</td></tr><tr><td>batch_id</td><td>▄▁▂▃▁▂▃▄▂▃▄▂▃▄▅▃▄▅▂▃▅▆▃▄▆▃▄▅▆▄▅▆▄▅▆▇▅▆▇█</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>test accuracy in this epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg test loss in this batch</td><td>1.13943</td></tr><tr><td>avg test loss in this epoch</td><td>1.10414</td></tr><tr><td>avg train loss in this batch</td><td>1.1101</td></tr><tr><td>avg train loss in this epoch</td><td>1.11512</td></tr><tr><td>batch_id</td><td>7</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>test accuracy in this epoch</td><td>33.33333</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">light-glitter-14</strong> at: <a href='https://wandb.ai/visriv/stock_prediction/runs/xr2m7y5z' target=\"_blank\">https://wandb.ai/visriv/stock_prediction/runs/xr2m7y5z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230623_145056-xr2m7y5z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:xr2m7y5z). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/visriv/Documents/Git/xai-seq/wandb/run-20230623_145850-d34q13j6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/visriv/stock_prediction/runs/d34q13j6' target=\"_blank\">giddy-cloud-15</a></strong> to <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/visriv/stock_prediction' target=\"_blank\">https://wandb.ai/visriv/stock_prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/visriv/stock_prediction/runs/d34q13j6' target=\"_blank\">https://wandb.ai/visriv/stock_prediction/runs/d34q13j6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"stock_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a509a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "train_loss_record = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    train_loss_sum = []\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "        x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        masks = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        # debugging roberta encoder and second lstm\n",
    "        '''\n",
    "        debug starts here\n",
    "        '''\n",
    "        # if idx > 1:\n",
    "        #     break\n",
    "        # batch_size_here = data['ids'].shape[0]\n",
    "        # print('batch_size_here:', batch_size_here)\n",
    "        # e2 = torch.zeros(batch_size_here, max_text_per_iter, 1024)\n",
    "        # print('ids shape:', ids.shape)\n",
    "        \n",
    "        # for k in range(ids.shape[1]):  #number of sentences in sequence = max_text_per_iter\n",
    "        #     print('k:', k)\n",
    "        #     seq_ids = ids[:,k,:].to(device)\n",
    "        #     seq_masks = masks[:,k,:].to(device)\n",
    "        #     seq_token_type_ids = token_type_ids[:,k,:].to(device)\n",
    "\n",
    "\n",
    "        #     e2k = roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "        #     print(e2.shape)\n",
    "        #     print(e2k[1].shape)\n",
    "        #     #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "        #     # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "        #     e2k1 = e2k[0][:, 0, :]  \n",
    "        #     e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "        # lstm2 = nn.LSTM(1024, 768, 1, batch_first=True)\n",
    "        # fc2 = nn.Linear(768, 256)\n",
    "\n",
    "        # h_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # c_20 = Variable(torch.zeros(1, e2.size(0), 768))\n",
    "        # ula2, (h_out2, _) = lstm2(e2, (h_20, c_20))\n",
    "        # h_out2 = h_out2.view(-1, 768)\n",
    "        # out2 = fc2(h_out2)\n",
    "        \n",
    "\n",
    "    #     print(ids.shape)\n",
    "    #     print(masks.shape)\n",
    "    #     print(token_type_ids.shape)\n",
    "    \n",
    "        # print(out2)\n",
    "\n",
    "\n",
    "        \n",
    "        '''\n",
    "        debug ends here\n",
    "        '''\n",
    "        print('shape of x1 = x_numerical : ', x_numerical.shape)    \n",
    "        y_pred = model(x_numerical, ids, masks, token_type_ids)\n",
    "        print('y_pred:', y_pred)\n",
    "        print('target:', targets)\n",
    "        loss = criterion(y_pred, targets.reshape(-1))\n",
    "        \n",
    "         # Zero out gradient, else they will accumulate between epochs\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update parameters\n",
    "        optimiser.step()\n",
    "        \n",
    "        \n",
    "        \n",
    "        train_loss.append(loss.data.cpu())\n",
    "        train_loss_sum.append(loss.data.cpu())\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch !=0:\n",
    "            print(\"Epoch \", epoch, \"CELoss: \", loss.item())   \n",
    "\n",
    "        wandb.log({'avg train loss in this batch': loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('Train Loss at epoch {}: {}\\n'.format(epoch, np.mean(train_loss_sum)))\n",
    "    train_loss_record.append(np.mean(train_loss_sum))\n",
    "    wandb.log({'avg train loss in this epoch': np.mean(train_loss_sum), 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # evaluate on test set every epoch\n",
    "    print('starting testing..')\n",
    "    tloss = []\n",
    "    test_loss_sum = []\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for idx, data in tqdm(enumerate(test_loader, 0)):\n",
    "        test_x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "        test_ids = data['ids'].to(device, dtype = torch.long)\n",
    "        test_masks = data['mask'].to(device, dtype = torch.long)\n",
    "        test_token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        test_targets = data['targets'].to(device, dtype = torch.long)\n",
    "        \n",
    "        print('shape of x1 = test_x_numerical : ', test_x_numerical.shape)    \n",
    "        y_pred = model(test_x_numerical, test_ids, test_masks, test_token_type_ids)\n",
    "        _, pred_label = torch.max(y_pred.data, 1)\n",
    "\n",
    "#         print('y_pred:', y_pred)\n",
    "        test_loss = criterion(y_pred, test_targets.reshape(-1))\n",
    "    \n",
    "        tloss.append(test_loss.data.cpu())\n",
    "        test_loss_sum.append(test_loss.data.cpu()) \n",
    "\n",
    "        wandb.log({'avg test loss in this batch': test_loss.item(), 'epoch': epoch, 'batch_id': idx})\n",
    "        \n",
    "        # Get accuracy\n",
    "        \n",
    "        total += test_targets.reshape(-1).size(0)\n",
    "        correct += (pred_label == test_targets.reshape(-1)).sum()\n",
    "        print('in this epoch, total, correct:', total, correct)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Record at every epoch\n",
    "    print('test Loss at epoch {}: {}\\n'.format(epoch, np.mean(test_loss_sum)))\n",
    "    wandb.log({'avg test loss in this epoch': np.mean(test_loss_sum), 'epoch': epoch})\n",
    "    wandb.log({'test accuracy in this epoch': accuracy, 'epoch': epoch})\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6eb336bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
    "\n",
    "class SiameseDataloader(Dataset):\n",
    "    \n",
    "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
    "        self.X_numerical_train = X_numerical_train\n",
    "        self.X_text_train = X_text_train\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.tokenizer = tokenizer\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        token_type_ids = []\n",
    "        input_seq = []\n",
    "\n",
    "        for sent in self.X_text_train[index]:\n",
    "            encoded_sent = self.tokenizer.encode_plus(\n",
    "                text=sent,\n",
    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
    "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
    "                pad_to_max_length=True,         # Pad sentence to max length \n",
    "                #return_attention_mask=True      # Return attention mask\n",
    "                return_token_type_ids=True\n",
    "                )\n",
    "            input_ids.append(encoded_sent.get('input_ids'))\n",
    "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'x_numerical': aelf.X_numerical_train[index],\n",
    "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.y_train[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91d69bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09c62611",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "    if idx > 1:\n",
    "        break\n",
    "        \n",
    "    \n",
    "    x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "    ids = data['ids'].to(device, dtype = torch.long)\n",
    "    masks = data['mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "    targets = data['targets'].to(device, dtype = torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6dfaa928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
    "\n",
    "class SiameseDataloader(Dataset):\n",
    "    \n",
    "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
    "        self.X_numerical_train = X_numerical_train\n",
    "        self.X_text_train = X_text_train\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.tokenizer = tokenizer\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def __getitem__(index):\n",
    "\n",
    "        \n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        token_type_ids = []\n",
    "        input_seq = []\n",
    "\n",
    "        for sent in self.X_text_train[index]:\n",
    "            encoded_sent = self.tokenizer.encode_plus(\n",
    "                text=sent,\n",
    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
    "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
    "                pad_to_max_length=True,         # Pad sentence to max length \n",
    "                #return_attention_mask=True      # Return attention mask\n",
    "                return_token_type_ids=True\n",
    "                )\n",
    "            input_ids.append(encoded_sent.get('input_ids'))\n",
    "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'x_numerical': aelf.X_numerical_train[index],\n",
    "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.y_train[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb57ee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06fcc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f7affe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "    if idx > 1:\n",
    "        break\n",
    "        \n",
    "    \n",
    "    x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "    ids = data['ids'].to(device, dtype = torch.long)\n",
    "    masks = data['mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "    targets = data['targets'].to(device, dtype = torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "649ae1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-large', truncation=True, do_lower_case=True)\n",
    "\n",
    "class SiameseDataloader(Dataset):\n",
    "    \n",
    "    def __init__(self, X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer):\n",
    "        self.X_numerical_train = X_numerical_train\n",
    "        self.X_text_train = X_text_train\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "        token_type_ids = []\n",
    "        input_seq = []\n",
    "\n",
    "        for sent in X_text_train[index]:\n",
    "            encoded_sent = self.tokenizer.encode_plus(\n",
    "                text=sent,\n",
    "                add_special_tokens=True,        # Add `[CLS]` and `[SEP]` special tokens\n",
    "                max_length=self.MAX_LEN,             # Choose max length to truncate/pad\n",
    "                pad_to_max_length=True,         # Pad sentence to max length \n",
    "                #return_attention_mask=True      # Return attention mask\n",
    "                return_token_type_ids=True\n",
    "                )\n",
    "            input_ids.append(encoded_sent.get('input_ids'))\n",
    "            attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "            token_type_ids.append(encoded_sent.get('token_type_ids'))\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids = torch.tensor(input_ids)\n",
    "        attention_masks = torch.tensor(attention_masks)\n",
    "        token_type_ids = torch.tensor(token_type_ids)\n",
    "\n",
    "\n",
    "        return {\n",
    "            'x_numerical': X_numerical_train[index],\n",
    "            'ids': torch.tensor(input_ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(attention_masks, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(y_train[index], dtype=torch.long)\n",
    "        }\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8c4512e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e04a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "    if idx > 1:\n",
    "        break\n",
    "        \n",
    "    \n",
    "    x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "    ids = data['ids'].to(device, dtype = torch.long)\n",
    "    masks = data['mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "    targets = data['targets'].to(device, dtype = torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb8c0cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7056, 0.4321, 0.5952, 0.4241, 0.2539, 0.0468, 0.7715, 0.3079],\n",
      "         [0.3989, 0.2382, 0.3931, 0.3906, 0.3120, 0.1181, 0.8105, 0.4438],\n",
      "         [0.7271, 0.6226, 0.7925, 0.6406, 0.2598, 0.1996, 0.9521, 0.4407],\n",
      "         [0.5898, 0.3608, 0.5508, 0.4673, 0.1748, 0.0541, 0.9111, 0.3813],\n",
      "         [0.5610, 0.4919, 0.5488, 0.5229, 0.3037, 0.2698, 0.9233, 0.4604]],\n",
      "\n",
      "        [[0.5996, 0.4429, 0.6064, 0.5288, 0.2595, 0.0425, 0.9399, 0.4458],\n",
      "         [0.6074, 0.4851, 0.6113, 0.5342, 0.2245, 0.1251, 0.9795, 0.4658],\n",
      "         [0.5903, 0.4114, 0.5547, 0.5298, 0.2646, 0.0901, 0.9443, 0.5078],\n",
      "         [0.5503, 0.3628, 0.4619, 0.3594, 0.2693, 0.0499, 0.8105, 0.3350],\n",
      "         [0.5088, 0.3552, 0.5752, 0.4983, 0.1159, 0.0986, 0.9790, 0.4609]],\n",
      "\n",
      "        [[0.9736, 1.0000, 0.9937, 0.9990, 0.7095, 0.4316, 0.9209, 0.5410],\n",
      "         [0.6455, 0.3428, 0.5498, 0.4832, 0.1078, 0.1014, 0.7695, 0.4150],\n",
      "         [0.5815, 0.3745, 0.5830, 0.4495, 0.1290, 0.0080, 0.8062, 0.3406],\n",
      "         [0.4460, 0.3103, 0.4087, 0.3533, 0.2072, 0.1185, 0.7793, 0.3330],\n",
      "         [0.5264, 0.4070, 0.6191, 0.5874, 0.2216, 0.2373, 0.9956, 0.5752]],\n",
      "\n",
      "        [[0.5684, 0.5200, 0.5977, 0.5923, 0.3550, 0.2576, 0.9775, 0.6006],\n",
      "         [0.6362, 0.3625, 0.5742, 0.4460, 0.2111, 0.0000, 0.8896, 0.4282],\n",
      "         [0.5767, 0.4607, 0.5884, 0.5176, 0.2417, 0.1074, 0.9478, 0.4736],\n",
      "         [0.6455, 0.4663, 0.6265, 0.5396, 0.2803, 0.0553, 0.9404, 0.4409],\n",
      "         [0.5693, 0.3777, 0.4717, 0.3982, 0.4419, 0.0000, 0.7886, 0.3022]],\n",
      "\n",
      "        [[0.7168, 0.4915, 0.6577, 0.5479, 0.2805, 0.0939, 0.8955, 0.4509],\n",
      "         [0.5376, 0.3669, 0.4888, 0.3750, 0.2852, 0.0949, 0.8398, 0.3257],\n",
      "         [0.5537, 0.4199, 0.6011, 0.6016, 0.1204, 0.1722, 0.9668, 0.5439],\n",
      "         [0.6470, 0.4514, 0.6143, 0.5161, 0.2961, 0.0838, 0.9336, 0.4700],\n",
      "         [0.6289, 0.5308, 0.6216, 0.6113, 0.3679, 0.2117, 0.9507, 0.5811]],\n",
      "\n",
      "        [[0.6997, 0.4731, 0.6685, 0.5967, 0.2283, 0.1892, 0.9653, 0.5483],\n",
      "         [0.6021, 0.4458, 0.6030, 0.5132, 0.1489, 0.2006, 1.0000, 0.5435],\n",
      "         [0.4470, 0.2390, 0.3589, 0.3496, 0.4546, 0.1470, 0.8706, 0.5283],\n",
      "         [0.7109, 0.5396, 0.6802, 0.5132, 0.1523, 0.0900, 0.8364, 0.3457],\n",
      "         [0.4438, 0.2717, 0.4495, 0.3767, 0.5552, 0.1193, 0.8945, 0.3811]],\n",
      "\n",
      "        [[0.4946, 0.3564, 0.5483, 0.4658, 0.2240, 0.0876, 0.9219, 0.3872],\n",
      "         [0.5454, 0.3735, 0.5498, 0.5200, 0.2096, 0.0836, 0.9683, 0.4885],\n",
      "         [0.6802, 0.4978, 0.5801, 0.5020, 0.3384, 0.0138, 0.8062, 0.3394],\n",
      "         [0.4961, 0.3345, 0.5361, 0.4851, 0.1107, 0.0486, 0.9253, 0.4653],\n",
      "         [0.5610, 0.3718, 0.4587, 0.3765, 0.4341, 0.0016, 0.7646, 0.3040]],\n",
      "\n",
      "        [[0.5801, 0.4414, 0.6123, 0.4700, 0.1643, 0.2539, 0.9907, 0.5151],\n",
      "         [0.5298, 0.2654, 0.3887, 0.3469, 0.2644, 0.0464, 0.7539, 0.3552],\n",
      "         [0.3755, 0.1788, 0.3474, 0.2622, 0.3457, 0.0439, 0.7520, 0.3152],\n",
      "         [0.5264, 0.3806, 0.5527, 0.4756, 0.1635, 0.1029, 0.8398, 0.3743],\n",
      "         [0.5962, 0.4429, 0.6035, 0.5977, 0.2050, 0.1226, 0.8867, 0.5161]]])"
     ]
    }
   ],
   "source": [
    "print(x_numerical.shape)\n",
    "x_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bfe57dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SiameseDataloader(X_numerical_train, y_train, X_text_train, MAX_LEN, tokenizer)\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "test_set = SiameseDataloader(X_numerical_test, y_test, X_text_test, MAX_LEN, tokenizer)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce9fc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in tqdm(enumerate(train_loader, 0)):\n",
    "    if idx > 1:\n",
    "        break\n",
    "        \n",
    "    \n",
    "    x_numerical = data['x_numerical'].to(device, dtype = torch.float)\n",
    "    ids = data['ids'].to(device, dtype = torch.long)\n",
    "    masks = data['mask'].to(device, dtype = torch.long)\n",
    "    token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "    targets = data['targets'].to(device, dtype = torch.long)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1be4039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.4482, 0.3164, 0.5532, 0.4597, 0.2559, 0.1724, 0.7974, 0.3616],\n",
      "         [0.3933, 0.1324, 0.3101, 0.3062, 0.2703, 0.0145, 0.6846, 0.3652],\n",
      "         [0.5269, 0.3479, 0.5117, 0.3589, 0.2173, 0.0000, 0.6943, 0.2324],\n",
      "         [0.5186, 0.7314, 0.6587, 0.9082, 0.3604, 0.8525, 0.9980, 1.0000],\n",
      "         [0.6636, 0.3513, 0.6284, 0.3013, 0.2277, 0.4827, 0.9590, 0.5181]],\n",
      "\n",
      "        [[0.3933, 0.1324, 0.3101, 0.3062, 0.2703, 0.0145, 0.6846, 0.3652],\n",
      "         [0.5269, 0.3479, 0.5117, 0.3589, 0.2173, 0.0000, 0.6943, 0.2324],\n",
      "         [0.5186, 0.7314, 0.6587, 0.9082, 0.3604, 0.8525, 0.9980, 1.0000],\n",
      "         [0.6636, 0.3513, 0.6284, 0.3013, 0.2277, 0.4827, 0.9590, 0.5181],\n",
      "         [0.5435, 0.3472, 0.4666, 0.4692, 0.2900, 0.4233, 0.8477, 0.5400]],\n",
      "\n",
      "        [[0.5269, 0.3479, 0.5117, 0.3589, 0.2173, 0.0000, 0.6943, 0.2324],\n",
      "         [0.5186, 0.7314, 0.6587, 0.9082, 0.3604, 0.8525, 0.9980, 1.0000],\n",
      "         [0.6636, 0.3513, 0.6284, 0.3013, 0.2277, 0.4827, 0.9590, 0.5181],\n",
      "         [0.5435, 0.3472, 0.4666, 0.4692, 0.2900, 0.4233, 0.8477, 0.5400],\n",
      "         [0.7925, 0.4985, 0.7910, 0.6055, 0.0974, 0.0766, 0.8613, 0.3762]],\n",
      "\n",
      "        [[0.5186, 0.7314, 0.6587, 0.9082, 0.3604, 0.8525, 0.9980, 1.0000],\n",
      "         [0.6636, 0.3513, 0.6284, 0.3013, 0.2277, 0.4827, 0.9590, 0.5181],\n",
      "         [0.5435, 0.3472, 0.4666, 0.4692, 0.2900, 0.4233, 0.8477, 0.5400],\n",
      "         [0.7925, 0.4985, 0.7910, 0.6055, 0.0974, 0.0766, 0.8613, 0.3762],\n",
      "         [0.6265, 0.5952, 0.6528, 0.6167, 0.3540, 0.3506, 0.9409, 0.4976]],\n",
      "\n",
      "        [[0.6636, 0.3513, 0.6284, 0.3013, 0.2277, 0.4827, 0.9590, 0.5181],\n",
      "         [0.5435, 0.3472, 0.4666, 0.4692, 0.2900, 0.4233, 0.8477, 0.5400],\n",
      "         [0.7925, 0.4985, 0.7910, 0.6055, 0.0974, 0.0766, 0.8613, 0.3762],\n",
      "         [0.6265, 0.5952, 0.6528, 0.6167, 0.3540, 0.3506, 0.9409, 0.4976],\n",
      "         [0.6938, 0.4355, 0.5898, 0.5166, 0.1724, 0.1091, 0.7715, 0.3494]],\n",
      "\n",
      "        [[0.5435, 0.3472, 0.4666, 0.4692, 0.2900, 0.4233, 0.8477, 0.5400],\n",
      "         [0.7925, 0.4985, 0.7910, 0.6055, 0.0974, 0.0766, 0.8613, 0.3762],\n",
      "         [0.6265, 0.5952, 0.6528, 0.6167, 0.3540, 0.3506, 0.9409, 0.4976],\n",
      "         [0.6938, 0.4355, 0.5898, 0.5166, 0.1724, 0.1091, 0.7715, 0.3494],\n",
      "         [0.5049, 0.3542, 0.4731, 0.5098, 0.2369, 0.1655, 0.7510, 0.5015]],\n",
      "\n",
      "        [[0.7925, 0.4985, 0.7910, 0.6055, 0.0974, 0.0766, 0.8613, 0.3762],\n",
      "         [0.6265, 0.5952, 0.6528, 0.6167, 0.3540, 0.3506, 0.9409, 0.4976],\n",
      "         [0.6938, 0.4355, 0.5898, 0.5166, 0.1724, 0.1091, 0.7715, 0.3494],\n",
      "         [0.5049, 0.3542, 0.4731, 0.5098, 0.2369, 0.1655, 0.7510, 0.5015],\n",
      "         [0.6479, 0.5220, 0.7427, 0.5850, 0.2191, 0.2273, 0.9531, 0.5376]],\n",
      "\n",
      "        [[0.6265, 0.5952, 0.6528, 0.6167, 0.3540, 0.3506, 0.9409, 0.4976],\n",
      "         [0.6938, 0.4355, 0.5898, 0.5166, 0.1724, 0.1091, 0.7715, 0.3494],\n",
      "         [0.5049, 0.3542, 0.4731, 0.5098, 0.2369, 0.1655, 0.7510, 0.5015],\n",
      "         [0.6479, 0.5220, 0.7427, 0.5850, 0.2191, 0.2273, 0.9531, 0.5376],\n",
      "         [0.7456, 0.6338, 0.7505, 0.7129, 0.2832, 0.2864, 0.9829, 0.6196]]])"
     ]
    }
   ],
   "source": [
    "print(x_numerical.shape)\n",
    "x_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b903941a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]],\n",
      "\n",
      "        [[    0,  9089, 43903,  ...,    30,   389,     2],\n",
      "         [    0, 28216,   852,  ...,   274,  4216,     2],\n",
      "         [    0, 15228,   261,  ...,   112,     4,     2],\n",
      "         ...,\n",
      "         [    0, 14773,  7458,  ...,  1782,   814,     2],\n",
      "         [    0, 34543,   195,  ...,  5090,   389,     2],\n",
      "         [    0,   698,    35,  ...,   189,   236,     2]]])"
     ]
    }
   ],
   "source": [
    "print(ids.shape)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "10025547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [2],\n",
      "        [0],\n",
      "        [0],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [1]])"
     ]
    }
   ],
   "source": [
    "print(targets.shape)\n",
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c353f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class SiameseModel(nn.Module):\n",
    "    def __init__(self, input_dim1, input_dim2, \n",
    "                 hidden_dim1, hidden_dim2, hidden_dim3, hidden_dim4,\n",
    "                 num_layers1, num_layers2, output_dim1, output_dim2):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.input_dim1 = input_dim1\n",
    "        self.input_dim2 = input_dim2\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.hidden_dim3 = hidden_dim3\n",
    "        self.hidden_dim4 = hidden_dim4\n",
    "        self.num_layers1 = num_layers1\n",
    "        self.num_layers2 = num_layers2\n",
    "        self.output_dim1 = output_dim1\n",
    "        self.output_dim2 = output_dim2\n",
    "        \n",
    "        \n",
    "\n",
    "#         self.roberta = RobertaModel.from_pretrained(\"roberta-large\").to(device)\n",
    "        \n",
    "        \n",
    "#         self.lstm1 = nn.LSTM(input_dim1, hidden_dim1, num_layers1, batch_first=True)\n",
    "#         self.lstm2 = nn.LSTM(input_dim2, hidden_dim2, num_layers2, batch_first=True)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_dim1, output_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim2, output_dim2)\n",
    "        self.fc3 = nn.Linear(input_dim1, hidden_dim3)\n",
    "#         self.fc3 = nn.Linear(output_dim1+output_dim2, hidden_dim3)\n",
    "        self.fc4 = nn.Linear(hidden_dim3, hidden_dim4)\n",
    "        self.fc5 = nn.Linear(hidden_dim4, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x1, ids, masks, token_type_ids):\n",
    "        #left tower with numerical features\n",
    "#         h_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "#         c_10 = Variable(torch.zeros(self.num_layers1, x1.size(0), self.hidden_dim1)).to(device)\n",
    "#         ula1, (h_out1, _) = self.lstm1(x1, (h_10, c_10))\n",
    "#         h_out1 = h_out1.view(-1, self.hidden_dim1)\n",
    "#         out1 = self.fc1(h_out1)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        # right tower with roberta on textual features  \n",
    "        #TODO\n",
    "#         batch_size_here = ids.shape[0]\n",
    "#         e2 = torch.zeros(batch_size_here, max_text_per_iter,1024).to(device)\n",
    "        \n",
    "#         for k in range(ids.shape[1]):\n",
    "#             seq_ids = ids[:,k,:]\n",
    "#             seq_masks = masks[:,k,:]\n",
    "#             seq_token_type_ids = token_type_ids[:,k,:]\n",
    "\n",
    "\n",
    "#             e2k = self.roberta(input_ids= seq_ids, attention_mask=seq_masks, token_type_ids=seq_token_type_ids)\n",
    "#             # print(e2.shape)\n",
    "#             # print(e2k[1].shape)\n",
    "#             #first 0 is for last_hidden_state: https://huggingface.co/docs/transformers/main/en/model_doc/roberta#transformers.RobertaModel.forward.returns:~:text=transformers.modeling_outputs.-,BaseModelOutputWithPoolingAndCrossAttentions%20or%20tuple(torch.FloatTensor),-A%20transformers.modeling_outputs\n",
    "#             # the shape of e2k[0] is (batch_size, sequence_length (<=MAX_LEN), hidden_size (=1024))\n",
    "#             e2k1 = e2k[0][:, 0, :]  \n",
    "#             e2[:,k,:] = e2k1\n",
    "    \n",
    "    \n",
    "#         print('e2 shape: ', e2.shape)        \n",
    "#         h_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "#         c_20 = Variable(torch.zeros(self.num_layers2, e2.size(0), self.hidden_dim2)).to(device)\n",
    "#         ula2, (h_out2, _) = self.lstm2(e2, (h_20, c_20))\n",
    "#         h_out2 = h_out2.view(-1, self.hidden_dim2)\n",
    "#         out2 = self.fc2(h_out2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # siamese merging layers\n",
    "        x1 = torch.squeeze(x1[:, 0, :], 1) #x1[:, 0, :].squeeze()\n",
    "        print('shape of x1 after squeeze:', x1.shape)\n",
    "#         output = torch.cat((out1, out2),1)\n",
    "#         output = F.relu(self.fc3(output))\n",
    "        output = F.relu(self.fc3(x1))\n",
    "        output = F.relu(self.fc4(output))\n",
    "        output = self.fc5(output)\n",
    "        return output\n",
    "    \n",
    "#TODO : correct these values\n",
    "model = SiameseModel(input_dim1 = 8, input_dim2 = 1024, \n",
    "                 hidden_dim1 = 20, hidden_dim2 = 768, hidden_dim3 = 128, hidden_dim4 = 64,\n",
    "                 num_layers1 = 1, num_layers2 = 1, output_dim1 = 10, output_dim2 = 256).to(device)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dba1fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "print(len(list(model.parameters())))\n",
    "# for i in range(len(list(model.parameters()))):\n",
    "#     print(list(model.parameters())[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "05628d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_arr = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5e4b69b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"stock_prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
